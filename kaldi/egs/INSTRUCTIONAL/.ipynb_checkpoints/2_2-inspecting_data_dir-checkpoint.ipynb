{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2: Inspecting the `data` directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`run_prepare_data.sh` 파일은 `data`라는 새로운 디렉토리를 생성합니다. 해당 디렉토리에는 `ASR` pipeline에 사용되는 많은 파일들이 들어있습니다. 어떠한 파일들이 들어있는지 살펴보도록 하겠습니다. \n",
    "\n",
    "**Note:** `kaldi` 공식 문서를 통해 해당 파일들에 대한 자세한 설명을 확인할 수 있습니다. (http://kaldi-asr.org/doc/data_prep.html) 일부 부분들은 워크샵에서 사용하는 pipeline과 무관합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `data/kaldi_config_args.json`\n",
    "\n",
    "This file is simply a *copy* of the `kaldi_config.json` used in the running of `run_prepare_data.sh`.  Each major step of the ASR pipeline will copy the relevant portion of the `kaldi_config.json` file to the relevant location so that we can keep track of what we used for the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat data/kaldi_config_args.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `data/{train|test}_dir`\n",
    "\n",
    "해당 디렉토리에는 각각의 데이터셋에 해당하는 4 개의 파일이 있습니다. 각 데이터셋은 `train`과 `test`로 구분되어 있습니다. (`run_prepare_data.sh`를 실행할 때 폴더를 나누어 두었음을 가정합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls data/train_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `wav.scp`\n",
    "\n",
    "이 파일은 각각의 `audio-basename`과 해당 음성 파일의 위치를 포함하고 있습니다. 파일 형식은 다음과 같습니다. \n",
    "\n",
    "\n",
    "```\n",
    "[audio-basename] [full/path/to/audio]\n",
    "[audio-basename] [full/path/to/audio]\n",
    "[audio-basename] [full/path/to/audio]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "head -n5 data/train_dir/wav.scp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** `kaldi`는 이 파일의 두 번째 논항을 `piped` 명령어로 사용하는 것이 가능합니다. 공식 매뉴얼에 있는 다음 예를 참고하세요. \n",
    "\n",
    "\n",
    "```\n",
    "s5# head -3 data/train/wav.scp\n",
    "sw02001-A /home/dpovey/kaldi-trunk/tools/sph2pipe_v2.5/sph2pipe -f wav -p -c 1 /export/corpora3/LDC/LDC97S62/swb1/sw02001.sph |\n",
    "sw02001-B /home/dpovey/kaldi-trunk/tools/sph2pipe_v2.5/sph2pipe -f wav -p -c 2 /export/corpora3/LDC/LDC97S62/swb1/sw02001.sph |\n",
    "```\n",
    "\n",
    "위의 경우, `/home/dpovey/kaldi-trunk/tools/sph2pipe_v2.5/sph2pipe -f wav -p -c 1 /export/corpora3/LDC/LDC97S62/swb1/sw02001.sph` 명령어는 `.sph` 파일을 `.wav` 파일로 변환합니다. 마지막 기호인 `|`는 변환한 결과물을 저장할 파일 위치를 정해주는 것과 같은 역할을 합니다. \n",
    "\n",
    "우리는 전처리 과정에서 이미 위의 변환 과정을 실행하였으므로 사용할 필요는 없습니다. 하지만 나중에 직접 데이터를 다룰 경우, 원본 데이터를 변경하지 않고 `pipeline`에서 실행하고 싶은 경우, 이러한 방법을 사용할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `text`\n",
    "\n",
    "이 파일은 `run_prepare_data.sh`에서 생성한 데이터셋의 `전사` 내용을 담고 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n5 data/train_dir/text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `utt2spk`\n",
    "\n",
    "이 파일은 각각의 발화가 어떠한 화자의 발화인지를 표시하는 내용을 담고 있습니다. 화자 정보를 유지하는 것은, 나중에 화자 정보를 이용한 모델을 구성할 때에는 중요할 수 있습니다. \n",
    "\n",
    "파일 형식은 다음과 같습니다. \n",
    "\n",
    "```\n",
    "[utterance-id] [speaker-id]\n",
    "[utterance-id] [speaker-id]\n",
    "[utterance-id] [speaker-id]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n5 data/train_dir/utt2spk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** 만약 우리가 화자 정보를 몰랐다면, `speaker-id`를 `utterance-id`와 동일하게 만들 수도 있습니다. 이 경우, `n` 명의 화자가 있었다는 결과를 낳게 됩니다. (`n` = 발화 갯수)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일 구조에서 확인할 수 있듯이, 지금 사용하는 `kaldi` pipeline에서는 우리가 화자 정보를 가지고 있지 않다는 것을 전제로 작동합니다. 하지만 `librispeech`의 경우 실제로는 화자 정보를 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중간 과정에서 (`1:1 Downloading...`) 생성되는 파일은 `librispeech` 화자 정보를 유지한 `utt2spk` 파일을 생성합니다. 해당 파일은 `raw_data/Librispeech/[subset]_data`에 저장되어 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n5 raw_data/LibriSpeech/dev-clean_data/utt2spk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 파일을 확인하면 `utterance-id`를 작성하는 규칙은 마지막 `000*`을 통해서 동일한 화자가 발화한 더 큰 음성 디렉토리의 일부라는 것을 명시하는 것이라는 것을 확인할 수 있습니다. \n",
    "\n",
    "**Note:** 우리는 연속성 유지를 위해 현재의 `utt2spk` 파일을 사용하도록 하겠습니다. 하지만 나중에 이 부분을 다시 실행하여서 화자 정보를 유지한 `utt2spk` 파일을 사용하는 것이 `ASR` 성능에 어떠한 영향을 미치는지 확인해볼 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `spk2utt`\n",
    "\n",
    "이 파일은 `utt2spk`와는 반대로 한 화자가 어떠한 발화를 하였는지를 표시해둔 파일입니다. `utt2spk`는 하나의 발화를 누가 녹음하였는지 일대일 대응의 형식으로 작성되어 있는 반면, `spk2utt` 파일은 하나의 화자가 발화한 전체 `utterance-id`가 작성되어 있습니다. 파일 형식은 다음과 같습니다. \n",
    "\n",
    "```\n",
    "[speaker-id] [utterance-id_1] [utterance-id_2] [utterance-id_3] ... [utterance-id_n]\n",
    "[speaker-id] [utterance-id_1] [utterance-id_2] [utterance-id_3] ... [utterance-id_n]\n",
    "[speaker-id] [utterance-id_1] [utterance-id_2] [utterance-id_3] ... [utterance-id_n]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 워크샵의 경우, `utt2spk`와 `spk2utt` 파일은 동일한 형식을 취하게 됩니다. 왜냐하면 이번 pipeline에서는 화자 정보를 고려하지 않고 `ASR` 시스템을 구축하기 때문입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n5 data/train_dir/spk2utt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`raw_data/LibriSpeech/[subset]` 내부에 존재하는 `spk2utt` 파일을 확인하면 실제 `librispeech` 파일에서는 화자 정보를 고려하여 파일이 작성되었음을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n2 raw_data/LibriSpeech/dev-clean_data/spk2utt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `segments` (optional)\n",
    "\n",
    "우리는 전처리 과정에서 `librispeech` 데이터를 각각 분리(segment)하였기 때문에, 이 과정은 필요하지 않습니다. 하지만 `utterance` 단위로 분리되어있지 않은 긴 음성 파일을 이용하고자 하는 경우, `run_prepare_data.sh`을 실행할 때 긴 음성 파일을 `{train|test}`으로 구분해주는 과정을 거쳐야 합니다. `segments` 파일 형식은 다음과 같습니다. \n",
    "\n",
    "```\n",
    "[audio-basename] [utterance-id] [utterance-start] [utterance-stop]\n",
    "[audio-basename] [utterance-id] [utterance-start] [utterance-stop]\n",
    "[audio-basename] [utterance-id] [utterance-start] [utterance-stop]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `data/local`\n",
    "\n",
    "`data/local` 폴더 아래에는 중간 과정에서 생성되는 파일들이 저장되고, 나중에 다른 pipeline 과정에서 필요한 파일들이 저장되어 있습니다. 모든 **중요한** 파일들은 `data` 아래에 다른 하위 폴더에 저장되므로, 이 폴더는 자세하게 설명하지 않도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `waves.{train|test}`\n",
    "\n",
    "이 파일들은 `train`과 `test` 데이터셋에 있는 음성 파일의 목록입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n5 data/local/waves.train\n",
    "echo ...\n",
    "head -n5 data/local/waves.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `lm_tg.arpa`\n",
    "\n",
    "이 파일은 `run_prepare_data.sh` 파일을 통해 `<UNK>` 없이 `n-gram`을 이용한 `language model`을 담고 있습니다. 이 파일을 이용할 경우, `<UNK>`는 `ASR` 시스템이 절대로 예측할 수 없다는 것을 다시 한 번 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff data/local/lm_tg.arpa raw_data/3-gram.pruned.3e-7.arpa | head -n10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `data/local/dict`\n",
    "\n",
    "이 디렉토리에는 `lexicon`과 관련된 파일들이 저장되어 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls data/local/dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `lexicon.txt`\n",
    "\n",
    "`run_prepare_data.sh` 파일 작성에 이용한 `lexicon` 파일의 복사본입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff: data/local/dict/lexicon.txt: No such file or directory\n",
      "diff: raw_data/librispeech-lexicon.txt: No such file or directory\n"
     ]
    },
    {
     "ename": "",
     "evalue": "2",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "diff data/local/dict/lexicon.txt raw_data/librispeech-lexicon.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** `kaldi`에서는 이러한 과정이 빈번하게 일어납니다. `kaldi`에서는 필요한 파일들을 `local` 폴더에 복사해두고, 필요한 파일들을 원래 위치에서 불러오는 것이 아니라 `local`에 복사해둔 복사본을 이용합니다. 디스크 용량을 많이 차지한다는 측면에서는 효율적이지 못할 수도 있지만, pipeline에 사용되는 모든 파라미터들을 수정하는 것은 너무나도 많은 작업을 요구하기 때문에, 불편함을 감수하고 이대로 진행하도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `lexiconp.txt`\n",
    "\n",
    "이 파일은 원래 `lexicon` 파일의 정보와 함께 각 단어들이 특정 발음으로 발화될 확률을 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat data/local/dict/lexiconp.txt | grep INDIRECTLY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 파일을 사용함으로써, `lexicon`을 통해 한 단어가 여러가지 발음을 가지고 잇다는 정보를 제공할 뿐만 아니라, 각각의 발음에 서로 다른 `weights`를 줄 수도 있습니다. 하지면 이번 워크샵에서는 발음에 대한 `weights`를 설정할만한 충분한 데이터를 가지고 있지 않으므로, 모든 발음에 동일한 `weights (1.0)`을 부여하겠습니다. (만약 발음이 두 개라면 각각 `0.5`의 weight를 부여하는 것이 맞겠지만, `kaldi`는 모든 발음에 `1.0`의 weight를 주어도 모든 발음에 동일한 weight가 부여된 것으로 인식합니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `{non}silence_phones.txt` and `optional_silence.txt`\n",
    "\n",
    "`silence_phones.txt`과 `nonsilence_phones.txt` 파일은 단순히 `run_data_prepare.sh` 파일의 input으로 사용된 `phones` 리스트에서 `silence`를 표시하기 위해 사용된 phone과 `nonsilence`를 표시하기 위해 사용된 phone을 구별해둔 것입니다. 우리가 사용하는 pipeline에서는 `SIL`이 유일한 `silence_phone` 입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat data/local/dict/silence_phones.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`optional_silence.txt` 파일은 단어 사이의 `silence`를 표시하기 위해 사용된 `phone`의 값을 저장하고 잇습니다. `kaldi` 공식 문서에서는 왜 이 파일이 사용되는지에 대한 자세한 설명은 제공하지 않습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat data/local/dict/optional_silence.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `data/local/lang`\n",
    "\n",
    "이 파일은 `data/lang` 파일을 사용하는데 임시로 사용된 디렉토리입니다. 자세한 내용은 `data/lang` 디렉토리를 살펴보도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `data/lang`\n",
    "\n",
    "이 디렉토리에는 `language model`을 구축하는데 필요한 모든 파일들이 들어있습니다. (`kaldi`에서 `ARPA` 포맷의 `language model`을 decoding 과정에서 어떻게 사용하는지는 나중에 다시 살펴보겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `words.txt`\n",
    "\n",
    "이 파일에는 `lexicon`의 단어들과 각각의 index의 관계가 명시되어 있습니다. \n",
    "\n",
    "**Note:** `kaldi`에서는 효율성을 위해 각각의 `단어`나 `phone`을 그 자체로 사용하는 것이 아니라 `index`를 사용하여서 표현하는 경우가 많습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n5 data/lang/words.txt\n",
    "echo ...\n",
    "tail -n5 data/lang/words.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "몇 가지 단어가 추가되어 있음을 확인할 수 있습니다. \n",
    "\n",
    " - `<eps>`: a faux-word used to model the \"space\" between words in a later step\n",
    " - `#0`: a faux-word used to allow our `finite state transducer (FST)` to function properly\n",
    " - `<s>`: an faux-word used to model the \"start of an utterance\" in a later step\n",
    " - `</s>`: an faux-word used to model the \"end of an utterance\" in a later step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `phones.txt`\n",
    "\n",
    "`run_prepare_data.sh` 실행에 사용된 각각의 `phone`들과 그 `phone`에 해당하는 `index` 사이의 관계를 담고 있는 파일입니다. \n",
    "\n",
    "이 경우, `phones.txt` 파일과 `run_prepare_data.sh` 파일에 사용된 `phone` 간에는 두 가지의 차이가 있습니다. \n",
    "\n",
    " - `<eps>`가 추가되었습니다. \n",
    " - 각각의 `phone`은 `BIES` 기호가 추가되어 있습니다. `BIES` 기호는 각각의 `phone`이 단어 내부에서 어느 위치에 있는지를 표시하는데 사용됩니다. \n",
    "   - `B`eginning\n",
    "   - `I`nside\n",
    "   - `E`nd\n",
    "   - `S`olo (the word is made up of only this phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head data/lang/phones.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `{arpa}_oov.txt`\n",
    "\n",
    "이 두개의 파일은 `language model`에 나타나지 않는 파일들을 다루기 위해 사용됩니다. (`OOV` = out of vocabulary)\n",
    "\n",
    "**Note:** `OOV`는 나중에 `ASR` 모델에 에러를 야기하기 쉽습니다. 그러므로 준비 과정에서 해당 단어들을 찾아서 `lexicon`에 추가해주는 것이 좋습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat data/lang/arpa_oov.txt\n",
    "echo ...\n",
    "cat data/lang/oov.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`language model`과 `lexicon`을 같은 데이터를 이용하여 직접 생성하였기 때문에, `OOV` 관련된 파일에 내용이 없는 것은 전혀 이상하지 않습니다. 하지만 만약 `language model`이 아주 큰 corpus를 이용하여 구축되었고 각각의 단어의 대략의 발음을 생성해낼 수 있는 방법이 있다면 `language model`과 `lexicon`에 같은 단어가 존재하는지 확인하는 과정을 건너 뛸 수 있습니다. \n",
    "\n",
    "나중에 우리는 자동적으로 `OOV` 단어들을 `FST`에서 제거하는 과정을 거치게 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `oov.int`\n",
    "\n",
    "`oov.txt` 파일의 내용을 `index`를 이용해 표시해둔 파일입니다. \n",
    "\n",
    "**Note:** `kaldi`에서 `.txt` 파일과 `.int` 파일이 같은 이름을 가지고 있다면, 같은 내용을 서로 다른 형식으로 표기하고 있다는 뜻입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat data/lang/oov.int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `topo`\n",
    "\n",
    "이 파일은 acoustic model을 구축할 때 사용할 `Hidden Markov Model (HMMs)`의 구조를 담고 있습니다. 나중에 더 자세하게 다루도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat data/lang/topo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서 우리는 두 개의 서로 다른 `HMM` 구조를 확인할 수 있습니다. 하나는 `1,2,3,4,5`의 숫자가 있는 phone이며, 그를 제외한 나머지 phone 입니다. `data/lang/phones.txt` 파일을 확인해보면, `1-5`의 숫자가 사용된 phone은 `silence phones` 이라는 것을 알 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat data/lang/phones.txt | head -n 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `L.fst` and `L_disambig.fst`\n",
    "\n",
    "이 두 파일은 구축해둔 language model의 `finite state transducer (FST)` 구조를 담고 있습니다. `L.fst`는 language model의 `FST` 구조를 담고 있습니다. `L_disambig.fst`는 `L.fst` 파일을 효율적으로 사용하기 위해서 수정된 파일입니다. 두 개의 차이가 궁금하시다면 [이 곳](http://kaldi-asr.org/doc/graph.html#graph_disambig)에서 확인하실 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 아래와 같이 두 파일을 비교해보면, `L_disambig.fst` 파일이 `L.fst` 파일보다 더 크다는 것을 확ㅇ니할 수 있습니다. 그 이유는 `L_disambig.fst` 파일이 더 많은 `states`와 `transition arcs`를 이용하여 구성되기 때문입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff <(/home/kaldi/tools/openfst/bin/fstinfo data/lang/L.fst) <(/home/kaldi/tools/openfst/bin/fstinfo data/lang/L_disambig.fst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** `diff <(...) <(...)` 명령어를 이용하면 두 출력에서의 차이를 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `data/lang/phones`\n",
    "\n",
    "`phones set`과 관련된 다른 파일들을 저장하고 있는 디렉토리입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `silence.{txt|int|csl}, nonsilence.{txt|int|csl}, and optional_silence.{txt|int|csl}`\n",
    "\n",
    "앞서 우리는 `.txt` 파일과 `.int` 파일의 차이를 확인하였습니다. `.csl` (colon-separated list) 파일은 `.txt` 파일의 또 다른 버전입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat data/lang/phones/silence.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat data/lang/phones/silence.csl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `word_boundary.{txt|int}`\n",
    "\n",
    "이 파일들은 BIES 표시가 된 각각의 phone이 단어에서 어디에 위치하고 있는지 표시하고 있습니다. `kaldi` 공식 문서에서는 왜 이 파일이 중요한지를 다음과 같이 설명하고 있습니다. \n",
    "\n",
    "```\n",
    "This is the same information as is in the suffixes of the phones (_B and so on), but we don't like to hardcode this in the text form of the phones– for one thing, Kaldi executables never see the text form of the phones, but only an integerized form.\n",
    "```\n",
    "연속된 음성에서 단어의 경계를 찾을 때, `word_boundary` 파일은 중요한 역할을 할 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head data/lang/phones/word_boundary.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `align_lexicon.{txt|int}`\n",
    "\n",
    "이 파일은 `BIES` 표기가 된 phone이 사용될 때 생성됩니다. 이 파일들은 `lexicon`에서 각각의 phone이 `BIES` 표기가 되도록 정보를 업데이트 합니다. \n",
    "\n",
    "원래의 `lexicon`과 `data/lang/phones/align_lexicon.txt` 파일을 비교해보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff <(tail data/lang/phones/align_lexicon.txt) <(tail raw_data/librispeech-lexicon.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `context_indep.{txt|int|csl}`\n",
    "\n",
    "이 파일은 context를 고려하지 않을 phone이 어떤 것들이 있는지 표시하고 있습니다. 결국 \"context-independent\"한 phone은 실제 단어에 사용되지 않는 phone을 나타내는데, 우리의 경우에는 `silence` phone이 이에 해당됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat data/lang/phones/context_indep.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `disambig.{txt|int|csl}`\n",
    "\n",
    "`L_disambig.fst` 파일에 사용되는 `disambiguation symbols`의 정보를 담고 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat data/lang/phones/disambig.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `sets.{txt|int}`\n",
    "\n",
    "`BIES` 표기가 된 phone들을 모아 하나의 `phone`과 연결시켜둔 파일입니다. 즉, 서로 다른 위치에 있는 같은 phone이 결국은 같은 phone이라는 것을 명시해 둔 것입니다. 나중에 pipeline에서 `HMM`을 이용하여 언어 모델을 구축할 때 중요하게 사용될 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head data/lang/phones/sets.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `extra_questions.{txt|int}`\n",
    "\n",
    "phone을 그룹으로 묶는 또다른 방법입니다. \n",
    "\n",
    "**Note:** 이 파일들이 \"questions\"라고 불리는 이유는, acoustic model을 구축할 때, decision tree에서 어떻게 데이터를 분류할지 \"questions\"이 되는 내용이기 때문입니다. \n",
    "\n",
    "이 파일은 position-dependent한 phone들을 서로묶고 있습니다. 즉, `BIES` 각각에 해당하는 음소들을 하나로 묶은 4 개의 리스트와, `silence phone`을 담은 하나의 리스트라고 볼 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat data/lang/phones/extra_questions.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `roots.{txt|int}`\n",
    "\n",
    "이 파일은 phonetic 환경을 모델링하는 decision tree를 구축할 때 유용하게 사용됩니다. \n",
    "\n",
    "Decision tree에 관한 내용은 나중에 다시 살펴보겠습니다. 다음은 `kaldi` 공식 문서에서 이 파일을 설명한 내용입니다. \n",
    "\n",
    "```\n",
    "The significance of having a number of phones on a single line, for example SIL SIL_B SIL_E SIL_I SIL_S, is that all of these phones have a single \"shared root\" in the decision tree, so states may be shared between those phones. For stress and tone-dependent systems, typically all the stress or tone-dependent versions of a particular phone will appear on the same line. In addition, all three states of a HMM (or all five states, for silences) share the root, and the decision-tree building process gets to ask about the state. This sharing of the decision-tree root between the HMM-states is what we mean by \"shared\" in the roots file.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n5 data/lang/phones/roots.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
