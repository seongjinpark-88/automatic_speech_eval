{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1: Confirming `docker` and `kaldi` functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`docker image`에는 앞으로 빈번하게 사용될 `전역 변수 (global variables)`가 설정되어 있습니다. 제대로 설정되어 있는지 `echo` 명령어를 사용하여 확인해보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/kaldi\n",
      "/scratch/kaldi/egs/INSTRUCTIONAL\n"
     ]
    }
   ],
   "source": [
    "echo $KALDI_PATH && echo $KALDI_INSTRUCTIONAL_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `mini_librispeech` `run.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kaldi`가 제대로 설치되었다면 다음의 `run.sh` 파일(`egs` 폴더 내부에 `mini_librispeech` 폴더에 있습니다)을 이용해서 `training`과 `testing` pipeline의 **데모** 버전을 실행해볼 수 있습니다. `run.sh` 파일은 `librispeech` 데이터에서 아주 작은 일부를 가지고 `kaldi`가 제대로 컴파일 되었는지를 확인합니다. 데이터가 크지는 않지만, `run.sh` 파일의 실행이 완료되는데 시간이 조금 걸릴 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/kaldi/egs/mini_librispeech/s5\n"
     ]
    }
   ],
   "source": [
    "cd ../mini_librispeech/s5 && pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`run.sh` 파일의 논항 구조를 확인해볼 수 있으며, 기본값들은 다음과 같습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "# -s stage <int> = which stage to start the script on\n",
      "# -n num_proc <int> = how many processors to use for steps\n",
      "# -c train_cmd <str> = which command to use (run.pl or queue.pl)\n",
      "\n",
      "stage=0\n",
      "num_proc=1\n",
      "train_cmd=run.pl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "head run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각의 `stage` 에서 다루는 내용은 다음과 같습니다. process 중간부터 시작할 경우, `-s` flag를 이용하여 해당하는 `stage`부터 `run.sh` 파일을 실행할 수 있습니다. \n",
    "\n",
    " - stage 0: downloading data\n",
    " - stage 1: preparing `data` directories\n",
    " - stage 2: feature extraction\n",
    " - stage 3: acoustic model - monophones\n",
    " - stage 4: acoustic model - triphones\n",
    " - stage 5: acoustic model - triphones + LDA\n",
    " - stage 6: acoustic model - triphones + LDA + SAT\n",
    " - stage 7: `word error rate` reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 명령어를 수정하여서 원하는 `stage`부터 스크립트를 실행할 수도 있고 (*e.g.,* `-s 4`), 스크립트를 실행하는데 사용할 `threads` 수를 늘릴 수도 있습니다. (*e.g.,* `-n 4`)\n",
    "\n",
    "**Note:** 기본값인 `-n 1`을 사용할 경우, `run.sh` 파일 실행을 완료하는데 최대 `1-2시간` 정도 소요될 수도 있습니다. \n",
    "\n",
    "실행이 완료되면 `word error rate (WER)` (i.e., 원래 문장에서 몇 개의 단어가 잘못 인식되었는지) 이 출력됩니다. \n",
    "\n",
    "**스포일러:** 결과는 생각만큼 좋지 않습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAGE 0: downloading data\n",
      "local/download_and_untar.sh: data part dev-clean-2 was already successfully extracted, nothing to do.\n",
      "local/download_and_untar.sh: data part train-clean-5 was already successfully extracted, nothing to do.\n",
      "Downloading file '3-gram.pruned.3e-7.arpa.gz' into 'data/local/lm'...\n",
      "'3-gram.pruned.3e-7.arpa.gz' already exists and appears to be complete\n",
      "Downloading file 'librispeech-vocab.txt' into 'data/local/lm'...\n",
      "'librispeech-vocab.txt' already exists and appears to be complete\n",
      "Downloading file 'librispeech-lexicon.txt' into 'data/local/lm'...\n",
      "'librispeech-lexicon.txt' already exists and appears to be complete\n",
      "STAGE 1: preparing data directories\n",
      "utils/data/get_utt2dur.sh: segments file does not exist so getting durations from wave files\n",
      "cat: write error: Broken pipe\n",
      "utils/data/get_utt2dur.sh: could not get utterance lengths from sphere-file headers, using wav-to-duration\n",
      "wav-to-duration --read-entire-file=false scp:data/dev_clean_2/wav.scp ark,t:data/dev_clean_2/utt2dur \n",
      "LOG (wav-to-duration[5.2.380~1-8e7d2]:main():wav-to-duration.cc:92) Printed duration for 1089 audio files.\n",
      "LOG (wav-to-duration[5.2.380~1-8e7d2]:main():wav-to-duration.cc:94) Mean duration was 6.72999, min and max durations were 1.505, 31.7\n",
      "utils/data/get_utt2dur.sh: computed data/dev_clean_2/utt2dur\n",
      "Checking data/dev_clean_2/text ...\n",
      "--> reading data/dev_clean_2/text\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory data/dev_clean_2\n",
      "local/data_prep.sh: successfully prepared data in data/dev_clean_2\n",
      "utils/data/get_utt2dur.sh: segments file does not exist so getting durations from wave files\n",
      "cat: write error: Broken pipe\n",
      "utils/data/get_utt2dur.sh: could not get utterance lengths from sphere-file headers, using wav-to-duration\n",
      "wav-to-duration --read-entire-file=false scp:data/train_clean_5/wav.scp ark,t:data/train_clean_5/utt2dur \n",
      "LOG (wav-to-duration[5.2.380~1-8e7d2]:main():wav-to-duration.cc:92) Printed duration for 1519 audio files.\n",
      "LOG (wav-to-duration[5.2.380~1-8e7d2]:main():wav-to-duration.cc:94) Mean duration was 12.5864, min and max durations were 1.87, 17.275\n",
      "utils/data/get_utt2dur.sh: computed data/train_clean_5/utt2dur\n",
      "Checking data/train_clean_5/text ...\n",
      "--> reading data/train_clean_5/text\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory data/train_clean_5\n",
      "local/data_prep.sh: successfully prepared data in data/train_clean_5\n",
      "Preparing phone lists and clustering questions\n",
      "2 silence phones saved to: data/local/dict_nosp/silence_phones.txt\n",
      "1 optional silence saved to: data/local/dict_nosp/optional_silence.txt\n",
      "39 non-silence phones saved to: data/local/dict_nosp/nonsilence_phones.txt\n",
      "5 extra triphone clustering-related questions saved to: data/local/dict_nosp/extra_questions.txt\n",
      "Lexicon text file saved as: data/local/dict_nosp/lexicon.txt\n",
      "utils/prepare_lang.sh data/local/dict_nosp <UNK> data/local/lang_tmp_nosp data/lang_nosp\n",
      "Checking data/local/dict_nosp/silence_phones.txt ...\n",
      "--> reading data/local/dict_nosp/silence_phones.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/local/dict_nosp/silence_phones.txt is OK\n",
      "\n",
      "Checking data/local/dict_nosp/optional_silence.txt ...\n",
      "--> reading data/local/dict_nosp/optional_silence.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/local/dict_nosp/optional_silence.txt is OK\n",
      "\n",
      "Checking data/local/dict_nosp/nonsilence_phones.txt ...\n",
      "--> reading data/local/dict_nosp/nonsilence_phones.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/local/dict_nosp/nonsilence_phones.txt is OK\n",
      "\n",
      "Checking disjoint: silence_phones.txt, nonsilence_phones.txt\n",
      "--> disjoint property is OK.\n",
      "\n",
      "Checking data/local/dict_nosp/lexicon.txt\n",
      "--> reading data/local/dict_nosp/lexicon.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/local/dict_nosp/lexicon.txt is OK\n",
      "\n",
      "Checking data/local/dict_nosp/lexiconp.txt\n",
      "--> reading data/local/dict_nosp/lexiconp.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/local/dict_nosp/lexiconp.txt is OK\n",
      "\n",
      "Checking lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt\n",
      "--> lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt match\n",
      "\n",
      "Checking data/local/dict_nosp/extra_questions.txt ...\n",
      "--> reading data/local/dict_nosp/extra_questions.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/local/dict_nosp/extra_questions.txt is OK\n",
      "--> SUCCESS [validating dictionary directory data/local/dict_nosp]\n",
      "\n",
      "fstaddselfloops data/lang_nosp/phones/wdisambig_phones.int data/lang_nosp/phones/wdisambig_words.int \n",
      "prepare_lang.sh: validating output directory\n",
      "utils/validate_lang.pl data/lang_nosp\n",
      "Checking data/lang_nosp/phones.txt ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/lang_nosp/phones.txt is OK\n",
      "\n",
      "Checking words.txt: #0 ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/lang_nosp/words.txt is OK\n",
      "\n",
      "Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> silence.txt and nonsilence.txt are disjoint\n",
      "--> silence.txt and disambig.txt are disjoint\n",
      "--> disambig.txt and nonsilence.txt are disjoint\n",
      "--> disjoint property is OK\n",
      "\n",
      "Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> summation property is OK\n",
      "\n",
      "Checking data/lang_nosp/phones/context_indep.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 10 entry/entries in data/lang_nosp/phones/context_indep.txt\n",
      "--> data/lang_nosp/phones/context_indep.int corresponds to data/lang_nosp/phones/context_indep.txt\n",
      "--> data/lang_nosp/phones/context_indep.csl corresponds to data/lang_nosp/phones/context_indep.txt\n",
      "--> data/lang_nosp/phones/context_indep.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_nosp/phones/nonsilence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 336 entry/entries in data/lang_nosp/phones/nonsilence.txt\n",
      "--> data/lang_nosp/phones/nonsilence.int corresponds to data/lang_nosp/phones/nonsilence.txt\n",
      "--> data/lang_nosp/phones/nonsilence.csl corresponds to data/lang_nosp/phones/nonsilence.txt\n",
      "--> data/lang_nosp/phones/nonsilence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_nosp/phones/silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 10 entry/entries in data/lang_nosp/phones/silence.txt\n",
      "--> data/lang_nosp/phones/silence.int corresponds to data/lang_nosp/phones/silence.txt\n",
      "--> data/lang_nosp/phones/silence.csl corresponds to data/lang_nosp/phones/silence.txt\n",
      "--> data/lang_nosp/phones/silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_nosp/phones/optional_silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in data/lang_nosp/phones/optional_silence.txt\n",
      "--> data/lang_nosp/phones/optional_silence.int corresponds to data/lang_nosp/phones/optional_silence.txt\n",
      "--> data/lang_nosp/phones/optional_silence.csl corresponds to data/lang_nosp/phones/optional_silence.txt\n",
      "--> data/lang_nosp/phones/optional_silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_nosp/phones/disambig.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 17 entry/entries in data/lang_nosp/phones/disambig.txt\n",
      "--> data/lang_nosp/phones/disambig.int corresponds to data/lang_nosp/phones/disambig.txt\n",
      "--> data/lang_nosp/phones/disambig.csl corresponds to data/lang_nosp/phones/disambig.txt\n",
      "--> data/lang_nosp/phones/disambig.{txt, int, csl} are OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking data/lang_nosp/phones/roots.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 41 entry/entries in data/lang_nosp/phones/roots.txt\n",
      "--> data/lang_nosp/phones/roots.int corresponds to data/lang_nosp/phones/roots.txt\n",
      "--> data/lang_nosp/phones/roots.{txt, int} are OK\n",
      "\n",
      "Checking data/lang_nosp/phones/sets.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 41 entry/entries in data/lang_nosp/phones/sets.txt\n",
      "--> data/lang_nosp/phones/sets.int corresponds to data/lang_nosp/phones/sets.txt\n",
      "--> data/lang_nosp/phones/sets.{txt, int} are OK\n",
      "\n",
      "Checking data/lang_nosp/phones/extra_questions.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 14 entry/entries in data/lang_nosp/phones/extra_questions.txt\n",
      "--> data/lang_nosp/phones/extra_questions.int corresponds to data/lang_nosp/phones/extra_questions.txt\n",
      "--> data/lang_nosp/phones/extra_questions.{txt, int} are OK\n",
      "\n",
      "Checking data/lang_nosp/phones/word_boundary.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 346 entry/entries in data/lang_nosp/phones/word_boundary.txt\n",
      "--> data/lang_nosp/phones/word_boundary.int corresponds to data/lang_nosp/phones/word_boundary.txt\n",
      "--> data/lang_nosp/phones/word_boundary.{txt, int} are OK\n",
      "\n",
      "Checking optional_silence.txt ...\n",
      "--> reading data/lang_nosp/phones/optional_silence.txt\n",
      "--> data/lang_nosp/phones/optional_silence.txt is OK\n",
      "\n",
      "Checking disambiguation symbols: #0 and #1\n",
      "--> data/lang_nosp/phones/disambig.txt has \"#0\" and \"#1\"\n",
      "--> data/lang_nosp/phones/disambig.txt is OK\n",
      "\n",
      "Checking topo ...\n",
      "\n",
      "Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> data/lang_nosp/phones/word_boundary.txt doesn't include disambiguation symbols\n",
      "--> data/lang_nosp/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt\n",
      "--> data/lang_nosp/phones/word_boundary.txt is OK\n",
      "\n",
      "Checking word-level disambiguation symbols...\n",
      "--> data/lang_nosp/phones/wdisambig.txt exists (newer prepare_lang.sh)\n",
      "Checking word_boundary.int and disambig.int\n",
      "--> generating a 92 word sequence\n",
      "--> resulting phone sequence from L.fst corresponds to the word sequence\n",
      "--> L.fst is OK\n",
      "--> generating a 6 word sequence\n",
      "--> resulting phone sequence from L_disambig.fst corresponds to the word sequence\n",
      "--> L_disambig.fst is OK\n",
      "\n",
      "Checking data/lang_nosp/oov.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in data/lang_nosp/oov.txt\n",
      "--> data/lang_nosp/oov.int corresponds to data/lang_nosp/oov.txt\n",
      "--> data/lang_nosp/oov.{txt, int} are OK\n",
      "\n",
      "--> data/lang_nosp/L.fst is olabel sorted\n",
      "--> data/lang_nosp/L_disambig.fst is olabel sorted\n",
      "--> SUCCESS [validating lang directory data/lang_nosp]\n",
      "arpa2fst --disambig-symbol=#0 --read-symbol-table=data/lang_nosp_test_tgsmall/words.txt - data/lang_nosp_test_tgsmall/G.fst \n",
      "LOG (arpa2fst[5.2.380~1-8e7d2]:Read():arpa-file-parser.cc:98) Reading \\data\\ section.\n",
      "LOG (arpa2fst[5.2.380~1-8e7d2]:Read():arpa-file-parser.cc:153) Reading \\1-grams: section.\n",
      "LOG (arpa2fst[5.2.380~1-8e7d2]:Read():arpa-file-parser.cc:153) Reading \\2-grams: section.\n",
      "LOG (arpa2fst[5.2.380~1-8e7d2]:Read():arpa-file-parser.cc:153) Reading \\3-grams: section.\n",
      "LOG (arpa2fst[5.2.380~1-8e7d2]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 1183418 to 249533\n",
      "utils/validate_lang.pl data/lang_nosp_test_tgsmall\n",
      "Checking data/lang_nosp_test_tgsmall/phones.txt ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/lang_nosp_test_tgsmall/phones.txt is OK\n",
      "\n",
      "Checking words.txt: #0 ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/lang_nosp_test_tgsmall/words.txt is OK\n",
      "\n",
      "Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> silence.txt and nonsilence.txt are disjoint\n",
      "--> silence.txt and disambig.txt are disjoint\n",
      "--> disambig.txt and nonsilence.txt are disjoint\n",
      "--> disjoint property is OK\n",
      "\n",
      "Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> summation property is OK\n",
      "\n",
      "Checking data/lang_nosp_test_tgsmall/phones/context_indep.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 10 entry/entries in data/lang_nosp_test_tgsmall/phones/context_indep.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/context_indep.int corresponds to data/lang_nosp_test_tgsmall/phones/context_indep.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/context_indep.csl corresponds to data/lang_nosp_test_tgsmall/phones/context_indep.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/context_indep.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_nosp_test_tgsmall/phones/nonsilence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 336 entry/entries in data/lang_nosp_test_tgsmall/phones/nonsilence.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/nonsilence.int corresponds to data/lang_nosp_test_tgsmall/phones/nonsilence.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/nonsilence.csl corresponds to data/lang_nosp_test_tgsmall/phones/nonsilence.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/nonsilence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_nosp_test_tgsmall/phones/silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 10 entry/entries in data/lang_nosp_test_tgsmall/phones/silence.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/silence.int corresponds to data/lang_nosp_test_tgsmall/phones/silence.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/silence.csl corresponds to data/lang_nosp_test_tgsmall/phones/silence.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_nosp_test_tgsmall/phones/optional_silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in data/lang_nosp_test_tgsmall/phones/optional_silence.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/optional_silence.int corresponds to data/lang_nosp_test_tgsmall/phones/optional_silence.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/optional_silence.csl corresponds to data/lang_nosp_test_tgsmall/phones/optional_silence.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/optional_silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_nosp_test_tgsmall/phones/disambig.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 17 entry/entries in data/lang_nosp_test_tgsmall/phones/disambig.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/disambig.int corresponds to data/lang_nosp_test_tgsmall/phones/disambig.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/disambig.csl corresponds to data/lang_nosp_test_tgsmall/phones/disambig.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/disambig.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang_nosp_test_tgsmall/phones/roots.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 41 entry/entries in data/lang_nosp_test_tgsmall/phones/roots.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/roots.int corresponds to data/lang_nosp_test_tgsmall/phones/roots.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/roots.{txt, int} are OK\n",
      "\n",
      "Checking data/lang_nosp_test_tgsmall/phones/sets.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 41 entry/entries in data/lang_nosp_test_tgsmall/phones/sets.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/sets.int corresponds to data/lang_nosp_test_tgsmall/phones/sets.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/sets.{txt, int} are OK\n",
      "\n",
      "Checking data/lang_nosp_test_tgsmall/phones/extra_questions.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 14 entry/entries in data/lang_nosp_test_tgsmall/phones/extra_questions.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> data/lang_nosp_test_tgsmall/phones/extra_questions.int corresponds to data/lang_nosp_test_tgsmall/phones/extra_questions.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/extra_questions.{txt, int} are OK\n",
      "\n",
      "Checking data/lang_nosp_test_tgsmall/phones/word_boundary.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 346 entry/entries in data/lang_nosp_test_tgsmall/phones/word_boundary.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/word_boundary.int corresponds to data/lang_nosp_test_tgsmall/phones/word_boundary.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/word_boundary.{txt, int} are OK\n",
      "\n",
      "Checking optional_silence.txt ...\n",
      "--> reading data/lang_nosp_test_tgsmall/phones/optional_silence.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/optional_silence.txt is OK\n",
      "\n",
      "Checking disambiguation symbols: #0 and #1\n",
      "--> data/lang_nosp_test_tgsmall/phones/disambig.txt has \"#0\" and \"#1\"\n",
      "--> data/lang_nosp_test_tgsmall/phones/disambig.txt is OK\n",
      "\n",
      "Checking topo ...\n",
      "\n",
      "Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> data/lang_nosp_test_tgsmall/phones/word_boundary.txt doesn't include disambiguation symbols\n",
      "--> data/lang_nosp_test_tgsmall/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt\n",
      "--> data/lang_nosp_test_tgsmall/phones/word_boundary.txt is OK\n",
      "\n",
      "Checking word-level disambiguation symbols...\n",
      "--> data/lang_nosp_test_tgsmall/phones/wdisambig.txt exists (newer prepare_lang.sh)\n",
      "Checking word_boundary.int and disambig.int\n",
      "--> generating a 7 word sequence\n",
      "--> resulting phone sequence from L.fst corresponds to the word sequence\n",
      "--> L.fst is OK\n",
      "--> generating a 33 word sequence\n",
      "--> resulting phone sequence from L_disambig.fst corresponds to the word sequence\n",
      "--> L_disambig.fst is OK\n",
      "\n",
      "Checking data/lang_nosp_test_tgsmall/oov.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in data/lang_nosp_test_tgsmall/oov.txt\n",
      "--> data/lang_nosp_test_tgsmall/oov.int corresponds to data/lang_nosp_test_tgsmall/oov.txt\n",
      "--> data/lang_nosp_test_tgsmall/oov.{txt, int} are OK\n",
      "\n",
      "--> data/lang_nosp_test_tgsmall/L.fst is olabel sorted\n",
      "--> data/lang_nosp_test_tgsmall/L_disambig.fst is olabel sorted\n",
      "--> data/lang_nosp_test_tgsmall/G.fst is ilabel sorted\n",
      "--> data/lang_nosp_test_tgsmall/G.fst has 249533 states\n",
      "--> utils/lang/check_g_properties.pl successfully validated data/lang_nosp_test_tgsmall/G.fst\n",
      "--> utils/lang/check_g_properties.pl succeeded.\n",
      "--> SUCCESS [validating lang directory data/lang_nosp_test_tgsmall]\n",
      "Succeeded in formatting data.\n",
      "STAGE 2: feature extraction\n",
      "steps/make_mfcc.sh --cmd run.pl --nj 3 data/dev_clean_2 exp/make_mfcc/dev_clean_2 mfcc\n",
      "Checking data/dev_clean_2/text ...\n",
      "--> reading data/dev_clean_2/text\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory data/dev_clean_2\n",
      "steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.\n",
      "Succeeded creating MFCC features for dev_clean_2\n",
      "steps/compute_cmvn_stats.sh data/dev_clean_2 exp/make_mfcc/dev_clean_2 mfcc\n",
      "Succeeded creating CMVN stats for dev_clean_2\n",
      "steps/make_mfcc.sh --cmd run.pl --nj 3 data/train_clean_5 exp/make_mfcc/train_clean_5 mfcc\n",
      "Checking data/train_clean_5/text ...\n",
      "--> reading data/train_clean_5/text\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory data/train_clean_5\n",
      "steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.\n",
      "Succeeded creating MFCC features for train_clean_5\n",
      "steps/compute_cmvn_stats.sh data/train_clean_5 exp/make_mfcc/train_clean_5 mfcc\n",
      "Succeeded creating CMVN stats for train_clean_5\n",
      "feat-to-len scp:data/train_clean_5/feats.scp ark,t:data/train_500short/tmp.len \n",
      "awk: write failure (Broken pipe)\n",
      "awk: close failed on file /dev/stdout (Broken pipe)\n",
      "utils/subset_data_dir.sh: reducing #utt from 1519 to 500\n",
      "feat-to-len scp:data/dev_clean_2/feats.scp ark,t:data/dev_40short/tmp.len \n",
      "awk: write failure (Broken pipe)\n",
      "utils/subset_data_dir.sh: reducing #utt from 1089 to 40\n",
      "STAGE 3: acoustic model - monophones\n",
      "steps/train_mono.sh --nj 3 --cmd run.pl --num_iters 2 --totgauss 500 data/train_500short data/lang_nosp exp/mono\n",
      "steps/train_mono.sh: Initializing monophone system.\n",
      "steps/train_mono.sh: Compiling training graphs\n",
      "steps/train_mono.sh: Aligning data equally (pass 0)\n",
      "steps/train_mono.sh: Pass 1\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/mono\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence SIL is seen only 8.41683366733% of the time at utterance begin.  This may not be optimal.\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence SIL is seen only 15.4308617234% of the time at utterance end.  This may not be optimal.\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/mono/log/analyze_alignments.log\n",
      "2 warnings in exp/mono/log/update.*.log\n",
      "136 warnings in exp/mono/log/align.*.*.log\n",
      "2 warnings in exp/mono/log/analyze_alignments.log\n",
      "1 warnings in exp/mono/log/acc.*.*.log\n",
      "6 warnings in exp/mono/log/init.log\n",
      "exp/mono: nj=3 align prob=-110.26 over 1.15h [retry=26.4%, fail=0.2%] states=127 gauss=127\n",
      "steps/train_mono.sh: Done training monophone system in exp/mono\n",
      "tree-info exp/mono/tree \n",
      "tree-info exp/mono/tree \n",
      "fstminimizeencoded \n",
      "fstpushspecial \n",
      "fstdeterminizestar --use-log=true \n",
      "fsttablecompose data/lang_nosp_test_tgsmall/L_disambig.fst data/lang_nosp_test_tgsmall/G.fst \n",
      "fstisstochastic data/lang_nosp_test_tgsmall/tmp/LG.fst \n",
      "-0.0783017 -0.0789139\n",
      "[info]: LG not stochastic.\n",
      "fstcomposecontext --context-size=1 --central-position=0 --read-disambig-syms=data/lang_nosp_test_tgsmall/phones/disambig.int --write-disambig-syms=data/lang_nosp_test_tgsmall/tmp/disambig_ilabels_1_0.int data/lang_nosp_test_tgsmall/tmp/ilabels_1_0.9996 \n",
      "fstisstochastic data/lang_nosp_test_tgsmall/tmp/CLG_1_0.fst \n",
      "-0.0783017 -0.0789139\n",
      "[info]: CLG not stochastic.\n",
      "make-h-transducer --disambig-syms-out=exp/mono/graph_nosp_tgsmall/disambig_tid.int --transition-scale=1.0 data/lang_nosp_test_tgsmall/tmp/ilabels_1_0 exp/mono/tree exp/mono/final.mdl \n",
      "fstminimizeencoded \n",
      "fsttablecompose exp/mono/graph_nosp_tgsmall/Ha.fst data/lang_nosp_test_tgsmall/tmp/CLG_1_0.fst \n",
      "fstrmepslocal \n",
      "fstdeterminizestar --use-log=true \n",
      "fstrmsymbols exp/mono/graph_nosp_tgsmall/disambig_tid.int \n",
      "fstisstochastic exp/mono/graph_nosp_tgsmall/HCLGa.fst \n",
      "0.000374027 -0.157611\n",
      "HCLGa is not stochastic\n",
      "add-self-loops --self-loop-scale=0.1 --reorder=true exp/mono/final.mdl \n",
      "steps/decode.sh --nj 3 --cmd run.pl exp/mono/graph_nosp_tgsmall data/dev_40short exp/mono/decode_nosp_tgsmall_dev_40short\n",
      "decode.sh: feature type is delta\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/mono/graph_nosp_tgsmall exp/mono/decode_nosp_tgsmall_dev_40short\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_nosp_tgsmall_dev_40short/log/analyze_alignments.log\n",
      "Overall, lattice depth (10,50,90-percentile)=(28,111,390) and mean=174.7\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_nosp_tgsmall_dev_40short/log/analyze_lattice_depth_stats.log\n",
      "STAGE 4: acoustic model - triphones\n",
      "steps/align_si.sh --nj 3 --cmd run.pl data/train_500short data/lang_nosp exp/mono exp/mono_ali_train_500short\n",
      "steps/align_si.sh: feature type is delta\n",
      "steps/align_si.sh: aligning data in data/train_500short using model from exp/mono, putting alignments in exp/mono_ali_train_500short\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/mono_ali_train_500short\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/mono_ali_train_500short/log/analyze_alignments.log\n",
      "steps/align_si.sh: done aligning data.\n",
      "steps/train_deltas.sh --cmd run.pl --num_iters 2 2000 10000 data/train_500short data/lang_nosp exp/mono_ali_train_500short exp/tri1\n",
      "steps/train_deltas.sh: accumulating tree stats\n",
      "steps/train_deltas.sh: getting questions for tree-building, via clustering\n",
      "steps/train_deltas.sh: building the tree\n",
      "steps/train_deltas.sh: converting alignments from exp/mono_ali_train_500short to use current tree\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps/train_deltas.sh: compiling graphs of transcripts\n",
      "steps/train_deltas.sh: training pass 1\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri1\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1/log/analyze_alignments.log\n",
      "2 warnings in exp/tri1/log/update.*.log\n",
      "1 warnings in exp/tri1/log/compile_questions.log\n",
      "114 warnings in exp/tri1/log/init_model.log\n",
      "1 warnings in exp/tri1/log/build_tree.log\n",
      "exp/tri1: nj=3 1.15h data log-like=-102.09 states=872 gauss=2002 tree-impr=3.40\n",
      "steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1\n",
      "tree-info exp/tri1/tree \n",
      "tree-info exp/tri1/tree \n",
      "fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=data/lang_nosp_test_tgsmall/phones/disambig.int --write-disambig-syms=data/lang_nosp_test_tgsmall/tmp/disambig_ilabels_3_1.int data/lang_nosp_test_tgsmall/tmp/ilabels_3_1.11657 \n",
      "fstisstochastic data/lang_nosp_test_tgsmall/tmp/CLG_3_1.fst \n",
      "0 -0.0789139\n",
      "[info]: CLG not stochastic.\n",
      "make-h-transducer --disambig-syms-out=exp/tri1/graph_nosp_tgsmall/disambig_tid.int --transition-scale=1.0 data/lang_nosp_test_tgsmall/tmp/ilabels_3_1 exp/tri1/tree exp/tri1/final.mdl \n",
      "fstrmepslocal \n",
      "fsttablecompose exp/tri1/graph_nosp_tgsmall/Ha.fst data/lang_nosp_test_tgsmall/tmp/CLG_3_1.fst \n",
      "fstdeterminizestar --use-log=true \n",
      "fstrmsymbols exp/tri1/graph_nosp_tgsmall/disambig_tid.int \n",
      "fstminimizeencoded \n",
      "fstisstochastic exp/tri1/graph_nosp_tgsmall/HCLGa.fst \n",
      "0.000488052 -0.224942\n",
      "HCLGa is not stochastic\n",
      "add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri1/final.mdl \n",
      "steps/decode.sh --nj 3 --cmd run.pl exp/tri1/graph_nosp_tgsmall data/dev_40short exp/tri1/decode_nosp_tgsmall_dev_40short\n",
      "decode.sh: feature type is delta\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri1/graph_nosp_tgsmall exp/tri1/decode_nosp_tgsmall_dev_40short\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri1/decode_nosp_tgsmall_dev_40short/log/analyze_alignments.log\n",
      "Overall, lattice depth (10,50,90-percentile)=(4,46,180) and mean=72.5\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri1/decode_nosp_tgsmall_dev_40short/log/analyze_lattice_depth_stats.log\n",
      "STAGE 5: acoustic model - triphones + LDA\n",
      "steps/align_si.sh --nj 3 --cmd run.pl data/train_500short data/lang_nosp exp/tri1 exp/tri1_ali_train_500short\n",
      "steps/align_si.sh: feature type is delta\n",
      "steps/align_si.sh: aligning data in data/train_500short using model from exp/tri1, putting alignments in exp/tri1_ali_train_500short\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri1_ali_train_500short\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1_ali_train_500short/log/analyze_alignments.log\n",
      "steps/align_si.sh: done aligning data.\n",
      "steps/train_lda_mllt.sh --cmd run.pl --num_iters 2 --splice-opts --left-context=3 --right-context=3 2500 15000 data/train_500short data/lang_nosp exp/tri1_ali_train_500short exp/tri2b\n",
      "steps/train_lda_mllt.sh: Accumulating LDA statistics.\n",
      "steps/train_lda_mllt.sh: Accumulating tree stats\n",
      "steps/train_lda_mllt.sh: Getting questions for tree clustering.\n",
      "steps/train_lda_mllt.sh: Building the tree\n",
      "steps/train_lda_mllt.sh: Initializing the model\n",
      "steps/train_lda_mllt.sh: Converting alignments from exp/tri1_ali_train_500short to use current tree\n",
      "steps/train_lda_mllt.sh: Compiling graphs of transcripts\n",
      "Training pass 1\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri2b\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b/log/analyze_alignments.log\n",
      "271 warnings in exp/tri2b/log/init_model.log\n",
      "4 warnings in exp/tri2b/log/update.*.log\n",
      "1 warnings in exp/tri2b/log/build_tree.log\n",
      "1 warnings in exp/tri2b/log/compile_questions.log\n",
      "exp/tri2b: nj=3 1.15h data log-like=-52.42 states=1230 gauss=2500 tree-impr=4.33 lda-sum=15.89\n",
      "steps/train_lda_mllt.sh: Done training system with LDA+MLLT features in exp/tri2b\n",
      "tree-info exp/tri2b/tree \n",
      "tree-info exp/tri2b/tree \n",
      "make-h-transducer --disambig-syms-out=exp/tri2b/graph_nosp_tgsmall/disambig_tid.int --transition-scale=1.0 data/lang_nosp_test_tgsmall/tmp/ilabels_3_1 exp/tri2b/tree exp/tri2b/final.mdl \n",
      "fsttablecompose exp/tri2b/graph_nosp_tgsmall/Ha.fst data/lang_nosp_test_tgsmall/tmp/CLG_3_1.fst \n",
      "fstdeterminizestar --use-log=true \n",
      "fstrmsymbols exp/tri2b/graph_nosp_tgsmall/disambig_tid.int \n",
      "fstrmepslocal \n",
      "fstminimizeencoded \n",
      "fstisstochastic exp/tri2b/graph_nosp_tgsmall/HCLGa.fst \n",
      "0.000488052 -0.224942\n",
      "HCLGa is not stochastic\n",
      "add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri2b/final.mdl \n",
      "steps/decode.sh --nj 3 --cmd run.pl exp/tri2b/graph_nosp_tgsmall data/dev_40short exp/tri2b/decode_nosp_tgsmall_dev_40short\n",
      "decode.sh: feature type is lda\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri2b/graph_nosp_tgsmall exp/tri2b/decode_nosp_tgsmall_dev_40short\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri2b/decode_nosp_tgsmall_dev_40short/log/analyze_alignments.log\n",
      "Overall, lattice depth (10,50,90-percentile)=(2,18,109) and mean=41.7\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri2b/decode_nosp_tgsmall_dev_40short/log/analyze_lattice_depth_stats.log\n",
      "STAGE 6: acoustic model - triphones + LDA + SAT\n",
      "steps/align_si.sh --nj 3 --cmd run.pl --use-graphs true data/train_clean_5 data/lang_nosp exp/tri2b exp/tri2b_ali_train_500short\n",
      "steps/align_si.sh: feature type is lda\n",
      "steps/align_si.sh: aligning data in data/train_clean_5 using model from exp/tri2b, putting alignments in exp/tri2b_ali_train_500short\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri2b_ali_train_500short\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b_ali_train_500short/log/analyze_alignments.log\n",
      "steps/align_si.sh: done aligning data.\n",
      "steps/train_sat.sh --cmd run.pl --num_iters 2 2500 15000 data/train_500short data/lang_nosp exp/tri2b_ali_train_500short exp/tri3b\n",
      "steps/train_sat.sh: feature type is lda\n",
      "steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri2b_ali_train_500short\n",
      "steps/train_sat.sh: Accumulating tree stats\n",
      "steps/train_sat.sh: Getting questions for tree clustering.\n",
      "steps/train_sat.sh: Building the tree\n",
      "steps/train_sat.sh: Initializing the model\n",
      "steps/train_sat.sh: Converting alignments from exp/tri2b_ali_train_500short to use current tree\n",
      "steps/train_sat.sh: Compiling graphs of transcripts\n",
      "Pass 1\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri3b\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3b/log/analyze_alignments.log\n",
      "1 warnings in exp/tri3b/log/build_tree.log\n",
      "297 warnings in exp/tri3b/log/init_model.log\n",
      "5 warnings in exp/tri3b/log/update.*.log\n",
      "16 warnings in exp/tri3b/log/fmllr.*.*.log\n",
      "5 warnings in exp/tri3b/log/est_alimdl.log\n",
      "15 warnings in exp/tri3b/log/acc.*.*.log\n",
      "1 warnings in exp/tri3b/log/compile_questions.log\n",
      "steps/train_sat.sh: Likelihood evolution:\n",
      "-48.3521 \n",
      "exp/tri3b: nj=3 1.12h data log-like=-51.00 states=1344 gauss=2500 fmllr-impr=2.88 over 0.91h tree-impr=5.79\n",
      "steps/train_sat.sh: done training SAT system in exp/tri3b\n",
      "tree-info exp/tri3b/tree \n",
      "tree-info exp/tri3b/tree \n",
      "make-h-transducer --disambig-syms-out=exp/tri3b/graph_nosp_tgsmall/disambig_tid.int --transition-scale=1.0 data/lang_nosp_test_tgsmall/tmp/ilabels_3_1 exp/tri3b/tree exp/tri3b/final.mdl \n",
      "fstrmepslocal \n",
      "fstdeterminizestar --use-log=true \n",
      "fstminimizeencoded \n",
      "fstrmsymbols exp/tri3b/graph_nosp_tgsmall/disambig_tid.int \n",
      "fsttablecompose exp/tri3b/graph_nosp_tgsmall/Ha.fst data/lang_nosp_test_tgsmall/tmp/CLG_3_1.fst \n",
      "fstisstochastic exp/tri3b/graph_nosp_tgsmall/HCLGa.fst \n",
      "0.000488052 -0.224942\n",
      "HCLGa is not stochastic\n",
      "add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri3b/final.mdl \n",
      "steps/decode_fmllr.sh --nj 3 --cmd run.pl exp/tri3b/graph_nosp_tgsmall data/dev_40short exp/tri3b/decode_nosp_tgsmall_dev_40short\n",
      "steps/decode.sh --scoring-opts  --num-threads 1 --skip-scoring false --acwt 0.083333 --nj 3 --cmd run.pl --beam 10.0 --model exp/tri3b/final.alimdl --max-active 2000 exp/tri3b/graph_nosp_tgsmall data/dev_40short exp/tri3b/decode_nosp_tgsmall_dev_40short.si\n",
      "decode.sh: feature type is lda\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri3b/graph_nosp_tgsmall exp/tri3b/decode_nosp_tgsmall_dev_40short.si\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_nosp_tgsmall_dev_40short.si/log/analyze_alignments.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall, lattice depth (10,50,90-percentile)=(2,11,50) and mean=20.5\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_nosp_tgsmall_dev_40short.si/log/analyze_lattice_depth_stats.log\n",
      "steps/decode_fmllr.sh: feature type is lda\n",
      "steps/decode_fmllr.sh: getting first-pass fMLLR transforms.\n",
      "steps/decode_fmllr.sh: doing main lattice generation phase\n",
      "steps/decode_fmllr.sh: estimating fMLLR transforms a second time.\n",
      "steps/decode_fmllr.sh: doing a final pass of acoustic rescoring.\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri3b/graph_nosp_tgsmall exp/tri3b/decode_nosp_tgsmall_dev_40short\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_nosp_tgsmall_dev_40short/log/analyze_alignments.log\n",
      "Overall, lattice depth (10,50,90-percentile)=(1,7,89) and mean=35.6\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_nosp_tgsmall_dev_40short/log/analyze_lattice_depth_stats.log\n",
      "STAGE 7: word error rate reporting\n",
      "Best results for mono:\n",
      "WER: 94.05 [ 174 / 185, 6 ins, 72 del, 96 sub ] exp/mono/decode_nosp_tgsmall_dev_40short/wer_11_0.0\n",
      "SER: 95.00 [ 38 / 40 ]\n",
      "-----\n",
      "Best results for tri1:\n",
      "WER: 59.46 [ 110 / 185, 8 ins, 22 del, 80 sub ] exp/tri1/decode_nosp_tgsmall_dev_40short/wer_10_0.0\n",
      "SER: 80.00 [ 32 / 40 ]\n",
      "-----\n",
      "Best results for tri2b:\n",
      "WER: 50.81 [ 94 / 185, 6 ins, 21 del, 67 sub ] exp/tri2b/decode_nosp_tgsmall_dev_40short/wer_12_0.0\n",
      "SER: 80.00 [ 32 / 40 ]\n",
      "-----\n",
      "Best results for tri3b:\n",
      "WER: 46.49 [ 86 / 185, 5 ins, 27 del, 54 sub ] exp/tri3b/decode_nosp_tgsmall_dev_40short/wer_12_0.5\n",
      "SER: 75.00 [ 30 / 40 ]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "./run.sh -n 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 `jupyter notebook`부터 `kaldi`에서 사용하는 파일들을 자세하게 살펴보고, 내부 디렉토리가 어떻게 구성되었는지도 살펴볼 것입니다. 하지만 지금 미리 한 번 훑어보고 싶으시다면, `mini_librespeech/s5`에 새로 생성된 다음 세 개의 디렉토리를 확인하시면 됩니다. \n",
    "\n",
    " - `data`: 오디오 파일과 언어 모델 (language model)이 저장되는 장소입니다. \n",
    " - `mfcc`: 오디오에서 추출된 특성들이 저장되는 장소입니다.\n",
    " - `exp`: `exp`eriment의 약자로, 각각의 음향 모델에 해당하는 파일들이 저장되는 장소입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
