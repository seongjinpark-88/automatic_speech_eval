{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ". ${KALDI_INSTRUCTIONAL_PATH}/path.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.11: Examining the acoustic models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acoustic model만 따로 떼어내어서 그 성능을 확인하는 간편한 방법은 없습니다. 실제로 할 수 있는 최선의 방법은 우리가 생성한 acoustic model의 두 측면을 살펴보는 것입니다. \n",
    " 1. acoustic model에 필요한 phone의 갯수와 `decision tree`의 크기/형태의 관계\n",
    " 2. `num_leaves`와 `num_gaussians`가 acoustic model에 끼치는 영향"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 `tree`와 `*.mld` 파일을 통해서 각각을 살펴보도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## understanding the `tree` file\n",
    "\n",
    "`tree` 파일은 acoustic training 과정에서 생성되는 **decision tree**를 바이너리 형태로 저장해 둔 파일입니다. 이 `tree`에는 어떠한 `phone`이 서로 그룹으로 묶여있는지(*e.g.,* \"state-tied\")에 관한 정보를 담고 있어서, 전체 모델 구성에 필요한 공간을 절약할 수 있게 도와줍니다.\n",
    "\n",
    "마지막에는 각각의 `leaf`가 probability distribution(`pdf`)를 나타내고, `tree`의 역할은 적절한 `phone`들을 하나의 그룹으로 묶어주는 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tree-info`\n",
    "\n",
    "`tree-info` 기능을 사용하여서 `decision` `tree`와 관련된 정보들을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree-info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree-info exp/monophones/tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`num-pdfs`는 `tree`에서 최종적으로 얻을 수 있는 `distribution`의 갯수입니다. 결국 몇 개의 `leaves`를 가지게 될지를 나타냅니다. \n",
    "\n",
    "`context-width`는 몇 개의 `phone`을 \"context\"로 취급할지를 나타냅니다. `central-position`은 중심 phone을 무엇으로 정할지, 그리고 어떠한 것들이 \"context\" phone이 될지를 나타냅니다. 위의 tree는 `monophones`에서 생성되었기 때문에, width는 `1`이 되고, `central-position`은 `0`이 됩니다. `triphone`의 `tree`와 비교해보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree-info exp/triphones/tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제는 `width`가 3으로 설정되어 있습니다. 즉, 중심 phone 양 쪽에 하나씩 phone이 위치한다는 것입니다. 그러므로 `central-position`은 두 번째 phone이 됩니다. (`index`의 시작이 항상 `0`이라는 것을 기억하세요.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `num_leaves` in relation to `num-pdfs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hyperparameters` 중 `num_leaves`라는 것이 있었습니다. 이것은 `tree`가 생성할 `leaves`의 대략적인 갯수를 정해주는 것입니다. \n",
    "\n",
    "일반적으로 `decision tree`의 `일반화(generalization)`와 `오버피팅(over-fitting)` 사이에는 trade-off가 존재합니다. 만약 `leaves`의 갯수를 데이터 포인트의 갯수와 동일하게 설정을 한다면 주어진 데이터에는 완벽하게 작동할 수도 있지만, 새로운 데이터에는 제대로 작동하지 못하는 `over-fitting`이 발생하게 됩니다. 반대의 경우로 오직 하나의 `leaf`만 가지게 설정을 한다면, `일반화(generalization)`을 최대화 할 수 있습니다. \n",
    "\n",
    "**Note:** 이러한 관계는 나중에 다시 살펴보도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 쉽게 살펴볼 수 있는 부분은 구축한 `tree`가 유사한 phone들을 얼마나 잘 `clustering` 했는지 확인하는 것입니다. \n",
    "\n",
    "각각의 phone은 3-state `HMM`으로 나타납니다. `SIL`은 주로 5-state `HMM`으로 구성되지만, 편의상 3-state으로 간주하도록 하겠습니다. \n",
    "\n",
    "그러므로 `monophone`의 경우, 모델은 $num\\_phones * 3$개의 states를 갖게 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat raw_data/librispeech-phones.txt | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 데이터에는 70개의 phone이 있습니다. phone 갯수가 많은 이유는 `Librispeech` 데이터셋에서는 모음의 `stress`에 따라 서로 다른 phone으로 나타냈기 때문입니다. 그러므로 결국 `monophone` 모델은 210개의 states를 다루게 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `monophone` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree-info exp/monophones/tree | grep num-pdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`monophone tree`는 212개의 `leaves`를 가지고 있는 것을 확인할 수 있습니다. 그 이유는 `SIL`이 5-state `HMM`으로 구성되기 때문입니다. \n",
    "\n",
    "또한 leaves의 갯수를 통해서 `clustering`이 이루어져 있지 않다는 것을 알 수 있스니다. 즉, 가능한 state의 갯수만큼의 `leaves`를 가지고 있는 것입니다. `tree`는 결국 acoustic training의 다른 layer과 동일한 과정으로 modeling을 하기 위해 존재하지만, 큰 역할을 하지는 않는다는 것을 알 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`monophone` tree를 자세히 살펴보면 위의 내용을 확인할 수 있습니다. 아래는 `draw-tree` 기능을 이용하여 랜더링하여 시각화한 tree입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tree_out](resource_files/tree_viz/monophone_tree_zoom_out.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tree_in](resource_files/tree_viz/monophone_tree_zoom_in.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종적으로 tree는 각각의 phone을 단순하게 분리하는 과정이라는 것을 확인할 수 있습니다. 예를 들어, 위의 그림에서 tree는 `SIL` phone들을 왼쪽으로 보내고 `AA_1` phone들을 오른쪽으로 보냅니다. \n",
    "\n",
    "최종 단계(leaves로 나누기 전)에서는 어떤 `HMM`을 사용할지를 결정하게 됩니다. 이 과정에서 `SIL` phone은 `5-state HMM`으로 구성되어 있고, 나머지 phone은 `3-state HMM`으로 구성되어 있다는 것을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`copy-tree`와 `--binary=false` flag를 사용해서 텍스트 버전의 `tree`도 확인할 수 있습니다. \n",
    "\n",
    "We can also get a `text`-version of any `tree` by using `copy-tree` and the `--binary=false` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy-tree --binary=false exp/triphones/tree - | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SE`(`SplitEventMap`)로 시작하는 줄은 실제로 `tree`의 가지를 나누는 장소입니다. 그리고 `CE`(`ConstantEventMap`)로 시작하는 줄은 terminal node(`leaf`)를 나타냅니다. 그러므로 `CE`의 갯수는 `num-pdf`와 일치할 것이고, `SE`의 갯수는 총 `split`하는 횟수와 동일하게 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 시각화에서 타원형 형태의 state는 `SE`를 나타내고, 최종 단계인 겹선의 원형 state는 `CE`를 나타냅니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tree_in](resource_files/tree_viz/monophone_tree_zoom_in.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy-tree --binary=false exp/monophones/tree - | grep SE | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`monophone` tree는 총 69번 split을 하게 됩니다. 다시 말하면 총 `70`개의 phone을 다루기 위해서 `69` 단계가 필요하다고도 할 수 있습니다. `monophone` tree에서는 실제로 `clustering`을 하지 않고 각각의 phone을 스스로의 `leaf`에 할당하기 때문에, `number_of_phones`와 `number_of_split`은 거의 `1-to-1`에 가까운 비율을 가지게 될 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제로 비율이 어떻게 되는지는 다음을 이용하여 계산할 수 있습니다. \n",
    " - `num_phones` (just counting the number of lines in our `phones.txt` file) \n",
    " - `num_splits` (counting the number of `SE`s in the `text` version of the `tree`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_phones_mono=$(cat raw_data/librispeech-phones.txt | wc -l)\n",
    "num_splits_mono=$(( $(copy-tree --binary=false exp/monophones/tree - | grep SE | wc -l) ))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구한 두 값을 나누어주면 비율을 알 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo print ${num_phones_mono}/${num_splits_mono}. | perl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `triphone` model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`triphone` tree에서는 다음 두 가지 내용을 알아보겠습니다. \n",
    "\n",
    " 1. `monophone` tree보다 `pdf (leaves)` 갯수는 많을 것입니다. 왜냐하면 `triphone`에서는 주변 \"context phones\"을 고려하기 때문에, 총 `num_phones^3`의 조합이 가능하기 때문입니다. (70개의 phone이 있을 경우, `70*70*70`개의 조합이 가능합니다.)\n",
    " 2. 총 `pdf`의 갯수는 `70*70*70`보다는 적을 것입니다. 왜냐하면 어느 정도의 일반화(generalization)은 되어 있을 것이기 때문입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree-info exp/triphones/tree | grep num-pdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`70`개의 phone이 있기 때문에, 최대 `343,000`개의 조합이 가능합니다. 위에서 우리는 `triphones` tree는 그 수를 매우 줄였다는 것을 확인하였고, 이는 `clustering`이 잘 이루어진 결과라고 해석할 수 있습니다. `clustering`이 얼마나 잘 되었는지는 `num_phones-to-num_split` 비율을 계산하여서 확인할 수 있습니다. 결과 값이 크면 클수록 `clustering`이 잘 이루어졌다고 할 수 있을 것입니다. (`clustering`이 잘 이루어 졌다면 한 번의 `split`으로 많은 수의 `phone`을 처리할 수 있을 것이기 때문입니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 `phone.txt`의 줄 수를 읽어온 다음, 그 값의 3승을 계산하도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_phones_in_context=$(( ${num_phones_mono} * ${num_phones_mono} * ${num_phones_mono} ))\n",
    "num_splits_tri=$(( $(copy-tree --binary=false exp/triphones/tree - | grep SE | wc -l) ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo print ${num_phones_in_context}/${num_splits_tri}. | perl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 결과값은 평균적으로 `90`개의 phone을 하나의 `leaf`로 `clustering` 했다는 것을 보여줍니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** `decision tree`에서 `일반화(generalization)`과 `오버피팅(over-fitting)`의 경계를 정하는 것은 중요합니다. 우리는 일반화를 시키고 싶지만, 너무 일반화를 시키면 제대로 작동하지 않을 수 있습니다. 그리고 `clustering`도 필요하지만 모든 것을 `cluster`로 변경하고 싶지는 않습니다. 그러므로 `num_phone-to-num_split` 값을 최대로 하는 것이 우리의 목표는 아니라는 것을 기억해야 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`num_leaves` 파라미터를 변경하여서 *decision tree*의 구조를 조정할 수 있습니다. `num_leaves` 값은 `decision tree`가 가질 수 있는 `leaves`의 대략적인 갯수를 알려주는 파라미터입니다. `triphone tree`의 경우 `num_leaves=5000`으로 설정되어 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat exp/triphones/kaldi_config_args.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree-info exp/triphones/tree | grep num-pdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kaldi`가 `leaves`의 갯수를 정하는 방법을 알아내는 것은 쉽지 않습니다. 하지만 `triphone tree`에서 `5000`개의 `leaves`를 필요로 하지 않다는 것을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `triphone_lda` model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`run_train_phones.sh` 스크립트가 하는 일 중에 하나는 `LDA` 모델을 구성할 때 `leaves`의 갯수를 **두 배**로 늘리는 것입니다. 그러므로 실제 `config` 파일에서 `num_leaves`를 `5000`으로 설정하였어도 실제로 코드에서는 `10000`개의 `leaves`를 생성합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat exp/triphones_lda/kaldi_config_args.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree-info exp/triphones_lda/tree | grep pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러므로 `lda tree`가 `triphone tree`보다 많은 수의 `leaves`를 가지고 있는 것은 놀랍지 않은 사실입니다. 그리고 `triphone`의 갯수는 변하지 않았기 때문에(`70*70*70`), 이 tree의 `num_leaves-to-num_splits` 비율은 `triphone tree`보다 작을 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits_lda=$(( $(copy-tree --binary=false exp/triphones_lda/tree - | grep SE | wc -l) ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo print ${num_phones_in_context}/${num_splits_lda}. | perl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 경우, *더 작은* 비율은 `clustering`을 더 작게 하였다고 볼 수 있습니다. (하나의 `leaf`에 더 적은 수의 `phone`이 존재). 이러한 결과가 실제 `ASR` pipeline의 성능에 어떠한 영향을 끼치는지 지금 단계에서는 확인할 수 없습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## understanding the `.mdl` file\n",
    "\n",
    "`.mdl` 파일은 `Hidden Markov Model (HMM)`으로 나타낸 acoustic model입니다. 이 파일은 `HMM` 정보 뿐만 아니라, 서로 다른 `phone`을 나타내는 `Gaussian Mixture Models (GMMs)` 정보도 담고 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `gmm-info`\n",
    "\n",
    "\n",
    "`gmm-info` 파일은 model의 통계적인 수치에 대한 대략적인 정보를 제공합니다. 일부 정보는 `GMM`에 해당하는 정보이고, 일부는 `HMM`에 해당하는 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm-info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm-info exp/monophones/final.mdl "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `num_leaves` in relation to `num_gaussians`\n",
    "\n",
    "`num_phones`와 `num-pdfs`의 관계는 이전에 살펴보았습니다. 이번에는 `num_leaves`와 `num_gaussians`의 관계를 살펴보겠습니다.\n",
    "\n",
    " - `num_leaves` (which ends up being represented as `num-pdfs` in the `tree`) \n",
    " - `num_gaussians`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각의 `pdf`는 *bell-curve* (*i.e.,* 가우시안 분포)의 형태를 띈 확률 분포를 보입니다. `GMM`은 *mixture-model*으로써, 여러개의 `가우시안` 분포를 합쳐서 더욱 **정교하게** 결과를 나타내려는 것입니다. `decision tree`와 마찬가지로, `일반화(Generalization)`과 `오버피팅(over-fitting)`의 경계에서 최고의 \"sweet spot\"을 찾는 것이 최고의 결과를 얻을 수 있는 방법일 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kaldi_config.json` 파일에는 `num_gaussians` 값을 설정할 수 있도록 되어있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat exp/monophones/kaldi_config_args.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 우리는 각각의 `pdf`를 생성할 때, 평균적으로 몇개의 `Gaussian`을 사용하였는지 그 비율을 계산할 수 있습니다. \n",
    "\n",
    "간단하게 `가우시안의 갯수`를 `pdf의 갯수`로 나누어주면 비율을 알 수 있습니다. ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `monophone` tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gaussians_mono=$(gmm-info exp/monophones/final.mdl | grep -Po \"(?<=number of gaussians )[0-9]+\")\n",
    "num_pdfs_mono=$(gmm-info exp/monophones/final.mdl | grep -Po \"(?<=number of pdfs )[0-9]+\")\n",
    "\n",
    "echo \"\"\n",
    "echo \"number of gaussians: ${num_gaussians_mono}\"\n",
    "echo \"number of pdfs: ${num_pdfs_mono}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo print ${num_gaussians_mono}/${num_pdfs_mono}. | perl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상대적으로 높은 비율이 나왔습니다. 이 값이 보여주는 것은, 각각의 `phone`을 모델링 하기 위해서 약 `45`개의 `Gaussian`이 사용되었다는 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `triphone` tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gaussians_tri=$(gmm-info exp/triphones/final.mdl | grep -Po \"(?<=number of gaussians )[0-9]+\")\n",
    "num_pdfs_tri=$(gmm-info exp/triphones/final.mdl | grep -Po \"(?<=number of pdfs )[0-9]+\")\n",
    "\n",
    "echo \"\"\n",
    "echo \"number of gaussians: ${num_gaussians_tri}\"\n",
    "echo \"number of pdfs: ${num_pdfs_tri}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo print ${num_gaussians_tri}/${num_pdfs_tri}. | perl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "같은 갯수의 `Gaussian`을 사용하였지만, 이 비율은 `context`를 고려해서 모델링을 한 `triphone`에서 큰 폭으로 내려갑니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `triphone_lda` tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`run_train_phones.sh` 파일에서 `num_leave`가 두 배로 증가한 것과 마찬가지로, `num_gaussians`도 `triphone_lda mdl`에서 두 배로 증가합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gaussians_lda=$(gmm-info exp/triphones_lda/final.mdl | grep -Po \"(?<=number of gaussians )[0-9]+\")\n",
    "num_pdfs_lda=$(gmm-info exp/triphones_lda/final.mdl | grep -Po \"(?<=number of pdfs )[0-9]+\")\n",
    "\n",
    "echo \"\"\n",
    "echo \"number of gaussians: ${num_gaussians_lda}\"\n",
    "echo \"number of pdfs: ${num_pdfs_lda}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo print ${num_gaussians_lda}/${num_pdfs_lda}. | perl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러므로 `triphones tree`에 비해서 `pdf`의 갯수는 증가하였지만, `Gaussian`의 갯수도 두 배로 증가하였기 때문에 `triphone_lda mdl`에서 구할 수 있는 `num_gaussians`와 `num_pdf`의 비율은 증가합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"best\" settings for these hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금 단계에서 우리가 `ASR` pipeline의 성능을 평가할 수 없기 때문에, 어떠한 값이 가장 최적의 값인지는 당장은 판단할 수 없습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`num_leaves`와 `num_gaussians`에서 최적의 값을 찾기 위해서 우리가 할 수 있는 유일한 방법은 `ASR` pipeline을 끝까지 실행한 이후, `Word Error Rate (WER)`을 측정하는 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 우리는 각각의 값이 결과에 어떠한 영향을 끼칠지는 다음과 같이 예상할 수 있습니다. \n",
    " - `num_leaves`의 값을 높게 하는 것은 `decision tree`가 `phone`을 `clustering` 할 때, **더욱 세부적으로** `clustering`을 하게 합니다. 즉, 더 작은 수의 `phone`을 하나의 `cluster`로 묶게 됩니다. 그리고 `num_leaves`의 값을 낮게 할 경우, 더 많은 `phone`을 하나로 `clustering` 할 것입니다. \n",
    " - `num_gaussians`를 높게 하는 것은 `GMM`이 각각의 `pdf`를 모델링 할 때 더 많은 `Gaussian`을 사용하여서 **더욱 세부으로** 모델링을 하게 할 것입니다. 그리고 값을 낮게 할 경우에는 **더욱 일반적인** 모델링을 할 것입니다. \n",
    " - `num_gaussians`를 `num_leaves`로 나누어서 얻은 결과는 일반적으로 각각의 `pdf`에 있어서 얼마나 많은 `Gaussian`이 사용되었는지를 나타냅니다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
