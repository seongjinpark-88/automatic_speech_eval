{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forced alignment with `Kaldi`\n",
    "\n",
    "일반적으로 자동음성인식에서 `phoneme` 단위까지 자세하게 인식하는 경우는 연구 목적, 혹은 더 나은 `ASR model` 구축을 위한 학습 데이터 수집 목적일 경우가 많습니다. 그렇기 때문에 대부분의 경우 `WER`, 혹은 `SER` 정도를 측정하는 선에서 마무리 짓게 됩니다. 하지만 발화 실험이나 데이터 수집의 측면에서는 `ASR` 모델을 이용하여 음성 데이터를 자동 정렬하는 것이 큰 도움이 될 것이기 때문에, 아래 과정을 통해서 실제 `kaldi`를 이용하여 음성 파일을 `자동 정렬`하는 방법을 알아보도록 하겠습니다. \n",
    "\n",
    "**Note:** 이 `notebook`의 목적은 실제 얼마나 잘 정렬이 되었냐가 아니라 **정렬을 하는 과정을 살펴보는 것**이기 때문에, 올바른 결과를 보기 위해 `ASR` 모델을 테스트할 때 사용했던 파일들을 이용하도록 하겠습니다 (`test_dir`). 지금은 모든 디렉토리가 `하드 코딩` 되어있는 상태이므로, 나중에 다른 데이터로 모델을 실행하실 경우, 스크립트를 훑어보시고 필요한 부분은 변경하셔야 합니다.  \n",
    "\n",
    "**Note:** 실제 `Automatic Speech Recognition`에서 제대로 단어를 측정해내는 것은 쉽지 않습니다. 이전 `notebook`에서 보신 것 처럼 단어를 완벽하게 인식하는 것도 어렵지만, [이 곳](https://www.eleanorchodroff.com/tutorial/kaldi/kaldi-forcedalignment.html)에서 한 것처럼 주어진 발음을 이용해서 단어를 예측해내는 과정은 결코 쉽지 않습니다. 이 `notebook`에서 진행하는 과정은 **낭독체 발화** 실험에서 얻을 수 있는 음성 데이터의 경우처럼 실제로 어떠한 문장을 발화하였는지 알고 있음을 전제로 합니다. \n",
    "\n",
    "**Note:** 일부 부분은 [이 곳](https://www.eleanorchodroff.com/tutorial/kaldi/kaldi-forcedalignment.html)을 참고하였습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env bash\n",
      "# Copyright 2012  Johns Hopkins University (Author: Daniel Povey)\n",
      "# Apache 2.0\n",
      "\n",
      "# Computes training alignments using a model with delta or\n",
      "# LDA+MLLT features.\n",
      "\n",
      "# If you supply the \"--use-graphs true\" option, it will use the training\n",
      "# graphs from the source directory (where the model is).  In this\n",
      "# case the number of jobs must match with the source directory.\n",
      "\n",
      "\n",
      "# Begin configuration section.  \n",
      "nj=4\n",
      "cmd=run.pl\n",
      "use_graphs=false\n",
      "# Begin configuration.\n",
      "scale_opts=\"--transition-scale=1.0 --acoustic-scale=0.1 --self-loop-scale=0.1\"\n",
      "beam=10\n",
      "retry_beam=40\n",
      "careful=false\n",
      "boost_silence=1.0 # Factor by which to boost silence during alignment.\n",
      "# End configuration options.\n",
      "\n",
      "echo \"$0 $@\"  # Print the command line for logging\n",
      "\n",
      "[ -f ${KALDI_INSTRUCTIONAL_PATH}/path.sh ] && . ${KALDI_INSTRUCTIONAL_PATH}/path.sh # source the path.\n",
      ". ${KALDI_INSTRUCTIONAL_PATH}/utils/parse_options.sh || exit 1;\n",
      "\n",
      "if [ $# != 4 ]; then\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "head -n30 steps/align_si.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps/align_si.sh --nj 4 data/test_dir data/lang exp/triphones_lda exp/test_aligned\n",
      "steps/align_si.sh: feature type is lda\n",
      "steps/align_si.sh: aligning data in data/test_dir using model from exp/triphones_lda, putting alignments in exp/test_aligned\n",
      "steps/align_si.sh: done aligning data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory 'exp/test_aligned': File exists\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "mkdir exp/test_aligned\n",
    "\n",
    "steps/align_si.sh --nj 4 data/test_dir data/lang exp/triphones_lda exp/test_aligned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ali-to-phones\n",
    "\n",
    "`ali-to-phone` 스크립트는 최종적으로 음성인식을 한 이후에 생성된 파일인 `ali.*.gz` 파일을 `acoustic model`을 이용하여 `CTM` 형식의 파일로 추출할 수 있게 도와줍니다. `CTM`은 **Time-Marked Conversation** file의 약어로, 파일 이름, 문장 순서, 시작 시간, 종료 시간, 그리고 발화된 음소에 대한 정보를 파일의 각 줄에 담고 있습니다. 현재 우리는 한 파일에 하나의 문장만 들어있기 때문에, 문장의 순서는 모두 *1*로 표시됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ali-to-phones --ctm-output exp/test_aligned/final.mdl 'ark:gunzip -c exp/test_aligned/ali.1.gz|' - \n",
      "LOG (ali-to-phones[5.2.380~1-8e7d2]:main():ali-to-phones.cc:134) Done 63 utterances.\n",
      "ali-to-phones --ctm-output exp/test_aligned/final.mdl 'ark:gunzip -c exp/test_aligned/ali.2.gz|' - \n",
      "LOG (ali-to-phones[5.2.380~1-8e7d2]:main():ali-to-phones.cc:134) Done 63 utterances.\n",
      "ali-to-phones --ctm-output exp/test_aligned/final.mdl 'ark:gunzip -c exp/test_aligned/ali.3.gz|' - \n",
      "LOG (ali-to-phones[5.2.380~1-8e7d2]:main():ali-to-phones.cc:134) Done 62 utterances.\n",
      "ali-to-phones --ctm-output exp/test_aligned/final.mdl 'ark:gunzip -c exp/test_aligned/ali.4.gz|' - \n",
      "LOG (ali-to-phones[5.2.380~1-8e7d2]:main():ali-to-phones.cc:134) Done 62 utterances.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    ". ./path.sh\n",
    "for i in exp/test_aligned/ali.*.gz; do\n",
    "    ali-to-phones --ctm-output exp/test_aligned/final.mdl ark:\"gunzip -c $i|\" -> ${i%.gz}.ctm;\n",
    "done;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089-134686-0000 1 0.000 0.510 1\n",
      "1089-134686-0000 1 0.510 0.060 138\n",
      "1089-134686-0000 1 0.570 0.070 159\n",
      "1089-134686-0000 1 0.640 0.070 138\n",
      "1089-134686-0000 1 0.710 0.140 196\n",
      "1089-134686-0000 1 0.850 0.070 216\n",
      "1089-134686-0000 1 0.920 0.080 231\n",
      "1089-134686-0000 1 1.000 0.050 90\n",
      "1089-134686-0000 1 1.050 0.030 100\n",
      "1089-134686-0000 1 1.080 0.060 219\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head exp/test_aligned/ali.1.ctm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보시는 것 처럼 `.ctm` 파일은 \"파일 이름/문장 번호/시작 시간/종료 시간/음소\"의 정보를 담고 있습니다. 음소의 경우, 이전에도 그랬듯 실제 음소가 아니라 음소의 `인덱스`로 표현되어 있습니다. 나중에 실제 음소로 변환하도록 하겠습니다. \n",
    "\n",
    "`kaldi`에서 `ASR`을 실행할 때 여러개의 cpu를 사용하여 작업을 진행하기 때문에, `CTM` 파일도 여러개가 있습니다. 다음의 명령어를 사용하여 하나의 파일(merged_alignment.txt)로 묶어보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089-134686-0000 1 0.000 0.510 1\n",
      "1089-134686-0000 1 0.510 0.060 138\n",
      "1089-134686-0000 1 0.570 0.070 159\n",
      "1089-134686-0000 1 0.640 0.070 138\n",
      "1089-134686-0000 1 0.710 0.140 196\n",
      "1089-134686-0000 1 0.850 0.070 216\n",
      "1089-134686-0000 1 0.920 0.080 231\n",
      "1089-134686-0000 1 1.000 0.050 90\n",
      "1089-134686-0000 1 1.050 0.030 100\n",
      "1089-134686-0000 1 1.080 0.060 219\n",
      "1284-1181-0004 1 6.000 0.040 184\n",
      "1284-1181-0004 1 6.040 0.050 87\n",
      "1284-1181-0004 1 6.090 0.080 214\n",
      "1284-1181-0004 1 6.170 0.050 176\n",
      "1284-1181-0004 1 6.220 0.130 72\n",
      "1284-1181-0004 1 6.350 0.070 32\n",
      "1284-1181-0004 1 6.420 0.060 80\n",
      "1284-1181-0004 1 6.480 0.030 32\n",
      "1284-1181-0004 1 6.510 0.160 175\n",
      "1284-1181-0004 1 6.670 0.460 1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd exp/test_aligned\n",
    "cat *.ctm > merged_alignment.txt\n",
    "head merged_alignment.txt\n",
    "tail merged_alignment.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# index2phone\n",
    "\n",
    "`인덱스`로 표현된 음소들을 실제 음소로 바꿔보도록 하겠습니다. `data/lang/phones.txt` 파일에는 음소와 그 음소에 해당하는 인덱스 값이 나타나 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<eps> 0\n",
      "SIL 1\n",
      "SIL_B 2\n",
      "SIL_E 3\n",
      "SIL_I 4\n",
      "SIL_S 5\n",
      "AA0_B 6\n",
      "AA0_E 7\n",
      "AA0_I 8\n",
      "AA0_S 9\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head data/lang/phones.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 코드를 이용하여서 `음소-인덱스` 관계를 정의하는 `<dict>`를 만들어 보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIL\n"
     ]
    }
   ],
   "source": [
    "idx2phn = {}\n",
    "with open(\"/scratch/kaldi/egs/INSTRUCTIONAL/data/lang/phones.txt\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    for line in data:\n",
    "        line = line.strip()\n",
    "        phone, idx = line.split()\n",
    "        idx2phn[idx] = phone\n",
    "    f.close\n",
    "print(idx2phn[\"1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만들어진 `<dict>`를 이용하여 인덱스를 실제 음소로 변환한 이후, 전체 결과를 새로운 파일(**`final_ali.txt`**)에 저장하도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout = open(\"/scratch/kaldi/egs/INSTRUCTIONAL/exp/test_aligned/final_ali.txt\", \"w\")\n",
    "with open(\"/scratch/kaldi/egs/INSTRUCTIONAL/exp/test_aligned/merged_alignment.txt\", \"r\") as fin:\n",
    "    data = fin.readlines()\n",
    "    for line in data:\n",
    "        line = line.strip()\n",
    "        file_name, utt, start, end, idx = line.split()\n",
    "        end = float(start) + float(end)\n",
    "        line = file_name + \" \" + utt + \" \" + start + \" \" + str(end) + \" \" + idx\n",
    "        phone = idx2phn[idx]\n",
    "        result = line + \" \" + phone + \"\\n\"\n",
    "        fout.write(result)\n",
    "    fin.close()\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종적으로 생성된 파일은 \"파일 이름/문장 번호/시작 시간/종료 시간/음소 인덱스/실제 음소\"의 정보를 담고 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089-134686-0000 1 0.000 0.51 1 SIL\n",
      "1089-134686-0000 1 0.510 0.57 138 HH_B\n",
      "1089-134686-0000 1 0.570 0.64 159 IY1_E\n",
      "1089-134686-0000 1 0.640 0.71 138 HH_B\n",
      "1089-134686-0000 1 0.710 0.85 196 OW1_I\n",
      "1089-134686-0000 1 0.850 0.92 216 P_I\n",
      "1089-134686-0000 1 0.920 1.0 231 T_E\n",
      "1089-134686-0000 1 1.000 1.05 90 DH_B\n",
      "1089-134686-0000 1 1.050 1.08 100 EH1_I\n",
      "1089-134686-0000 1 1.080 1.14 219 R_E\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head exp/test_aligned/final_ali.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create directories\n",
    "\n",
    "실제 `TextGrid` 파일을 생성하기까지는 많은 과정을 거치게 됩니다. 나중에는 중간에 생성되는 파일/폴더들을 지우셔도 괜찮지만, 지금은 모두 남겨놓은 이후, 각각의 과정에서 어떠한 파일들이 생성되는지 살펴보겠습니다. 필요한 폴더들을 생성하겠습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir ${KALDI_INSTRUCTIONAL_PATH}/exp/test_aligned/align_phones\n",
    "mkdir ${KALDI_INSTRUCTIONAL_PATH}/exp/test_aligned/align_prons\n",
    "mkdir ${KALDI_INSTRUCTIONAL_PATH}/exp/test_aligned/align_words\n",
    "mkdir ${KALDI_INSTRUCTIONAL_PATH}/exp/test_aligned/align_transcripts\n",
    "mkdir ${KALDI_INSTRUCTIONAL_PATH}/exp/test_aligned/textgrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate final_ali.txt\n",
    "\n",
    "`final_ali.txt` 하나의 파일 안에 모든 데이터에 대한 정보가 들어있기 때문에, 각각의 음성 파일에 대한 `forced alignment`를 바로 하기에는 복잡한 과정이 필요합니다. 그렇기 때문에 각 파일에 대한 정보를 나누어서 따로 저장하도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, csv, re, glob, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/scratch/kaldi/egs/INSTRUCTIONAL/exp/test_aligned/final_ali.txt\", \"r\") as fin:\n",
    "    data = fin.readlines()\n",
    "    file_name = data[0].strip().split()[0]\n",
    "    results = []\n",
    "    for line in data:\n",
    "        name = file_name\n",
    "        line = line.strip()\n",
    "        file_name, utt, start, end, idx, phn = line.split()\n",
    "        if (file_name != name):\n",
    "            try:\n",
    "                with open(\"exp/test_aligned/align_phones/\" + (name)+\".txt\",'w') as fwrite:\n",
    "                    writer = csv.writer(fwrite)\n",
    "                    fwrite.write(\"\\n\".join(results))\n",
    "                    fwrite.close()\n",
    "                #print name\n",
    "            except Exception, e:\n",
    "                print \"Failed to write file\",e\n",
    "                sys.exit(2)\n",
    "            del results[:]\n",
    "            results.append(line)\n",
    "        else:\n",
    "            results.append(line)\n",
    "\n",
    "try:\n",
    "    with open(\"exp/test_aligned/align_phones/\" + (name)+\".txt\",'w') as fwrite:\n",
    "        writer = csv.writer(fwrite)\n",
    "        fwrite.write(\"\\n\".join(results))\n",
    "        fwrite.close()\n",
    "                #print name\n",
    "except Exception, e:\n",
    "    print \"Failed to write file\",e\n",
    "    sys.exit(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드를 실행하시면 `exp/triphones_lda/align_phones` 폴더 아래에 각각의 파일 이름으로 `음소 정보`가 저장되었음을 알 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089-134686-0000.txt\n",
      "1089-134686-0001.txt\n",
      "1089-134686-0002.txt\n",
      "1089-134686-0003.txt\n",
      "1089-134686-0004.txt\n",
      "1089-134686-0005.txt\n",
      "1089-134686-0006.txt\n",
      "1089-134686-0007.txt\n",
      "1089-134686-0008.txt\n",
      "1089-134686-0009.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls ${KALDI_INSTRUCTIONAL_PATH}/exp/test_aligned/align_phones | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일을 살펴보면 이제는 한 파일에는 하나의 문장에 대한 정보만 들어있는 것을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089-134686-0000 1 0.000 0.51 1 SIL\n",
      "1089-134686-0000 1 0.510 0.57 138 HH_B\n",
      "1089-134686-0000 1 0.570 0.64 159 IY1_E\n",
      "1089-134686-0000 1 0.640 0.71 138 HH_B\n",
      "1089-134686-0000 1 0.710 0.85 196 OW1_I\n",
      "1089-134686-0000 1 0.850 0.92 216 P_I\n",
      "1089-134686-0000 1 0.920 1.0 231 T_E\n",
      "1089-134686-0000 1 1.000 1.05 90 DH_B\n",
      "1089-134686-0000 1 1.050 1.08 100 EH1_I\n",
      "1089-134686-0000 1 1.080 1.14 219 R_E\n",
      "1089-134686-0000 1 1.140 1.21 266 W_B\n",
      "1089-134686-0000 1 1.210 1.24 244 UH1_I\n",
      "1089-134686-0000 1 1.240 1.31 87 D_E\n",
      "1089-134686-0000 1 1.310 1.37 78 B_B\n",
      "1089-134686-0000 1 1.370 1.42 159 IY1_E\n",
      "1089-134686-0000 1 1.420 1.55 222 S_B\n",
      "1089-134686-0000 1 1.550 1.62 232 T_I\n",
      "1089-134686-0000 1 1.620 1.83 255 UW1_E\n",
      "1089-134686-0000 1 1.830 1.86 1 SIL\n",
      "1089-134686-0000 1 1.860 1.89 130 F_B\n",
      "1089-134686-0000 1 1.890 1.97 107 ER0_E\n",
      "1089-134686-0000 1 1.970 2.05 86 D_B\n",
      "1089-134686-0000 1 2.050 2.1 148 IH1_I\n",
      "1089-134686-0000 1 2.100 2.16 184 N_I\n",
      "1089-134686-0000 1 2.160 2.36 107 ER0_E\n",
      "1089-134686-0000 1 2.360 2.58 1 SIL\n",
      "1089-134686-0000 1 2.580 2.67 230 T_B\n",
      "1089-134686-0000 1 2.670 2.77 112 ER1_I\n",
      "1089-134686-0000 1 2.770 2.83 184 N_I\n",
      "1089-134686-0000 1 2.830 2.9 32 AH0_I\n",
      "1089-134686-0000 1 2.900 2.96 216 P_I\n",
      "1089-134686-0000 1 2.960 3.06 223 S_E\n",
      "1089-134686-0000 1 3.060 3.1 30 AH0_B\n",
      "1089-134686-0000 1 3.100 3.17 184 N_I\n",
      "1089-134686-0000 1 3.170 3.22 87 D_E\n",
      "1089-134686-0000 1 3.220 3.32 170 K_B\n",
      "1089-134686-0000 1 3.320 3.39 100 EH1_I\n",
      "1089-134686-0000 1 3.390 3.53 220 R_I\n",
      "1089-134686-0000 1 3.530 3.57 32 AH0_I\n",
      "1089-134686-0000 1 3.570 3.63 232 T_I\n",
      "1089-134686-0000 1 3.630 3.76 223 S_E\n",
      "1089-134686-0000 1 3.760 3.83 30 AH0_B\n",
      "1089-134686-0000 1 3.830 3.89 184 N_I\n",
      "1089-134686-0000 1 3.890 3.99 87 D_E\n",
      "1089-134686-0000 1 3.990 4.05 78 B_B\n",
      "1089-134686-0000 1 4.050 4.11 220 R_I\n",
      "1089-134686-0000 1 4.110 4.25 256 UW1_I\n",
      "1089-134686-0000 1 4.250 4.31 276 Z_I\n",
      "1089-134686-0000 1 4.310 4.38 87 D_E\n",
      "1089-134686-0000 1 4.380 4.44 214 P_B\n",
      "1089-134686-0000 1 4.440 4.49 32 AH0_I\n",
      "1089-134686-0000 1 4.490 4.6 232 T_I\n",
      "1089-134686-0000 1 4.600 4.68 124 EY1_I\n",
      "1089-134686-0000 1 4.680 4.72 232 T_I\n",
      "1089-134686-0000 1 4.720 4.94 192 OW0_I\n",
      "1089-134686-0000 1 4.940 5.04 275 Z_E\n",
      "1089-134686-0000 1 5.040 5.09 30 AH0_B\n",
      "1089-134686-0000 1 5.090 5.15 184 N_I\n",
      "1089-134686-0000 1 5.150 5.2 87 D_E\n",
      "1089-134686-0000 1 5.200 5.36 130 F_B\n",
      "1089-134686-0000 1 5.360 5.48 24 AE1_I\n",
      "1089-134686-0000 1 5.480 5.54 231 T_E\n",
      "1089-134686-0000 1 5.540 5.57 1 SIL\n",
      "1089-134686-0000 1 5.570 5.78 178 M_B\n",
      "1089-134686-0000 1 5.780 5.82 36 AH1_I\n",
      "1089-134686-0000 1 5.820 5.92 232 T_I\n",
      "1089-134686-0000 1 5.920 5.96 32 AH0_I\n",
      "1089-134686-0000 1 5.960 6.02 183 N_E\n",
      "1089-134686-0000 1 6.020 6.08 1 SIL\n",
      "1089-134686-0000 1 6.080 6.15 214 P_B\n",
      "1089-134686-0000 1 6.150 6.23 160 IY1_I\n",
      "1089-134686-0000 1 6.230 6.32 224 S_I\n",
      "1089-134686-0000 1 6.320 6.39 32 AH0_I\n",
      "1089-134686-0000 1 6.390 6.47 275 Z_E\n",
      "1089-134686-0000 1 6.470 6.58 230 T_B\n",
      "1089-134686-0000 1 6.580 6.63 31 AH0_E\n",
      "1089-134686-0000 1 6.630 6.7 78 B_B\n",
      "1089-134686-0000 1 6.700 6.78 159 IY1_E\n",
      "1089-134686-0000 1 6.780 6.94 174 L_B\n",
      "1089-134686-0000 1 6.940 7.03 124 EY1_I\n",
      "1089-134686-0000 1 7.030 7.06 88 D_I\n",
      "1089-134686-0000 1 7.060 7.12 32 AH0_I\n",
      "1089-134686-0000 1 7.120 7.17 176 L_I\n",
      "1089-134686-0000 1 7.170 7.25 87 D_E\n",
      "1089-134686-0000 1 7.250 7.45 58 AW1_B\n",
      "1089-134686-0000 1 7.450 7.56 231 T_E\n",
      "1089-134686-0000 1 7.560 7.61 142 IH0_B\n",
      "1089-134686-0000 1 7.610 7.69 183 N_E\n",
      "1089-134686-0000 1 7.690 7.79 1 SIL\n",
      "1089-134686-0000 1 7.790 7.89 234 TH_B\n",
      "1089-134686-0000 1 7.890 7.96 148 IH1_I\n",
      "1089-134686-0000 1 7.960 8.12 171 K_E\n",
      "1089-134686-0000 1 8.120 8.22 1 SIL\n",
      "1089-134686-0000 1 8.220 8.31 214 P_B\n",
      "1089-134686-0000 1 8.310 8.36 100 EH1_I\n",
      "1089-134686-0000 1 8.360 8.45 216 P_I\n",
      "1089-134686-0000 1 8.450 8.53 108 ER0_I\n",
      "1089-134686-0000 1 8.530 8.63 87 D_E\n",
      "1089-134686-0000 1 8.630 8.75 1 SIL\n",
      "1089-134686-0000 1 8.750 8.86 130 F_B\n",
      "1089-134686-0000 1 8.860 8.91 176 L_I\n",
      "1089-134686-0000 1 8.910 8.95 60 AW1_I\n",
      "1089-134686-0000 1 8.950 9.09 107 ER0_E\n",
      "1089-134686-0000 1 9.090 9.26 130 F_B\n",
      "1089-134686-0000 1 9.260 9.35 24 AE1_I\n",
      "1089-134686-0000 1 9.350 9.4 232 T_I\n",
      "1089-134686-0000 1 9.400 9.47 32 AH0_I\n",
      "1089-134686-0000 1 9.470 9.5 184 N_I\n",
      "1089-134686-0000 1 9.500 9.53 87 D_E\n",
      "1089-134686-0000 1 9.530 9.75 222 S_B\n",
      "1089-134686-0000 1 9.750 9.92 48 AO1_I\n",
      "1089-134686-0000 1 9.920 10.11 223 S_E\n",
      "1089-134686-0000 1 10.110 10.42 1 SIL"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat ${KALDI_INSTRUCTIONAL_PATH}/exp/test_aligned/align_phones/1089-134686-0000.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align pronunciations\n",
    "\n",
    "앞에서 생성한 파일을 토대로 우리는 \"파일이름/문장 번호/시작 시간/종료 시간/단어의 발음\"의 정보를 담은 파일들을 생성할 수 있습니다. 이전 기억을 더듬어 보시면, `kaldi`에서는 음소를 표기할 때 음소의 단어 내 위치까지도 표시하였다는 것을 아실 수 있습니다(**`BIES`**). 우리는 해당 정보를 이용하여서 어떤 음소에서 어떤 음소까지가 하나의 단어에 대한 발음인지를 알 수 있습니다. 아래 셀을 실행하여서 결과를 확인하도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/scratch/kaldi/egs/INSTRUCTIONAL/exp/test_aligned/align_phones\"\n",
    "pron=[]\n",
    "files = os.listdir(path)\n",
    "for fname in files:\n",
    "    file_name = path + \"/\" + fname\n",
    "    f = open(file_name, \"r\")\n",
    "    data = f.readlines()\n",
    "    fout = open(\"/scratch/kaldi/egs/INSTRUCTIONAL/exp/test_aligned/align_prons/\" + fname, \"w\")\n",
    "    wstart = 0\n",
    "    wend = 0\n",
    "    for line in data:\n",
    "        line = line.strip()\n",
    "        name, utt, start, end, idx, phone = line.split()\n",
    "        if (phone == \"SIL\"):\n",
    "            phone = \"SIL_S\"\n",
    "        phn, pos = phone.split(\"_\")\n",
    "        if pos == \"B\":\n",
    "            w_start = start\n",
    "            pron.append(phn)\n",
    "        if pos == \"S\":\n",
    "            w_start=start\n",
    "            w_end=end\n",
    "            pron.append(phn)\n",
    "            fout.write(name + \"\\t\" + \" \".join(pron) +\"\\t\"+ str(w_start) + \"\\t\" + str(w_end) + \"\\n\")\n",
    "            pron=[]\n",
    "        if pos == \"E\":\n",
    "            w_end=end\n",
    "            pron.append(phn)\n",
    "            fout.write(name + \"\\t\" + \" \".join(pron) +\"\\t\"+ str(w_start) + \"\\t\" + str(w_end) + \"\\n\")\n",
    "            pron=[]\n",
    "        if pos == \"I\":\n",
    "            pron.append(phn)\n",
    "    fout.close()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`exp/triphones_lda/align_prons` 디렉토리를 확인하시면 아까와 같은 이름의 파일들이 있는 것을 확인하실 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089-134686-0000.txt\n",
      "1089-134686-0001.txt\n",
      "1089-134686-0002.txt\n",
      "1089-134686-0003.txt\n",
      "1089-134686-0004.txt\n",
      "1089-134686-0005.txt\n",
      "1089-134686-0006.txt\n",
      "1089-134686-0007.txt\n",
      "1089-134686-0008.txt\n",
      "1089-134686-0009.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ls: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls exp/test_aligned/align_prons/ | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일의 내용은 어떤지 살펴보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089-134686-0000\tSIL\t0.000\t0.51\n",
      "1089-134686-0000\tHH IY1\t0.510\t0.64\n",
      "1089-134686-0000\tHH OW1 P T\t0.640\t1.0\n",
      "1089-134686-0000\tDH EH1 R\t1.000\t1.14\n",
      "1089-134686-0000\tW UH1 D\t1.140\t1.31\n",
      "1089-134686-0000\tB IY1\t1.310\t1.42\n",
      "1089-134686-0000\tS T UW1\t1.420\t1.83\n",
      "1089-134686-0000\tSIL\t1.830\t1.86\n",
      "1089-134686-0000\tF ER0\t1.860\t1.97\n",
      "1089-134686-0000\tD IH1 N ER0\t1.970\t2.36\n",
      "1089-134686-0000\tIH0 N\t7.560\t7.69\n",
      "1089-134686-0000\tSIL\t7.690\t7.79\n",
      "1089-134686-0000\tTH IH1 K\t7.790\t8.12\n",
      "1089-134686-0000\tSIL\t8.120\t8.22\n",
      "1089-134686-0000\tP EH1 P ER0 D\t8.220\t8.63\n",
      "1089-134686-0000\tSIL\t8.630\t8.75\n",
      "1089-134686-0000\tF L AW1 ER0\t8.750\t9.09\n",
      "1089-134686-0000\tF AE1 T AH0 N D\t9.090\t9.53\n",
      "1089-134686-0000\tS AO1 S\t9.530\t10.11\n",
      "1089-134686-0000\tSIL\t10.110\t10.42\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head exp/test_aligned/align_prons/1089-134686-0000.txt\n",
    "tail exp/test_aligned/align_prons/1089-134686-0000.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 파일과 유사하지만, 이제는 음성 파일 어디에서부터 어디까지 어떠한 단어가 발음되었는지의 정보를 담고 있는 것을 볼 수 있습니다. 실제 단어는 어떤 단어일지 아직 모르지만, 그 단어가 **`어떤 발음`**으로 발화되었는지의 정보는 여기에서 확인 가능한 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract real words\n",
    "\n",
    "이 `notebook`에서 우리는 단어를 예측해야 하는 것이 아니라, 실제 어떠한 단어가 발화되었는지 알고 있습니다. 그렇기 때문에 아래 스크립트를 이용하여서 각각의 파일에서 어떤 단어들이 발화되었는지 순서대로 기록하도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"raw_data/librispeech-transcripts.txt\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    for line in data:\n",
    "        line = line.strip()\n",
    "        info = line.split()\n",
    "        fname = info[0]\n",
    "        file_name = \"exp/test_aligned/align_transcripts/\" + fname + \".txt\"\n",
    "        \n",
    "        fout = open(file_name, \"w\")\n",
    "        for item in info[1:]:\n",
    "            result = fname + \" \" + item + \"\\n\"\n",
    "            fout.write(result)\n",
    "        fout.close()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089-134686-0000.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "ls exp/test_aligned/align_transcripts | grep \"1089-134686-0000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성된 파일을 확인해보면, `SIL`을 제외하고는 실제 문장에서 어떤 단어들이 발화되었는지 순서대로 나타나 있는 것을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089-134686-0000 HE\n",
      "1089-134686-0000 HOPED\n",
      "1089-134686-0000 THERE\n",
      "1089-134686-0000 WOULD\n",
      "1089-134686-0000 BE\n",
      "1089-134686-0000 STEW\n",
      "1089-134686-0000 FOR\n",
      "1089-134686-0000 DINNER\n",
      "1089-134686-0000 TURNIPS\n",
      "1089-134686-0000 AND\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head exp/test_aligned/align_transcripts/1089-134686-0000.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pron2word\n",
    "\n",
    "`kaldi`를 시작할 때, 우리는 발음 사전을 이용했었습니다. 같은 파일을 이용해서 이번에는 `발음-단어`의 관계를 정의하는 `<dict>`를 만들어 보도록 하겠습니다. 이 과정을 수행하는 목적은 어떠한 단어가 발음되었을 때, 그 발음을 가진 단어들을 **후보군**으로 지정하고 나중에 실제 문장에서 발화된 단어와 일치하는지 확인하기 위해서입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"A''S\", \"A'S\", 'AISE', 'AYS', 'EYS']\n"
     ]
    }
   ],
   "source": [
    "pron2word = {}\n",
    "with open(\"/scratch/kaldi/egs/INSTRUCTIONAL/data/local/dict/lexicon.txt\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    for line in data:\n",
    "        line = line.strip()\n",
    "        info = line.split()\n",
    "        word = info[0]\n",
    "        pron = \" \".join(info[1:])\n",
    "        try:\n",
    "            pron2word[pron].append(word)\n",
    "        except:\n",
    "            pron2word[pron] = []\n",
    "            pron2word[pron].append(word)\n",
    "    f.close\n",
    "print(pron2word[\"EY1 Z\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pron2word`와 앞서 생성된 `align_prons`, `align_transcripts`를 이용하여서 \"파일 이름/단어/시작 시간/종료 시간\"의 정보를 담고 있는 파일들을 생성해보도록 하겠습니다. 먼저 `align_prons` 파일을 읽어온 이후, 같은 이름을 가진 `align_transcripts`를 읽어옵니다. `align_prons`의 파일들은 `SIL`을 제외하고는 `align_transcript` 폴더에 같은 이름을 가진 파일의 단어들이 순서대로 발화되어야 하므로, `align_prons`에 있는 발음들의 **후보군** 단어들을 불러오고, `align_transcript`에 같은 순서의 단어가 후보군에 있는지 확인하는 과정을 거쳤습니다. 후보군에 해당 단어가 있는 경우 실제 단어를 출력하고, 잘못 발화되었을 경우 `<UNK>`를 출력하는 형식입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pron_path = \"/scratch/kaldi/egs/INSTRUCTIONAL/exp/test_aligned/align_prons\"\n",
    "tran_path = \"/scratch/kaldi/egs/INSTRUCTIONAL/exp/test_aligned/align_transcripts\"\n",
    "\n",
    "pron_files = os.listdir(pron_path)\n",
    "tran_files = os.listdir(tran_path)\n",
    "for fname in pron_files:\n",
    "    pron_name = pron_path + \"/\" + fname\n",
    "    tran_name = tran_path + \"/\" + fname\n",
    "    word_name = \"/scratch/kaldi/egs/INSTRUCTIONAL/exp/test_aligned/align_words/\" + fname\n",
    "    f_pron = open(pron_name, \"r\")\n",
    "    f_tran = open(tran_name, \"r\")\n",
    "    pron_data = f_pron.readlines()\n",
    "    tran_data = f_tran.readlines()\n",
    "    \n",
    "    fout = open(word_name, \"w\")\n",
    "    \n",
    "    idx = 0\n",
    "    for line in pron_data:\n",
    "        line = line.strip()\n",
    "        name, pron, start, end = line.split(\"\\t\")\n",
    "        if (pron == \"SIL\"):\n",
    "            result = line + \"\\n\"\n",
    "            fout.write(result)\n",
    "        else:\n",
    "            candidates = pron2word[pron]\n",
    "            info = tran_data[idx]\n",
    "            t_name, t_word = info.split()\n",
    "            if (t_word in candidates):\n",
    "                result = name + \"\\t\" + t_word + \"\\t\" + start + \"\\t\" + end + \"\\n\"\n",
    "                fout.write(result)\n",
    "                idx += 1\n",
    "            else:\n",
    "                result = name + \"\\t<UNK>\\t\" + start + \"\\t\" + end + \"\\n\"\n",
    "                fout.write(result)\n",
    "                idx += 1\n",
    "    f_pron.close()\n",
    "    f_tran.close()\n",
    "    fout.close()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089-134686-0000.txt\n",
      "1089-134686-0001.txt\n",
      "1089-134686-0002.txt\n",
      "1089-134686-0003.txt\n",
      "1089-134686-0004.txt\n",
      "1089-134686-0005.txt\n",
      "1089-134686-0006.txt\n",
      "1089-134686-0007.txt\n",
      "1089-134686-0008.txt\n",
      "1089-134686-0009.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "ls exp/test_aligned/align_words | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행 결과를 살펴보면 단어 정보가 제대로 옮겨졌다는 것을 볼 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089-134686-0000\tSIL\t0.000\t0.51\n",
      "1089-134686-0000\tHE\t0.510\t0.64\n",
      "1089-134686-0000\tHOPED\t0.640\t1.0\n",
      "1089-134686-0000\tTHERE\t1.000\t1.14\n",
      "1089-134686-0000\tWOULD\t1.140\t1.31\n",
      "1089-134686-0000\tBE\t1.310\t1.42\n",
      "1089-134686-0000\tSTEW\t1.420\t1.83\n",
      "1089-134686-0000\tSIL\t1.830\t1.86\n",
      "1089-134686-0000\tFOR\t1.860\t1.97\n",
      "1089-134686-0000\tDINNER\t1.970\t2.36\n",
      "1089-134686-0000\tIN\t7.560\t7.69\n",
      "1089-134686-0000\tSIL\t7.690\t7.79\n",
      "1089-134686-0000\tTHICK\t7.790\t8.12\n",
      "1089-134686-0000\tSIL\t8.120\t8.22\n",
      "1089-134686-0000\tPEPPERED\t8.220\t8.63\n",
      "1089-134686-0000\tSIL\t8.630\t8.75\n",
      "1089-134686-0000\tFLOUR\t8.750\t9.09\n",
      "1089-134686-0000\tFATTENED\t9.090\t9.53\n",
      "1089-134686-0000\tSAUCE\t9.530\t10.11\n",
      "1089-134686-0000\tSIL\t10.110\t10.42\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "head exp/test_aligned/align_words/1089-134686-0000.txt\n",
    "tail exp/test_aligned/align_words/1089-134686-0000.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TextGrid files\n",
    "\n",
    "이제는 생성한 모든 파일들을 토대로 `TextGrid` 파일을 생성해보도록 하겠습니다. \n",
    "\n",
    "과정이 매우 복잡해 보일 수 있지만, 대부분의 과정은 `TextGrid` 파일을 `Praat`에서 제대로 읽어오기 위한 정보를 담고 있는 부분들이 많습니다. \n",
    "\n",
    "내부에서 phone, word, 그리고 sentence를 각각의 티어에 담기 위해 진행되는 과정은 단순합니다. \n",
    "\n",
    " 1. align_words 파일을 이용하여 전체 음성 파일의 시작/종료 시간 구하기\n",
    " 2. align_phones 파일의 각 줄을 읽어오면서 시작 시간, 종료 시간, 음소를 출력\n",
    " 3. align_words 파일의 각 줄을 읽어오면서 시작 시간, 종료 시간, 음소를 출력\n",
    " 4. align_words 파일에서 \"SIL\"을 제외한 단어들을 이용하여 문장을 구성해고, 해당 문장을 마지막 티어로 추가. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pron_path = \"/scratch/kaldi/egs/INSTRUCTIONAL/exp/test_aligned/align_phones\"\n",
    "word_path = \"/scratch/kaldi/egs/INSTRUCTIONAL/exp/test_aligned/align_words\"\n",
    "\n",
    "pron_files = os.listdir(pron_path)\n",
    "word_files = os.listdir(word_path)\n",
    "for fname in pron_files:\n",
    "    name, ext = fname.split(\".\")\n",
    "    pron_name = pron_path + \"/\" + fname\n",
    "    word_name = word_path + \"/\" + fname\n",
    "    tg_name = \"/scratch/kaldi/egs/INSTRUCTIONAL/exp/test_aligned/textgrid/\" + name + \".TextGrid\"\n",
    "    f_pron = open(pron_name, \"r\")\n",
    "    f_word = open(word_name, \"r\")\n",
    "    pron_data = f_pron.readlines()\n",
    "    word_data = f_word.readlines()\n",
    "    \n",
    "    f_start = word_data[0].strip().split(\"\\t\")[2]\n",
    "    f_end = word_data[-1].strip().split(\"\\t\")[3]\n",
    "    \n",
    "    fout = open(tg_name, \"w\")\n",
    "    \n",
    "    fout.write('File type = \"ooTextFile\"\\n')\n",
    "    fout.write('Object class = \"TextGrid\"\\n\\n')\n",
    "    fout.write(\"xmin = \" + str(f_start) + \"\\n\")\n",
    "    fout.write(\"xmax = \" + str(f_end) + \"\\n\")\n",
    "    fout.write(\"tiers? <exists>\\n\")\n",
    "    fout.write(\"size = 3\\n\")\n",
    "    fout.write(\"item []:\\n\")\n",
    "    \n",
    "    fout.write(\"\\titem [1]:\\n\")\n",
    "    fout.write('\\t\\tclass = \"IntervalTier\"\\n')\n",
    "    fout.write('\\t\\tname = \"phone\"\\n')\n",
    "    fout.write(\"\\t\\txmin = \" + str(f_start) + \"\\n\")\n",
    "    fout.write(\"\\t\\txmax = \" + str(f_end) + \"\\n\")\n",
    "    fout.write(\"\\t\\tintervals: size = \" + str(len(pron_data)) + \"\\n\")\n",
    "    for i in range(0, len(pron_data)):\n",
    "        fout.write(\"\\t\\tintervals [\" + str(i + 1) + \"]:\\n\")\n",
    "        info = pron_data[i].strip().split()\n",
    "        start = info[2]\n",
    "        end = info[3]\n",
    "        pron = info[5]\n",
    "        if (pron != \"SIL\"):\n",
    "            phn, pos = pron.split(\"_\")\n",
    "            pron = phn\n",
    "        fout.write(\"\\t\\t\\txmin = \" + start + \"\\n\")\n",
    "        fout.write(\"\\t\\t\\txmax = \" + end + \"\\n\")\n",
    "        fout.write('\\t\\t\\ttext = \"' + pron + '\"\\n')\n",
    "    fout.write(\"\\titem [2]:\\n\")\n",
    "    fout.write('\\t\\tclass = \"IntervalTier\"\\n')\n",
    "    fout.write('\\t\\tname = \"word\"\\n')\n",
    "    fout.write(\"\\t\\txmin = \" + str(f_start) + \"\\n\")\n",
    "    fout.write(\"\\t\\txmax = \" + str(f_end) + \"\\n\")\n",
    "    fout.write(\"\\t\\tintervals: size = \" + str(len(word_data)) + \"\\n\")\n",
    "    words = []\n",
    "    for i in range(0, len(word_data)):\n",
    "        fout.write(\"\\t\\tintervals [\" + str(i + 1) + \"]:\\n\")\n",
    "        info = word_data[i].strip().split()\n",
    "        start = info[2]\n",
    "        end = info[3]\n",
    "        word = info[1]\n",
    "        if word != \"SIL\":\n",
    "            words.append(word) \n",
    "        fout.write(\"\\t\\t\\txmin = \" + start + \"\\n\")\n",
    "        fout.write(\"\\t\\t\\txmax = \" + end + \"\\n\")\n",
    "        fout.write('\\t\\t\\ttext = \"' + word + '\"\\n')\n",
    "    fout.write(\"\\titem [3]:\\n\")\n",
    "    fout.write('\\t\\tclass = \"IntervalTier\"\\n')\n",
    "    fout.write('\\t\\tname = \"sent\"\\n')\n",
    "    fout.write(\"\\t\\txmin = \" + str(f_start) + \"\\n\")\n",
    "    fout.write(\"\\t\\txmax = \" + str(f_end) + \"\\n\")\n",
    "    fout.write(\"\\t\\tintervals: size = 1\\n\")\n",
    "    fout.write(\"\\t\\tintervals [1]:\\n\")\n",
    "    info = word_data[i].strip().split()\n",
    "    start = info[2]\n",
    "    end = info[3]\n",
    "    sent = \" \".join(words)\n",
    "    fout.write(\"\\t\\t\\txmin = \" + str(f_start) + \"\\n\")\n",
    "    fout.write(\"\\t\\t\\txmax = \" + str(f_end) + \"\\n\")\n",
    "    fout.write('\\t\\t\\ttext = \"' + sent + '\"\\n')\n",
    "    f_pron.close()\n",
    "    f_word.close()\n",
    "    fout.close()                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과로 다음과 같은 `TextGrid` 파일들이 생성됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089-134686-0000.TextGrid\n",
      "1089-134686-0001.TextGrid\n",
      "1089-134686-0002.TextGrid\n",
      "1089-134686-0003.TextGrid\n",
      "1089-134686-0004.TextGrid\n",
      "1089-134686-0005.TextGrid\n",
      "1089-134686-0006.TextGrid\n",
      "1089-134686-0007.TextGrid\n",
      "1089-134686-0008.TextGrid\n",
      "1089-134686-0009.TextGrid\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls exp/test_aligned/textgrid | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일을 훑어보면 실제 TextGrid 파일과 동일한 구조로 되어있음을 알 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File type = \"ooTextFile\"\n",
      "Object class = \"TextGrid\"\n",
      "\n",
      "xmin = 0.000\n",
      "xmax = 10.42\n",
      "tiers? <exists>\n",
      "size = 3\n",
      "item []:\n",
      "\titem [1]:\n",
      "\t\tclass = \"IntervalTier\"\n",
      "\t\tname = \"phone\"\n",
      "\t\txmin = 0.000\n",
      "\t\txmax = 10.42\n",
      "\t\tintervals: size = 113\n",
      "\t\tintervals [1]:\n",
      "\t\t\txmin = 0.000\n",
      "\t\t\txmax = 0.51\n",
      "\t\t\ttext = \"SIL\"\n",
      "\t\tintervals [2]:\n",
      "\t\t\txmin = 0.510\n",
      "\t\t\txmax = 0.57\n",
      "\t\t\ttext = \"HH\"\n",
      "\t\tintervals [3]:\n",
      "\t\t\txmin = 0.570\n",
      "\t\t\txmax = 0.64\n",
      "\t\t\ttext = \"IY1\"\n",
      "\t\tintervals [4]:\n",
      "\t\t\txmin = 0.640\n",
      "\t\t\txmax = 0.71\n",
      "\t\t\ttext = \"HH\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head -n 30 exp/test_aligned/textgrid/1089-134686-0000.TextGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample 파일을 실제 `Praat`에서 열어보도록 하겠습니다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
