{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "io3htdIajyFK"
   },
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jY_kKl4oj0wQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seongjinpark/.conda/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/seongjinpark/.conda/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/seongjinpark/.conda/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/seongjinpark/.conda/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/seongjinpark/.conda/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/seongjinpark/.conda/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/seongjinpark/.conda/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/seongjinpark/.conda/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/seongjinpark/.conda/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/seongjinpark/.conda/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/seongjinpark/.conda/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/seongjinpark/.conda/envs/pytorch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, LSTM, GRU, Bidirectional\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W5ClbVSTkDXs"
   },
   "source": [
    "### Check the location of WAV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Yxhw3xWkFy-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S02_Almost-All-Colleges.wav\t     S19_Military-Personnel-Are.wav\r\n",
      "S02_A-Monstrous-Shadow.wav\t     S19_Nothing-Has-Been.wav\r\n",
      "S02_An-Adult-Male.wav\t\t     S19_Of-Course-Dear.wav\r\n",
      "S02_Any-Organism-That.wav\t     S19_Only-The-Most.wav\r\n",
      "S02_Are-You-Looking.wav\t\t     S19_Pam-Gives-Driving.wav\r\n",
      "S02_Before-Thursdays-Exam.wav\t     S19_Ralph-Prepared-Red.wav\r\n",
      "S02_Carl-Lives-In.wav\t\t     S19_She-Had-Your.wav\r\n",
      "S02_Combine-All-The.wav\t\t     S19_Steve-Collects-Rare.wav\r\n",
      "S02_Continental-Drift-Is.wav\t     S19_The-Moisture-In.wav\r\n",
      "S02_Did-Shawn-Catch.wav\t\t     S19_The-Small-Boy.wav\r\n",
      "S02_Dont-Ask-Me.wav\t\t     S19_The-Surplus-Shoes.wav\r\n",
      "S02_Gently-Place-Jims.wav\t     S19_The-Tooth-Fairy.wav\r\n",
      "S02_George-And-Tom.wav\t\t     S19_They-All-Like.wav\r\n",
      "S02_Gregory-And-Tom.wav\t\t     S19_They-Enjoy-It.wav\r\n",
      "S02_He-Ate-Four.wav\t\t     S19_They-Were-Already.wav\r\n",
      "S02_He-Shrugged-Casually.wav\t     S19_Those-Answers-Will.wav\r\n",
      "S02_How-Oily-Do.wav\t\t     S19_Thus-Technical-Efficiency.wav\r\n",
      "S02_How-Permanent-Are.wav\t     S19_Too-Much-Curiosity.wav\r\n",
      "S02_In-Every-Major.wav\t\t     S19_Tradition-Requires-Parental.wav\r\n",
      "S02_In-The-Long.wav\t\t     S19_Try-To-Recall.wav\r\n",
      "S02_It-Took-Him.wav\t\t     S21_Almost-All-Colleges.wav\r\n",
      "S02_Military-Personnel-Are.wav\t     S21_A-Monstrous-Shadow.wav\r\n",
      "S02_Nothing-Has-Been.wav\t     S21_An-Adult-Male.wav\r\n",
      "S02_Of-Course-Dear.wav\t\t     S21_Any-Organism-That.wav\r\n",
      "S02_Only-The-Most.wav\t\t     S21_Are-You-Looking.wav\r\n",
      "S02_Pam-Gives-Driving.wav\t     S21_Before-Thursdays-Exam.wav\r\n",
      "S02_Ralph-Prepared-Red.wav\t     S21_Carl-Lives-In.wav\r\n",
      "S02_She-Had-Your.wav\t\t     S21_Combine-All-The.wav\r\n",
      "S02_Steve-Collects-Rare.wav\t     S21_Continental-Drift-Is.wav\r\n",
      "S02_The-Moisture-In.wav\t\t     S21_Did-Shawn-Catch.wav\r\n",
      "S02_The-Small-Boy.wav\t\t     S21_Dont-Ask-Me.wav\r\n",
      "S02_The-Surplus-Shoes.wav\t     S21_Gently-Place-Jims.wav\r\n",
      "S02_The-Tooth-Fairy.wav\t\t     S21_Gregory-And-Tom.wav\r\n",
      "S02_They-All-Like.wav\t\t     S21_He-Ate-Four.wav\r\n",
      "S02_They-Enjoy-It.wav\t\t     S21_He-Shrugged-Casually.wav\r\n",
      "S02_They-Were-Already.wav\t     S21_How-Oily-Do.wav\r\n",
      "S02_Those-Answers-Will.wav\t     S21_How-Permanent-Are.wav\r\n",
      "S02_Thus-Technical-Efficiency.wav    S21_In-Every-Major.wav\r\n",
      "S02_Too-Much-Curiosity.wav\t     S21_In-The-Long.wav\r\n",
      "S02_Tradition-Requires-Parental.wav  S21_It-Took-Him.wav\r\n",
      "S02_Try-To-Recall.wav\t\t     S21_Military-Personnel-Are.wav\r\n",
      "S03_Almost-All-Colleges.wav\t     S21_Nothing-Has-Been.wav\r\n",
      "S03_A-Monstrous-Shadow.wav\t     S21_Of-Course-Dear.wav\r\n",
      "S03_An-Adult-Male.wav\t\t     S21_Only-The-Most.wav\r\n",
      "S03_Any-Organism-That.wav\t     S21_Pam-Gives-Driving.wav\r\n",
      "S03_Are-You-Looking.wav\t\t     S21_Ralph-Prepared-Red.wav\r\n",
      "S03_Before-Thursdays-Exam.wav\t     S21_She-Had-Your.wav\r\n",
      "S03_Carl-Lives-In.wav\t\t     S21_Steve-Collects-Rare.wav\r\n",
      "S03_Combine-All-The.wav\t\t     S21_The-Moisture-In.wav\r\n",
      "S03_Continental-Drift-Is.wav\t     S21_The-Small-Boy.wav\r\n",
      "S03_Did-Shawn-Catch.wav\t\t     S21_The-Surplus-Shoes.wav\r\n",
      "S03_Dont-Ask-Me.wav\t\t     S21_The-Tooth-Fairy.wav\r\n",
      "S03_Gently-Place-Jims.wav\t     S21_They-All-Like.wav\r\n",
      "S03_Gregory-And-Tom.wav\t\t     S21_They-Enjoy-It.wav\r\n",
      "S03_He-Ate-Four.wav\t\t     S21_They-Were-Already.wav\r\n",
      "S03_He-Shrugged-Casually.wav\t     S21_Those-Answers-Will.wav\r\n",
      "S03_How-Oily-Do.wav\t\t     S21_Thus-Technical-Efficiency.wav\r\n",
      "S03_How-Permanent-Are.wav\t     S21_Too-Much-Curiosity.wav\r\n",
      "S03_In-Every-Major.wav\t\t     S21_Tradition-Requires-Parental.wav\r\n",
      "S03_In-The-Long.wav\t\t     S21_Try-To-Recall.wav\r\n",
      "S03_It-Took-Him.wav\t\t     S22_Almost-All-Colleges.wav\r\n",
      "S03_Military-Personnel-Are.wav\t     S22_A-Monstrous-Shadow.wav\r\n",
      "S03_Nothing-Has-Been.wav\t     S22_An-Adult-Male.wav\r\n",
      "S03_Of-Course-Dear.wav\t\t     S22_Any-Organism-That.wav\r\n",
      "S03_Only-The-Most.wav\t\t     S22_Are-You-Looking.wav\r\n",
      "S03_Pam-Gives-Driving.wav\t     S22_Before-Thursdays-Exam.wav\r\n",
      "S03_Ralph-Prepared-Red.wav\t     S22_Carl-Lives-In.wav\r\n",
      "S03_She-Had-Your.wav\t\t     S22_Combine-All-The.wav\r\n",
      "S03_Steve-Collects-Rare.wav\t     S22_Continental-Drift-Is.wav\r\n",
      "S03_The-Moisture-In.wav\t\t     S22_Did-Shawn-Catch.wav\r\n",
      "S03_The-Small-Boy.wav\t\t     S22_Dont-Ask-Me.wav\r\n",
      "S03_The-Surplus-Shoes.wav\t     S22_Gently-Place-Jims.wav\r\n",
      "S03_The-Tooth-Fairy.wav\t\t     S22_Gregory-And-Tom.wav\r\n",
      "S03_They-All-Like.wav\t\t     S22_He-Ate-Four.wav\r\n",
      "S03_They-Enjoy-It.wav\t\t     S22_He-Shrugged-Casually.wav\r\n",
      "S03_They-Were-Already.wav\t     S22_How-Oily-Do.wav\r\n",
      "S03_Those-Answers-Will.wav\t     S22_How-Permanent-Are.wav\r\n",
      "S03_Thus-Technical-Efficiency.wav    S22_In-Every-Major.wav\r\n",
      "S03_Too-Much-Curiosity.wav\t     S22_In-The-Long.wav\r\n",
      "S03_Tradition-Requires-Parental.wav  S22_It-Took-Him.wav\r\n",
      "S03_Try-To-Recall.wav\t\t     S22_Military-Personnel-Are.wav\r\n",
      "S04_Almost-All-Colleges.wav\t     S22_Nothing-Has-Been.wav\r\n",
      "S04_A-Monstrous-Shadow.wav\t     S22_Of-Course-Dear.wav\r\n",
      "S04_An-Adult-Male.wav\t\t     S22_Only-The-Most.wav\r\n",
      "S04_Any-Organism-That.wav\t     S22_Pam-Gives-Driving.wav\r\n",
      "S04_Are-You-Looking.wav\t\t     S22_Ralph-Prepared-Red.wav\r\n",
      "S04_Before-Thursdays-Exam.wav\t     S22_She-Had-Your.wav\r\n",
      "S04_Carl-Lives-In.wav\t\t     S22_Steve-Collects-Rare.wav\r\n",
      "S04_Combine-All-The.wav\t\t     S22_The-Moisture-In.wav\r\n",
      "S04_Continental-Drift-Is.wav\t     S22_The-Small-Boy.wav\r\n",
      "S04_Did-Shawn-Catch.wav\t\t     S22_The-Surplus-Shoes.wav\r\n",
      "S04_Dont-Ask-Me.wav\t\t     S22_The-Tooth-Fairy.wav\r\n",
      "S04_Gently-Place-Jims.wav\t     S22_They-All-Like.wav\r\n",
      "S04_Gregory-And-Tom.wav\t\t     S22_They-Enjoy-It.wav\r\n",
      "S04_He-Ate-Four.wav\t\t     S22_They-Were-Already.wav\r\n",
      "S04_He-Shrugged-Casually.wav\t     S22_Those-Answers-Will.wav\r\n",
      "S04_How-Oily-Do.wav\t\t     S22_Thus-Technical-Efficiency.wav\r\n",
      "S04_How-Permanent-Are.wav\t     S22_Too-Much-Curiosity.wav\r\n",
      "S04_In-Every-Major.wav\t\t     S22_Tradition-Requires-Parental.wav\r\n",
      "S04_In-The-Long.wav\t\t     S22_Try-To-Recall.wav\r\n",
      "S04_It-Took-Him.wav\t\t     S23_Almost-All-Colleges.wav\r\n",
      "S04_Military-Personnel-Are.wav\t     S23_A-Monstrous-Shadow.wav\r\n",
      "S04_Nothing-Has-Been.wav\t     S23_An-Adult-Male.wav\r\n",
      "S04_Of-Course-Dear.wav\t\t     S23_Any-Organism-That.wav\r\n",
      "S04_Only-The-Most.wav\t\t     S23_Are-You-Looking.wav\r\n",
      "S04_Pam-Gives-Driving.wav\t     S23_Before-Thursdays-Exam.wav\r\n",
      "S04_Ralph-Prepared-Red.wav\t     S23_Carl-Lives-In.wav\r\n",
      "S04_She-Had-Your.wav\t\t     S23_Combine-All-The.wav\r\n",
      "S04_Steve-Collects-Rare.wav\t     S23_Continental-Drift-Is.wav\r\n",
      "S04_The-Moisture-In.wav\t\t     S23_Did-Shawn-Catch.wav\r\n",
      "S04_The-Small-Boy.wav\t\t     S23_Dont-Ask-Me.wav\r\n",
      "S04_The-Surplus-Shoes.wav\t     S23_Gently-Place-Jims.wav\r\n",
      "S04_The-Tooth-Fairy.wav\t\t     S23_Gregory-And-Tom.wav\r\n",
      "S04_They-All-Like.wav\t\t     S23_He-Ate-Four.wav\r\n",
      "S04_They-Enjoy-It.wav\t\t     S23_He-Shrugged-Casually.wav\r\n",
      "S04_They-Were-Already.wav\t     S23_How-Oily-Do.wav\r\n",
      "S04_Those-Answers-Will.wav\t     S23_How-Permanent-Are.wav\r\n",
      "S04_Thus-Technical-Efficiency.wav    S23_In-Every-Major.wav\r\n",
      "S04_Too-Much-Curiosity.wav\t     S23_In-The-Long.wav\r\n",
      "S04_Tradition-Requires-Parental.wav  S23_It-Took-Him.wav\r\n",
      "S04_Try-To-Recall.wav\t\t     S23_Military-Personnel-Are.wav\r\n",
      "S05_Almost-All-Colleges.wav\t     S23_Nothing-Has-Been.wav\r\n",
      "S05_A-Monstrous-Shadow.wav\t     S23_Of-Course-Dear.wav\r\n",
      "S05_An-Adult-Male.wav\t\t     S23_Only-The-Most.wav\r\n",
      "S05_Any-Organism-That.wav\t     S23_Pam-Gives-Driving.wav\r\n",
      "S05_Are-You-Looking.wav\t\t     S23_Ralph-Prepared-Red.wav\r\n",
      "S05_Before-Thursdays-Exam.wav\t     S23_She-Had-Your.wav\r\n",
      "S05_Carl-Lives-In.wav\t\t     S23_Steve-Collects-Rare.wav\r\n",
      "S05_Combine-All-The.wav\t\t     S23_The-Moisture-In.wav\r\n",
      "S05_Continental-Drift-Is.wav\t     S23_The-Small-Boy.wav\r\n",
      "S05_Did-Shawn-Catch.wav\t\t     S23_The-Surplus-Shoes.wav\r\n",
      "S05_Dont-Ask-Me.wav\t\t     S23_The-Tooth-Fairy.wav\r\n",
      "S05_Gently-Place-Jims.wav\t     S23_They-All-Like.wav\r\n",
      "S05_Gregory-And-Tom.wav\t\t     S23_They-Enjoy-It.wav\r\n",
      "S05_He-Ate-Four.wav\t\t     S23_They-Were-Already.wav\r\n",
      "S05_He-Shrugged-Casually.wav\t     S23_Those-Answers-Will.wav\r\n",
      "S05_How-Oily-Do.wav\t\t     S23_Thus-Technical-Efficiency.wav\r\n",
      "S05_How-Permanent-Are.wav\t     S23_Too-Much-Curiosity.wav\r\n",
      "S05_In-Every-Major.wav\t\t     S23_Tradition-Requires-Parental.wav\r\n",
      "S05_In-The-Long.wav\t\t     S23_Try-To-Recall.wav\r\n",
      "S05_It-Took-Him.wav\t\t     S24_Almost-All-Colleges.wav\r\n",
      "S05_Military-Personnel-Are.wav\t     S24_A-Monstrous-Shadow.wav\r\n",
      "S05_Nothing-Has-Been.wav\t     S24_An-Adult-Male.wav\r\n",
      "S05_Of-Course-Dear.wav\t\t     S24_Any-Organism-That.wav\r\n",
      "S05_Only-The-Most.wav\t\t     S24_Are-You-Looking.wav\r\n",
      "S05_Pam-Gives-Driving.wav\t     S24_Before-Thursdays-Exam.wav\r\n",
      "S05_Ralph-Prepared-Red.wav\t     S24_Carl-Lives-In.wav\r\n",
      "S05_She-Had-Your.wav\t\t     S24_Combine-All-The.wav\r\n",
      "S05_Steve-Collects-Rare.wav\t     S24_Continental-Drift-Is.wav\r\n",
      "S05_The-Moisture-In.wav\t\t     S24_Did-Shawn-Catch.wav\r\n",
      "S05_The-Small-Boy.wav\t\t     S24_Dont-Ask-Me.wav\r\n",
      "S05_The-Surplus-Shoes.wav\t     S24_Gently-Place-Jims.wav\r\n",
      "S05_The-Tooth-Fairy.wav\t\t     S24_Gregory-And-Tom.wav\r\n",
      "S05_They-All-Like.wav\t\t     S24_He-Ate-Four.wav\r\n",
      "S05_They-Enjoy-It.wav\t\t     S24_He-Shrugged-Casually.wav\r\n",
      "S05_They-Were-Already.wav\t     S24_How-Oily-Do.wav\r\n",
      "S05_Those-Answers-Will.wav\t     S24_How-Permanent-Are.wav\r\n",
      "S05_Thus-Technical-Efficiency.wav    S24_In-Every-Major.wav\r\n",
      "S05_Too-Much-Curiosity.wav\t     S24_In-The-Long.wav\r\n",
      "S05_Tradition-Requires-Parental.wav  S24_It-Took-Him.wav\r\n",
      "S05_Try-To-Recall.wav\t\t     S24_Military-Personnel-Are.wav\r\n",
      "S07_Almost-All-Colleges.wav\t     S24_Nothing-Has-Been.wav\r\n",
      "S07_A-Monstrous-Shadow.wav\t     S24_Of-Course-Dear.wav\r\n",
      "S07_An-Adult-Male.wav\t\t     S24_Only-The-Most.wav\r\n",
      "S07_Any-Organism-That.wav\t     S24_Pam-Gives-Driving.wav\r\n",
      "S07_Are-You-Looking.wav\t\t     S24_Ralph-Prepared-Red.wav\r\n",
      "S07_Before-Thursdays-Exam.wav\t     S24_She-Had-Your.wav\r\n",
      "S07_Carl-Lives-In.wav\t\t     S24_Steve-Collects-Rare.wav\r\n",
      "S07_Combine-All-The.wav\t\t     S24_The-Moisture-In.wav\r\n",
      "S07_Continental-Drift-Is.wav\t     S24_The-Small-Boy.wav\r\n",
      "S07_Did-Shawn-Catch.wav\t\t     S24_The-Surplus-Shoes.wav\r\n",
      "S07_Dont-Ask-Me.wav\t\t     S24_The-Tooth-Fairy.wav\r\n",
      "S07_Gently-Place-Jims.wav\t     S24_They-All-Like.wav\r\n",
      "S07_Gregory-And-Tom.wav\t\t     S24_They-Enjoy-It.wav\r\n",
      "S07_He-Ate-Four.wav\t\t     S24_They-Were-Already.wav\r\n",
      "S07_He-Shrugged-Casually.wav\t     S24_Those-Answers-Will.wav\r\n",
      "S07_How-Oily-Do.wav\t\t     S24_Thus-Technical-Efficiency.wav\r\n",
      "S07_How-Permanent-Are.wav\t     S24_Too-Much-Curiosity.wav\r\n",
      "S07_In-Every-Major.wav\t\t     S24_Tradition-Requires-Parental.wav\r\n",
      "S07_In-The-Long.wav\t\t     S24_Try-To-Recall.wav\r\n",
      "S07_It-Took-Him.wav\t\t     S25_Almost-All-Colleges.wav\r\n",
      "S07_Military-Personnel-Are.wav\t     S25_A-Monstrous-Shadow.wav\r\n",
      "S07_Nothing-Has-Been.wav\t     S25_An-Adult-Male.wav\r\n",
      "S07_Of-Course-Dear.wav\t\t     S25_Any-Organism-That.wav\r\n",
      "S07_Only-The-Most.wav\t\t     S25_Are-You-Looking.wav\r\n",
      "S07_Pam-Gives-Driving.wav\t     S25_Before-Thursdays-Exam.wav\r\n",
      "S07_Ralph-Prepared-Red.wav\t     S25_Carl-Lives-In.wav\r\n",
      "S07_She-Had-Your.wav\t\t     S25_Combine-All-The.wav\r\n",
      "S07_Steve-Collects-Rare.wav\t     S25_Continental-Drift-Is.wav\r\n",
      "S07_The-Moisture-In.wav\t\t     S25_Did-Shawn-Catch.wav\r\n",
      "S07_The-Small-Boy.wav\t\t     S25_Dont-Ask-Me.wav\r\n",
      "S07_The-Surplus-Shoes.wav\t     S25_Gently-Place-Jims.wav\r\n",
      "S07_The-Tooth-Fairy.wav\t\t     S25_Gregory-And-Tom.wav\r\n",
      "S07_They-All-Like.wav\t\t     S25_He-Ate-Four.wav\r\n",
      "S07_They-Enjoy-It.wav\t\t     S25_He-Shrugged-Casually.wav\r\n",
      "S07_They-Were-Already.wav\t     S25_How-Oily-Do.wav\r\n",
      "S07_Those-Answers-Will.wav\t     S25_How-Permanent-Are.wav\r\n",
      "S07_Thus-Technical-Efficiency.wav    S25_In-Every-Major.wav\r\n",
      "S07_Too-Much-Curiosity.wav\t     S25_In-The-Long.wav\r\n",
      "S07_Tradition-Requires-Parental.wav  S25_It-Took-Him.wav\r\n",
      "S07_Try-To-Recall.wav\t\t     S25_Military-Personnel-Are.wav\r\n",
      "S08_Almost-All-Colleges.wav\t     S25_Nothing-Has-Been.wav\r\n",
      "S08_A-Monstrous-Shadow.wav\t     S25_Of-Course-Dear.wav\r\n",
      "S08_An-Adult-Male.wav\t\t     S25_Only-The-Most.wav\r\n",
      "S08_Any-Organism-That.wav\t     S25_Pam-Gives-Driving.wav\r\n",
      "S08_Are-You-Looking.wav\t\t     S25_Ralph-Prepared-Red.wav\r\n",
      "S08_Before-Thursdays-Exam.wav\t     S25_She-Had-Your.wav\r\n",
      "S08_Carl-Lives-In.wav\t\t     S25_Steve-Collects-Rare.wav\r\n",
      "S08_Combine-All-The.wav\t\t     S25_The-Moisture-In.wav\r\n",
      "S08_Continental-Drift-Is.wav\t     S25_The-Small-Boy.wav\r\n",
      "S08_Did-Shawn-Catch.wav\t\t     S25_The-Surplus-Shoes.wav\r\n",
      "S08_Dont-Ask-Me.wav\t\t     S25_The-Tooth-Fairy.wav\r\n",
      "S08_Gently-Place-Jims.wav\t     S25_They-All-Like.wav\r\n",
      "S08_Gregory-And-Tom.wav\t\t     S25_They-Enjoy-It.wav\r\n",
      "S08_He-Ate-Four.wav\t\t     S25_They-Were-Already.wav\r\n",
      "S08_He-Shrugged-Casually.wav\t     S25_Those-Answers-Will.wav\r\n",
      "S08_How-Oily-Do.wav\t\t     S25_Thus-Technical-Efficiency.wav\r\n",
      "S08_How-Permanent-Are.wav\t     S25_Too-Much-Curiosity.wav\r\n",
      "S08_In-Every-Major.wav\t\t     S25_Tradition-Requires-Parental.wav\r\n",
      "S08_In-The-Long.wav\t\t     S25_Try-To-Recall.wav\r\n",
      "S08_It-Took-Him.wav\t\t     S26_Almost-All-Colleges.wav\r\n",
      "S08_Military-Personnel-Are.wav\t     S26_A-Monstrous-Shadow.wav\r\n",
      "S08_Nothing-Has-Been.wav\t     S26_An-Adult-Male.wav\r\n",
      "S08_Of-Course-Dear.wav\t\t     S26_Any-Organism-That.wav\r\n",
      "S08_Only-The-Most.wav\t\t     S26_Are-You-Looking.wav\r\n",
      "S08_Pam-Gives-Driving.wav\t     S26_Before-Thursdays-Exam.wav\r\n",
      "S08_Ralph-Prepared-Red.wav\t     S26_Carl-Lives-In.wav\r\n",
      "S08_She-Had-Your.wav\t\t     S26_Combine-All-The.wav\r\n",
      "S08_Steve-Collects-Rare.wav\t     S26_Continental-Drift-Is.wav\r\n",
      "S08_The-Moisture-In.wav\t\t     S26_Did-Shawn-Catch.wav\r\n",
      "S08_The-Small-Boy.wav\t\t     S26_Dont-Ask-Me.wav\r\n",
      "S08_The-Surplus-Shoes.wav\t     S26_Gently-Place-Jims.wav\r\n",
      "S08_The-Tooth-Fairy.wav\t\t     S26_Gregory-And-Tom.wav\r\n",
      "S08_They-All-Like.wav\t\t     S26_He-Ate-Four.wav\r\n",
      "S08_They-Enjoy-It.wav\t\t     S26_He-Shrugged-Casually.wav\r\n",
      "S08_They-Were-Already.wav\t     S26_How-Oily-Do.wav\r\n",
      "S08_Those-Answers-Will.wav\t     S26_How-Permanent-Are.wav\r\n",
      "S08_Thus-Technical-Efficiency.wav    S26_In-Every-Major.wav\r\n",
      "S08_Too-Much-Curiosity.wav\t     S26_In-The-Long.wav\r\n",
      "S08_Tradition-Requires-Parental.wav  S26_It-Took-Him.wav\r\n",
      "S08_Try-To-Recall.wav\t\t     S26_Military-Personnel-Are.wav\r\n",
      "S09_Almost-All-Colleges.wav\t     S26_Nothing-Has-Been.wav\r\n",
      "S09_A-Monstrous-Shadow.wav\t     S26_Of-Course-Dear.wav\r\n",
      "S09_An-Adult-Male.wav\t\t     S26_Only-The-Most.wav\r\n",
      "S09_Any-Organism-That.wav\t     S26_Pam-Gives-Driving.wav\r\n",
      "S09_Are-You-Looking.wav\t\t     S26_Ralph-Prepared-Red.wav\r\n",
      "S09_Before-Thursdays-Exam.wav\t     S26_She-Had-Your.wav\r\n",
      "S09_Carl-Lives-In.wav\t\t     S26_Steve-Collects-Rare.wav\r\n",
      "S09_Combine-All-The.wav\t\t     S26_The-Moisture-In.wav\r\n",
      "S09_Continental-Drift-Is.wav\t     S26_The-Small-Boy.wav\r\n",
      "S09_Did-Shawn-Catch.wav\t\t     S26_The-Surplus-Shoes.wav\r\n",
      "S09_Dont-Ask-Me.wav\t\t     S26_The-Tooth-Fairy.wav\r\n",
      "S09_Gently-Place-Jims.wav\t     S26_They-All-Like.wav\r\n",
      "S09_Gregory-And-Tom.wav\t\t     S26_They-Enjoy-It.wav\r\n",
      "S09_He-Ate-Four.wav\t\t     S26_They-Were-Already.wav\r\n",
      "S09_He-Shrugged-Casually.wav\t     S26_Those-Answers-Will.wav\r\n",
      "S09_How-Oily-Do.wav\t\t     S26_Thus-Technical-Efficiency.wav\r\n",
      "S09_How-Permanent-Are.wav\t     S26_Too-Much-Curiosity.wav\r\n",
      "S09_In-Every-Major.wav\t\t     S26_Tradition-Requires-Parental.wav\r\n",
      "S09_In-The-Long.wav\t\t     S26_Try-To-Recall.wav\r\n",
      "S09_It-Took-Him.wav\t\t     S28_Almost-All-Colleges.wav\r\n",
      "S09_Military-Personnel-Are.wav\t     S28_A-Monstrous-Shadow.wav\r\n",
      "S09_Nothing-Has-Been.wav\t     S28_An-Adult-Male.wav\r\n",
      "S09_Of-Course-Dear.wav\t\t     S28_Any-Organism-That.wav\r\n",
      "S09_Only-The-Most.wav\t\t     S28_Are-You-Looking.wav\r\n",
      "S09_Pam-Gives-Driving.wav\t     S28_Before-Thursdays-Exam.wav\r\n",
      "S09_Ralph-Prepared-Red.wav\t     S28_Carl-Lives-In.wav\r\n",
      "S09_She-Had-Your.wav\t\t     S28_Combine-All-The.wav\r\n",
      "S09_Steve-Collects-Rare.wav\t     S28_Continental-Drift-Is.wav\r\n",
      "S09_The-Moisture-In.wav\t\t     S28_Did-Shawn-Catch.wav\r\n",
      "S09_The-Small-Boy.wav\t\t     S28_Dont-Ask-Me.wav\r\n",
      "S09_The-Surplus-Shoes.wav\t     S28_Gently-Place-Jims.wav\r\n",
      "S09_The-Tooth-Fairy.wav\t\t     S28_Gregory-And-Tom.wav\r\n",
      "S09_They-All-Like.wav\t\t     S28_He-Ate-Four.wav\r\n",
      "S09_They-Enjoy-It.wav\t\t     S28_He-Shrugged-Casually.wav\r\n",
      "S09_They-Were-Already.wav\t     S28_How-Oily-Do.wav\r\n",
      "S09_Those-Answers-Will.wav\t     S28_How-Permanent-Are.wav\r\n",
      "S09_Thus-Technical-Efficiency.wav    S28_In-Every-Major.wav\r\n",
      "S09_Too-Much-Curiosity.wav\t     S28_In-The-Long.wav\r\n",
      "S09_Tradition-Requires-Parental.wav  S28_It-Took-Him.wav\r\n",
      "S09_Try-To-Recall.wav\t\t     S28_Military-Personnel-Are.wav\r\n",
      "S19_Almost-All-Colleges.wav\t     S28_Nothing-Has-Been.wav\r\n",
      "S19_A-Monstrous-Shadow.wav\t     S28_Of-Course-Dear.wav\r\n",
      "S19_An-Adult-Male.wav\t\t     S28_Only-The-Most.wav\r\n",
      "S19_Any-Organism-That.wav\t     S28_Pam-Gives-Driving.wav\r\n",
      "S19_Are-You-Looking.wav\t\t     S28_Ralph-Prepared-Red.wav\r\n",
      "S19_Before-Thursdays-Exam.wav\t     S28_She-Had-Your.wav\r\n",
      "S19_Carl-Lives-In.wav\t\t     S28_Steve-Collects-Rare.wav\r\n",
      "S19_Combine-All-The.wav\t\t     S28_The-Moisture-In.wav\r\n",
      "S19_Continental-Drift-Is.wav\t     S28_The-Small-Boy.wav\r\n",
      "S19_Did-Shawn-Catch.wav\t\t     S28_The-Surplus-Shoes.wav\r\n",
      "S19_Dont-Ask-Me.wav\t\t     S28_The-Tooth-Fairy.wav\r\n",
      "S19_Gently-Place-Jims.wav\t     S28_They-All-Like.wav\r\n",
      "S19_Gregory-And-Tom.wav\t\t     S28_They-Enjoy-It.wav\r\n",
      "S19_He-Ate-Four.wav\t\t     S28_They-Were-Already.wav\r\n",
      "S19_He-Shrugged-Casually.wav\t     S28_Those-Answers-Will.wav\r\n",
      "S19_How-Oily-Do.wav\t\t     S28_Thus-Technical-Efficiency.wav\r\n",
      "S19_How-Permanent-Are.wav\t     S28_Too-Much-Curiosity.wav\r\n",
      "S19_In-Every-Major.wav\t\t     S28_Tradition-Requires-Parental.wav\r\n",
      "S19_In-The-Long.wav\t\t     S28_Try-To-Recall.wav\r\n",
      "S19_It-Took-Him.wav\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../audio/wavs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8dPlvT3kkH67"
   },
   "source": [
    "### Check wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6rbHW-B6kJy8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S09_He-Ate-Four.wav', 'S26_Those-Answers-Will.wav', 'S28_Try-To-Recall.wav', 'S03_Thus-Technical-Efficiency.wav', 'S25_Try-To-Recall.wav', 'S02_A-Monstrous-Shadow.wav', 'S21_A-Monstrous-Shadow.wav', 'S04_The-Small-Boy.wav', 'S28_Gently-Place-Jims.wav', 'S21_Military-Personnel-Are.wav']\n"
     ]
    }
   ],
   "source": [
    "audio_path = '../audio/wavs/'\n",
    "print(os.listdir(audio_path)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract mel-spectrogram and mfcc features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav2idx = {}\n",
    "melspec_dict = {}\n",
    "mfcc_dict = {}\n",
    "\n",
    "wav_names = [wav for wav in os.listdir(audio_path) if wav.endswith(\"wav\")]\n",
    "\n",
    "samples = 132300\n",
    "max_len = 0\n",
    "\n",
    "for i, w in enumerate(wav_names):\n",
    "    wav2idx[w] = i\n",
    "    wav_path = audio_path + w\n",
    "    \n",
    "    y, sr = librosa.load(wav_path) \n",
    "    \n",
    "#     sample = sr * 5\n",
    "    \n",
    "    if 0 < len(y): # workaround: 0 length causes error\n",
    "        y, _ = librosa.effects.trim(y)\n",
    "\n",
    "    if len(y) > samples: # long enough\n",
    "        y = y[0:0+samples]\n",
    "\n",
    "    else: # pad blank\n",
    "        padding = samples - len(y)\n",
    "        offset = padding // 2\n",
    "        y = np.pad(y, (offset, samples - len(y) - offset), 'constant')\n",
    "    \n",
    "    \n",
    "    mel_data = librosa.feature.melspectrogram(y = y, sr= sr)\n",
    "    mfcc_data = librosa.feature.mfcc(y = y, sr = sr, n_mfcc = 13)\n",
    "    mfcc_delta = librosa.feature.delta(mfcc_data)\n",
    "    mfcc_delta2 = librosa.feature.delta(mfcc_data, order = 2)\n",
    "\n",
    "    mfcc = np.vstack((mfcc_data, mfcc_delta, mfcc_delta2))\n",
    "#     if (np.shape(mel_data)[1] > max_len):\n",
    "#         max_len = np.shape(mel_data)[1] \n",
    "    \n",
    "    melspec_dict[i] = mel_data\n",
    "    mfcc_dict[i] = mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "110250\n",
      "(128, 259)\n",
      "(128, 259)\n",
      "(128, 259)\n",
      "(128, 259)\n",
      "(128, 259)\n",
      "(128, 259)\n",
      "(128, 259)\n",
      "(128, 259)\n",
      "(128, 259)\n",
      "(128, 259)\n"
     ]
    }
   ],
   "source": [
    "print(max_len)\n",
    "print(sr * 5)\n",
    "for i in list(melspec_dict.keys())[:10]:\n",
    "    print(melspec_dict[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/perception_results/comp_data.csv\", \"r\") as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11100, 39, 259)\n",
      "(11100,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "X_wav = []\n",
    "\n",
    "zeros = np.zeros(128)\n",
    "for i in range(1, len(data)):\n",
    "    line = data[i].rstrip()\n",
    "    \n",
    "    accented, stim, wav_name = line.split(\",\")\n",
    "    wav_idx = wav2idx[wav_name]\n",
    "    X_wav.append(wav_idx)\n",
    "    \n",
    "#     x = np.zeros(shape = (128, max_len))\n",
    "    # x_data = np.vstack((melspec_dict[wav_idx],mfcc_dict[wav_idx]))\n",
    "    x_data = mfcc_dict[wav_idx]\n",
    "\n",
    "#     print(np.shape(x), np.shape(x_data))\n",
    "    \n",
    "#     for i in range(0, np.shape(x_data)[0]):\n",
    "#         for j in range(0, np.shape(x_data)[1]):\n",
    "#             x[i][j] = x_data[i][j]\n",
    "    \n",
    "    X.append(x_data)\n",
    "    Y.append(int(accented)-1)\n",
    "\n",
    "print(np.shape(X))\n",
    "print(np.shape(Y))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11100, 39, 259)\n",
      "(11100,)\n"
     ]
    }
   ],
   "source": [
    "# reshape\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X_wav = np.array(X_wav)\n",
    "print(np.shape(X))\n",
    "print(np.shape(X_wav))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:  [510 467 571 ... 175 139  69]\n",
      "TRAIN:  [1 5 5 ... 5 2 5]\n",
      "TRAIN:  [404 454 554 ... 175 139  69]\n",
      "TRAIN:  [5 5 5 ... 2 3 2]\n",
      "TRAIN:  [404 454 554 ... 175 139  69]\n",
      "TRAIN:  [3 3 4 ... 5 5 4]\n",
      "TRAIN:  [404 454 554 ... 175 139  69]\n",
      "TRAIN:  [2 5 5 ... 5 1 1]\n",
      "TRAIN:  [404 454 554 ... 175 139  69]\n",
      "TRAIN:  [1 2 1 ... 5 5 5]\n",
      "TRAIN:  [404 454 554 ... 175 139  69]\n",
      "TRAIN:  [5 4 5 ... 1 2 5]\n",
      "TRAIN:  [404 454 554 ... 175 139  69]\n",
      "TRAIN:  [5 5 5 ... 2 2 0]\n",
      "TRAIN:  [404 454 554 ... 175 139  69]\n",
      "TRAIN:  [0 4 2 ... 2 5 5]\n",
      "TRAIN:  [404 454 554 ... 175 139  69]\n",
      "TRAIN:  [5 4 4 ... 4 3 3]\n",
      "TRAIN:  [404 454 554 ... 117 264  63]\n",
      "TRAIN:  [3 3 4 ... 4 2 3]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN: \", X_wav[train_index])\n",
    "    print(\"TRAIN: \", Y[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "drop_out_rate = 0.25\n",
    "num_dense_unit = 256\n",
    "num_epochs = 50\n",
    "\n",
    "num_mel = np.shape(X)[1]\n",
    "max_time = np.shape(X)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 39, 1024)          3162112   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 1024)              6295552   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 9,753,089\n",
      "Trainable params: 9,753,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (num_mel, max_time)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(512, return_sequences=True), input_shape = (num_mel, max_time)))\n",
    "model.add(Bidirectional(LSTM(512)))\n",
    "model.add(Dropout(drop_out_rate))\n",
    "model.add(Dense(num_dense_unit))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# use adam optimizer\n",
    "adam = keras.optimizers.Adam(lr = lr)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=adam, loss=\"mse\", metrics=[\"mse\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "logdir = \"logs/scalars/CV_COMP\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_mse = []\n",
    "CV_histories = []\n",
    "CV_prediction = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "\n",
    "cv_idx = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    model_name = \"../data/CV_comp_rnn_mfcc_40_CV%d.h5\" % (cv_idx)\n",
    "#     model.load_weights(model_name)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    X_train_wav, X_test_wav = X_wav[train_index], X_wav[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    history = model.fit(X_train, y_train, batch_size = batch_size, epochs = num_epochs, shuffle = False,\n",
    "                       class_weight = None, verbose = 1, validation_data = (X_test, y_test), \n",
    "                       callbacks = [tensorboard_callback])\n",
    "    CV_histories.append(history)\n",
    "            \n",
    "    model.save(model_name)\n",
    "    \n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    CV_mse.append(scores[1])\n",
    "    y_prediction = model.predict(X_test)\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        result = \"%d\\t%s\\t%d\\t%f\\n\" % (cv_idx, wav_names[X_test_wav[i]], y_test[i], y_prediction[i][0])\n",
    "#         print(result)\n",
    "        CV_prediction.append(result)\n",
    "    \n",
    "    cv_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"MSE: %.5f\" % (scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, mse in enumerate(CV_mse[-10:]):\n",
    "    print(i + 1, mse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results/comp_mfcc_10CV.txt\", \"w\") as output:\n",
    "    for prediction in CV_prediction:\n",
    "        output.write(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "\n",
    "for history in CV_histories[-10:]:\n",
    "    plt.plot(history.history['loss'])\n",
    "    \n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result looks like the model gets stable after 20 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test the model with Mel-Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10806, 128, 259)\n",
      "(10806,)\n"
     ]
    }
   ],
   "source": [
    "X_mel = []\n",
    "X_wav = []\n",
    "Y = []\n",
    "\n",
    "zeros = np.zeros(128)\n",
    "for i in range(1, len(data)):\n",
    "    line = data[i].rstrip()\n",
    "    \n",
    "    accented, stim, wav_name = line.split(\",\")\n",
    "    wav_idx = wav2idx[wav_name]\n",
    "    X_wav.append(wav_idx)\n",
    "\n",
    "    x_data = melspec_dict[wav_idx]\n",
    "\n",
    "    X_mel.append(x_data)\n",
    "    Y.append(int(accented)-1)\n",
    "\n",
    "print(np.shape(X_mel))\n",
    "print(np.shape(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10806, 128, 259)\n",
      "(10806,)\n"
     ]
    }
   ],
   "source": [
    "# reshape\n",
    "X_mel = np.array(X_mel)\n",
    "X_wav = np.array(X_wav)\n",
    "Y = np.array(Y)\n",
    "\n",
    "# X_train = X_train.reshape(X_train.shape[0], max_time, num_mel, 1)\n",
    "# X_test = X_test.reshape(X_test.shape[0], max_time, num_mel, 1)\n",
    "\n",
    "\n",
    "\n",
    "print(np.shape(X_mel))\n",
    "print(np.shape(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:  [[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[2.0017268e-03 6.0102041e-03 2.9307615e-02 ... 1.3972856e-03\n",
      "   4.1934382e-03 5.3188771e-02]\n",
      "  [2.4821896e-03 2.4255083e-03 1.1600483e-02 ... 2.9206700e-03\n",
      "   2.2063912e-03 3.0219160e-02]\n",
      "  [2.8413531e-04 1.3192802e-03 6.8252613e-03 ... 3.1541933e-03\n",
      "   1.5349960e-03 1.6189046e-02]\n",
      "  ...\n",
      "  [3.3742728e-07 7.7856998e-07 4.9746827e-06 ... 4.2269784e-07\n",
      "   5.3897134e-07 2.6763573e-06]\n",
      "  [8.4673395e-08 1.6515568e-07 9.5097442e-07 ... 2.0189812e-07\n",
      "   3.4928900e-07 2.5276822e-06]\n",
      "  [1.1414482e-08 2.6347683e-08 2.6530094e-07 ... 1.1812353e-08\n",
      "   1.1859876e-07 2.0209584e-06]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]]\n",
      "TRAIN:  [218 533 283 ...  15 577  71]\n",
      "TRAIN:  [4 5 4 ... 5 5 5]\n",
      "TRAIN:  [[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[2.0017268e-03 6.0102041e-03 2.9307615e-02 ... 1.3972856e-03\n",
      "   4.1934382e-03 5.3188771e-02]\n",
      "  [2.4821896e-03 2.4255083e-03 1.1600483e-02 ... 2.9206700e-03\n",
      "   2.2063912e-03 3.0219160e-02]\n",
      "  [2.8413531e-04 1.3192802e-03 6.8252613e-03 ... 3.1541933e-03\n",
      "   1.5349960e-03 1.6189046e-02]\n",
      "  ...\n",
      "  [3.3742728e-07 7.7856998e-07 4.9746827e-06 ... 4.2269784e-07\n",
      "   5.3897134e-07 2.6763573e-06]\n",
      "  [8.4673395e-08 1.6515568e-07 9.5097442e-07 ... 2.0189812e-07\n",
      "   3.4928900e-07 2.5276822e-06]\n",
      "  [1.1414482e-08 2.6347683e-08 2.6530094e-07 ... 1.1812353e-08\n",
      "   1.1859876e-07 2.0209584e-06]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]]\n",
      "TRAIN:  [223 599 565 ...  15 577  71]\n",
      "TRAIN:  [5 5 4 ... 1 4 0]\n",
      "TRAIN:  [[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[2.0017268e-03 6.0102041e-03 2.9307615e-02 ... 1.3972856e-03\n",
      "   4.1934382e-03 5.3188771e-02]\n",
      "  [2.4821896e-03 2.4255083e-03 1.1600483e-02 ... 2.9206700e-03\n",
      "   2.2063912e-03 3.0219160e-02]\n",
      "  [2.8413531e-04 1.3192802e-03 6.8252613e-03 ... 3.1541933e-03\n",
      "   1.5349960e-03 1.6189046e-02]\n",
      "  ...\n",
      "  [3.3742728e-07 7.7856998e-07 4.9746827e-06 ... 4.2269784e-07\n",
      "   5.3897134e-07 2.6763573e-06]\n",
      "  [8.4673395e-08 1.6515568e-07 9.5097442e-07 ... 2.0189812e-07\n",
      "   3.4928900e-07 2.5276822e-06]\n",
      "  [1.1414482e-08 2.6347683e-08 2.6530094e-07 ... 1.1812353e-08\n",
      "   1.1859876e-07 2.0209584e-06]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]]\n",
      "TRAIN:  [223 599 565 ...  15 577  71]\n",
      "TRAIN:  [0 1 0 ... 5 2 2]\n",
      "TRAIN:  [[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[2.0017268e-03 6.0102041e-03 2.9307615e-02 ... 1.3972856e-03\n",
      "   4.1934382e-03 5.3188771e-02]\n",
      "  [2.4821896e-03 2.4255083e-03 1.1600483e-02 ... 2.9206700e-03\n",
      "   2.2063912e-03 3.0219160e-02]\n",
      "  [2.8413531e-04 1.3192802e-03 6.8252613e-03 ... 3.1541933e-03\n",
      "   1.5349960e-03 1.6189046e-02]\n",
      "  ...\n",
      "  [3.3742728e-07 7.7856998e-07 4.9746827e-06 ... 4.2269784e-07\n",
      "   5.3897134e-07 2.6763573e-06]\n",
      "  [8.4673395e-08 1.6515568e-07 9.5097442e-07 ... 2.0189812e-07\n",
      "   3.4928900e-07 2.5276822e-06]\n",
      "  [1.1414482e-08 2.6347683e-08 2.6530094e-07 ... 1.1812353e-08\n",
      "   1.1859876e-07 2.0209584e-06]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]]\n",
      "TRAIN:  [223 599 565 ...  15 577  71]\n",
      "TRAIN:  [5 2 4 ... 0 1 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:  [[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[2.0017268e-03 6.0102041e-03 2.9307615e-02 ... 1.3972856e-03\n",
      "   4.1934382e-03 5.3188771e-02]\n",
      "  [2.4821896e-03 2.4255083e-03 1.1600483e-02 ... 2.9206700e-03\n",
      "   2.2063912e-03 3.0219160e-02]\n",
      "  [2.8413531e-04 1.3192802e-03 6.8252613e-03 ... 3.1541933e-03\n",
      "   1.5349960e-03 1.6189046e-02]\n",
      "  ...\n",
      "  [3.3742728e-07 7.7856998e-07 4.9746827e-06 ... 4.2269784e-07\n",
      "   5.3897134e-07 2.6763573e-06]\n",
      "  [8.4673395e-08 1.6515568e-07 9.5097442e-07 ... 2.0189812e-07\n",
      "   3.4928900e-07 2.5276822e-06]\n",
      "  [1.1414482e-08 2.6347683e-08 2.6530094e-07 ... 1.1812353e-08\n",
      "   1.1859876e-07 2.0209584e-06]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]]\n",
      "TRAIN:  [223 599 565 ...  15 577  71]\n",
      "TRAIN:  [1 5 5 ... 5 2 3]\n",
      "TRAIN:  [[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[2.0017268e-03 6.0102041e-03 2.9307615e-02 ... 1.3972856e-03\n",
      "   4.1934382e-03 5.3188771e-02]\n",
      "  [2.4821896e-03 2.4255083e-03 1.1600483e-02 ... 2.9206700e-03\n",
      "   2.2063912e-03 3.0219160e-02]\n",
      "  [2.8413531e-04 1.3192802e-03 6.8252613e-03 ... 3.1541933e-03\n",
      "   1.5349960e-03 1.6189046e-02]\n",
      "  ...\n",
      "  [3.3742728e-07 7.7856998e-07 4.9746827e-06 ... 4.2269784e-07\n",
      "   5.3897134e-07 2.6763573e-06]\n",
      "  [8.4673395e-08 1.6515568e-07 9.5097442e-07 ... 2.0189812e-07\n",
      "   3.4928900e-07 2.5276822e-06]\n",
      "  [1.1414482e-08 2.6347683e-08 2.6530094e-07 ... 1.1812353e-08\n",
      "   1.1859876e-07 2.0209584e-06]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]]\n",
      "TRAIN:  [223 599 565 ...  15 577  71]\n",
      "TRAIN:  [1 2 4 ... 5 0 5]\n",
      "TRAIN:  [[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[2.0017268e-03 6.0102041e-03 2.9307615e-02 ... 1.3972856e-03\n",
      "   4.1934382e-03 5.3188771e-02]\n",
      "  [2.4821896e-03 2.4255083e-03 1.1600483e-02 ... 2.9206700e-03\n",
      "   2.2063912e-03 3.0219160e-02]\n",
      "  [2.8413531e-04 1.3192802e-03 6.8252613e-03 ... 3.1541933e-03\n",
      "   1.5349960e-03 1.6189046e-02]\n",
      "  ...\n",
      "  [3.3742728e-07 7.7856998e-07 4.9746827e-06 ... 4.2269784e-07\n",
      "   5.3897134e-07 2.6763573e-06]\n",
      "  [8.4673395e-08 1.6515568e-07 9.5097442e-07 ... 2.0189812e-07\n",
      "   3.4928900e-07 2.5276822e-06]\n",
      "  [1.1414482e-08 2.6347683e-08 2.6530094e-07 ... 1.1812353e-08\n",
      "   1.1859876e-07 2.0209584e-06]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]]\n",
      "TRAIN:  [223 599 565 ...  15 577  71]\n",
      "TRAIN:  [2 1 2 ... 4 0 5]\n",
      "TRAIN:  [[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[2.0017268e-03 6.0102041e-03 2.9307615e-02 ... 1.3972856e-03\n",
      "   4.1934382e-03 5.3188771e-02]\n",
      "  [2.4821896e-03 2.4255083e-03 1.1600483e-02 ... 2.9206700e-03\n",
      "   2.2063912e-03 3.0219160e-02]\n",
      "  [2.8413531e-04 1.3192802e-03 6.8252613e-03 ... 3.1541933e-03\n",
      "   1.5349960e-03 1.6189046e-02]\n",
      "  ...\n",
      "  [3.3742728e-07 7.7856998e-07 4.9746827e-06 ... 4.2269784e-07\n",
      "   5.3897134e-07 2.6763573e-06]\n",
      "  [8.4673395e-08 1.6515568e-07 9.5097442e-07 ... 2.0189812e-07\n",
      "   3.4928900e-07 2.5276822e-06]\n",
      "  [1.1414482e-08 2.6347683e-08 2.6530094e-07 ... 1.1812353e-08\n",
      "   1.1859876e-07 2.0209584e-06]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:  [223 599 565 ...  15 577  71]\n",
      "TRAIN:  [5 0 1 ... 2 2 2]\n",
      "TRAIN:  [[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[2.0017268e-03 6.0102041e-03 2.9307615e-02 ... 1.3972856e-03\n",
      "   4.1934382e-03 5.3188771e-02]\n",
      "  [2.4821896e-03 2.4255083e-03 1.1600483e-02 ... 2.9206700e-03\n",
      "   2.2063912e-03 3.0219160e-02]\n",
      "  [2.8413531e-04 1.3192802e-03 6.8252613e-03 ... 3.1541933e-03\n",
      "   1.5349960e-03 1.6189046e-02]\n",
      "  ...\n",
      "  [3.3742728e-07 7.7856998e-07 4.9746827e-06 ... 4.2269784e-07\n",
      "   5.3897134e-07 2.6763573e-06]\n",
      "  [8.4673395e-08 1.6515568e-07 9.5097442e-07 ... 2.0189812e-07\n",
      "   3.4928900e-07 2.5276822e-06]\n",
      "  [1.1414482e-08 2.6347683e-08 2.6530094e-07 ... 1.1812353e-08\n",
      "   1.1859876e-07 2.0209584e-06]]\n",
      "\n",
      " [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  ...\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00]]]\n",
      "TRAIN:  [223 599 565 ...  15 577  71]\n",
      "TRAIN:  [1 3 5 ... 5 1 1]\n",
      "TRAIN:  [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  ...\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  ...\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  ...\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  ...\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[0.00000000e+00 4.66478814e-04 6.71543600e-03 ... 1.65265892e-02\n",
      "   3.12485197e-03 1.02321337e-06]\n",
      "  [0.00000000e+00 2.42003327e-04 3.18872696e-03 ... 5.48427552e-03\n",
      "   1.23172393e-03 8.79027823e-07]\n",
      "  [0.00000000e+00 7.18440133e-05 1.25221990e-03 ... 1.29771058e-03\n",
      "   1.19298624e-04 6.39821508e-07]\n",
      "  ...\n",
      "  [0.00000000e+00 5.39975487e-09 9.16192633e-08 ... 3.01800810e-07\n",
      "   9.13402260e-08 4.16609525e-10]\n",
      "  [0.00000000e+00 2.20866236e-09 5.63806282e-08 ... 9.51692627e-08\n",
      "   3.84337611e-08 2.34133657e-10]\n",
      "  [0.00000000e+00 1.99862987e-10 6.54189991e-09 ... 4.42093580e-08\n",
      "   2.42872744e-08 1.77101916e-10]]\n",
      "\n",
      " [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  ...\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]]\n",
      "TRAIN:  [223 599 565 ... 536 102 455]\n",
      "TRAIN:  [0 5 0 ... 2 2 3]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN: \", X_mel[train_index])\n",
    "    print(\"TRAIN: \", X_wav[train_index])\n",
    "    print(\"TRAIN: \", Y[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "drop_out_rate = 0.25\n",
    "num_dense_unit = 256\n",
    "num_epochs = 50\n",
    "\n",
    "num_melspec = np.shape(X_mel)[1]\n",
    "max_time = np.shape(X_mel)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_3 (Bidirection (None, 128, 1024)         3162112   \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 1024)              6295552   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 9,753,089\n",
      "Trainable params: 9,753,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (num_melspec, max_time)\n",
    "\n",
    "model_mel = Sequential()\n",
    "\n",
    "model_mel.add(Bidirectional(LSTM(512, return_sequences=True), input_shape = (num_melspec, max_time)))\n",
    "model_mel.add(Bidirectional(LSTM(512)))\n",
    "model_mel.add(Dropout(drop_out_rate))\n",
    "model_mel.add(Dense(num_dense_unit))\n",
    "model_mel.add(Dense(128))\n",
    "model_mel.add(Dense(1, activation='linear'))\n",
    "\n",
    "# use adam optimizer\n",
    "adam = keras.optimizers.Adam(lr = lr)\n",
    "\n",
    "# compile the model\n",
    "model_mel.compile(optimizer=adam, loss=\"mse\", metrics=[\"mse\"])\n",
    "\n",
    "model_mel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "logdir = \"logs/scalars/melspec_CV_ACC\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_mel_mse = []\n",
    "CV_mel_histories = []\n",
    "CV_mel_prediction = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9725 samples, validate on 1081 samples\n",
      "Epoch 1/40\n",
      "9725/9725 [==============================] - 73s 7ms/step - loss: 2.5238 - mean_squared_error: 2.5238 - val_loss: 3.6068 - val_mean_squared_error: 3.6068\n",
      "Epoch 2/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 2.1608 - mean_squared_error: 2.1608 - val_loss: 3.2893 - val_mean_squared_error: 3.2893\n",
      "Epoch 3/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.7719 - mean_squared_error: 1.7719 - val_loss: 2.1613 - val_mean_squared_error: 2.1613\n",
      "Epoch 4/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.6159 - mean_squared_error: 1.6159 - val_loss: 1.7432 - val_mean_squared_error: 1.7432\n",
      "Epoch 5/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.5607 - mean_squared_error: 1.5607 - val_loss: 1.5840 - val_mean_squared_error: 1.5840\n",
      "Epoch 6/40\n",
      "9725/9725 [==============================] - 72s 7ms/step - loss: 1.5116 - mean_squared_error: 1.5116 - val_loss: 1.6032 - val_mean_squared_error: 1.6032\n",
      "Epoch 7/40\n",
      "9725/9725 [==============================] - 73s 7ms/step - loss: 1.4964 - mean_squared_error: 1.4964 - val_loss: 1.4687 - val_mean_squared_error: 1.4687\n",
      "Epoch 8/40\n",
      "9725/9725 [==============================] - 72s 7ms/step - loss: 1.4666 - mean_squared_error: 1.4666 - val_loss: 1.3774 - val_mean_squared_error: 1.3774\n",
      "Epoch 9/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.4524 - mean_squared_error: 1.4524 - val_loss: 1.3331 - val_mean_squared_error: 1.3331\n",
      "Epoch 10/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.4520 - mean_squared_error: 1.4520 - val_loss: 1.4236 - val_mean_squared_error: 1.4236\n",
      "Epoch 11/40\n",
      "9725/9725 [==============================] - 73s 7ms/step - loss: 1.4366 - mean_squared_error: 1.4366 - val_loss: 1.3605 - val_mean_squared_error: 1.3605\n",
      "Epoch 12/40\n",
      "9725/9725 [==============================] - 72s 7ms/step - loss: 1.4353 - mean_squared_error: 1.4353 - val_loss: 1.3543 - val_mean_squared_error: 1.3543\n",
      "Epoch 13/40\n",
      "9725/9725 [==============================] - 72s 7ms/step - loss: 1.4176 - mean_squared_error: 1.4176 - val_loss: 1.2997 - val_mean_squared_error: 1.2997\n",
      "Epoch 14/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3937 - mean_squared_error: 1.3937 - val_loss: 1.3149 - val_mean_squared_error: 1.3149\n",
      "Epoch 15/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3962 - mean_squared_error: 1.3962 - val_loss: 1.3183 - val_mean_squared_error: 1.3183\n",
      "Epoch 16/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3903 - mean_squared_error: 1.3903 - val_loss: 1.3131 - val_mean_squared_error: 1.3131\n",
      "Epoch 17/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3802 - mean_squared_error: 1.3802 - val_loss: 1.3109 - val_mean_squared_error: 1.3109\n",
      "Epoch 18/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3785 - mean_squared_error: 1.3785 - val_loss: 1.3023 - val_mean_squared_error: 1.3023\n",
      "Epoch 19/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3879 - mean_squared_error: 1.3879 - val_loss: 1.3693 - val_mean_squared_error: 1.3693\n",
      "Epoch 20/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3945 - mean_squared_error: 1.3945 - val_loss: 1.3295 - val_mean_squared_error: 1.3295\n",
      "Epoch 21/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3902 - mean_squared_error: 1.3902 - val_loss: 1.3778 - val_mean_squared_error: 1.3778\n",
      "Epoch 22/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3684 - mean_squared_error: 1.3684 - val_loss: 1.3541 - val_mean_squared_error: 1.3541\n",
      "Epoch 23/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3655 - mean_squared_error: 1.3655 - val_loss: 1.3614 - val_mean_squared_error: 1.3614\n",
      "Epoch 24/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3624 - mean_squared_error: 1.3624 - val_loss: 1.3809 - val_mean_squared_error: 1.3809\n",
      "Epoch 25/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3708 - mean_squared_error: 1.3708 - val_loss: 1.3803 - val_mean_squared_error: 1.3803\n",
      "Epoch 26/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3644 - mean_squared_error: 1.3644 - val_loss: 1.4017 - val_mean_squared_error: 1.4017\n",
      "Epoch 27/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3730 - mean_squared_error: 1.3730 - val_loss: 1.3914 - val_mean_squared_error: 1.3914\n",
      "Epoch 28/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3531 - mean_squared_error: 1.3531 - val_loss: 1.4505 - val_mean_squared_error: 1.4505\n",
      "Epoch 29/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3506 - mean_squared_error: 1.3506 - val_loss: 1.4160 - val_mean_squared_error: 1.4160\n",
      "Epoch 30/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3496 - mean_squared_error: 1.3496 - val_loss: 1.4244 - val_mean_squared_error: 1.4244\n",
      "Epoch 31/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3435 - mean_squared_error: 1.3435 - val_loss: 1.4332 - val_mean_squared_error: 1.4332\n",
      "Epoch 32/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3552 - mean_squared_error: 1.3552 - val_loss: 1.4325 - val_mean_squared_error: 1.4325\n",
      "Epoch 33/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3363 - mean_squared_error: 1.3363 - val_loss: 1.4338 - val_mean_squared_error: 1.4338\n",
      "Epoch 34/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3428 - mean_squared_error: 1.3428 - val_loss: 1.4120 - val_mean_squared_error: 1.4120\n",
      "Epoch 35/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3380 - mean_squared_error: 1.3380 - val_loss: 1.3979 - val_mean_squared_error: 1.3979\n",
      "Epoch 36/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3300 - mean_squared_error: 1.3300 - val_loss: 1.4329 - val_mean_squared_error: 1.4329\n",
      "Epoch 37/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3232 - mean_squared_error: 1.3232 - val_loss: 1.4031 - val_mean_squared_error: 1.4031\n",
      "Epoch 38/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3302 - mean_squared_error: 1.3302 - val_loss: 1.4258 - val_mean_squared_error: 1.4258\n",
      "Epoch 39/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3286 - mean_squared_error: 1.3286 - val_loss: 1.4346 - val_mean_squared_error: 1.4346\n",
      "Epoch 40/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3285 - mean_squared_error: 1.3285 - val_loss: 1.4038 - val_mean_squared_error: 1.4038\n",
      "Train on 9725 samples, validate on 1081 samples\n",
      "Epoch 1/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3649 - mean_squared_error: 1.3649 - val_loss: 1.0396 - val_mean_squared_error: 1.0396\n",
      "Epoch 2/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3527 - mean_squared_error: 1.3527 - val_loss: 1.0582 - val_mean_squared_error: 1.0582\n",
      "Epoch 3/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3571 - mean_squared_error: 1.3571 - val_loss: 1.0549 - val_mean_squared_error: 1.0549\n",
      "Epoch 4/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3772 - mean_squared_error: 1.3772 - val_loss: 1.0782 - val_mean_squared_error: 1.0782\n",
      "Epoch 5/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3631 - mean_squared_error: 1.3631 - val_loss: 1.0996 - val_mean_squared_error: 1.0996\n",
      "Epoch 6/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3532 - mean_squared_error: 1.3532 - val_loss: 1.0932 - val_mean_squared_error: 1.0932\n",
      "Epoch 7/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3497 - mean_squared_error: 1.3497 - val_loss: 1.0778 - val_mean_squared_error: 1.0778\n",
      "Epoch 8/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3466 - mean_squared_error: 1.3466 - val_loss: 1.0866 - val_mean_squared_error: 1.0866\n",
      "Epoch 9/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3489 - mean_squared_error: 1.3489 - val_loss: 1.1085 - val_mean_squared_error: 1.1085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3404 - mean_squared_error: 1.3404 - val_loss: 1.0992 - val_mean_squared_error: 1.0992\n",
      "Epoch 11/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3489 - mean_squared_error: 1.3489 - val_loss: 1.0926 - val_mean_squared_error: 1.0926\n",
      "Epoch 12/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3483 - mean_squared_error: 1.3483 - val_loss: 1.1188 - val_mean_squared_error: 1.1188\n",
      "Epoch 13/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3416 - mean_squared_error: 1.3416 - val_loss: 1.1124 - val_mean_squared_error: 1.1124\n",
      "Epoch 14/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3409 - mean_squared_error: 1.3409 - val_loss: 1.1213 - val_mean_squared_error: 1.1213\n",
      "Epoch 15/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3356 - mean_squared_error: 1.3356 - val_loss: 1.1558 - val_mean_squared_error: 1.1558\n",
      "Epoch 16/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3485 - mean_squared_error: 1.3485 - val_loss: 1.1677 - val_mean_squared_error: 1.1677\n",
      "Epoch 17/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3414 - mean_squared_error: 1.3414 - val_loss: 1.1825 - val_mean_squared_error: 1.1825\n",
      "Epoch 18/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3502 - mean_squared_error: 1.3502 - val_loss: 1.1547 - val_mean_squared_error: 1.1547\n",
      "Epoch 19/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3420 - mean_squared_error: 1.3420 - val_loss: 1.1545 - val_mean_squared_error: 1.1545\n",
      "Epoch 20/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3534 - mean_squared_error: 1.3534 - val_loss: 1.1570 - val_mean_squared_error: 1.1570\n",
      "Epoch 21/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3466 - mean_squared_error: 1.3466 - val_loss: 1.1569 - val_mean_squared_error: 1.1569\n",
      "Epoch 22/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3450 - mean_squared_error: 1.3450 - val_loss: 1.1926 - val_mean_squared_error: 1.1926\n",
      "Epoch 23/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3447 - mean_squared_error: 1.3447 - val_loss: 1.1532 - val_mean_squared_error: 1.1532\n",
      "Epoch 24/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3376 - mean_squared_error: 1.3376 - val_loss: 1.1746 - val_mean_squared_error: 1.1746\n",
      "Epoch 25/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3402 - mean_squared_error: 1.3402 - val_loss: 1.1394 - val_mean_squared_error: 1.1394\n",
      "Epoch 26/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.4465 - mean_squared_error: 1.4465 - val_loss: 1.9675 - val_mean_squared_error: 1.9675\n",
      "Epoch 27/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.5267 - mean_squared_error: 1.5267 - val_loss: 1.1234 - val_mean_squared_error: 1.1234\n",
      "Epoch 28/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3995 - mean_squared_error: 1.3995 - val_loss: 1.1687 - val_mean_squared_error: 1.1687\n",
      "Epoch 29/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3685 - mean_squared_error: 1.3685 - val_loss: 1.1771 - val_mean_squared_error: 1.1771\n",
      "Epoch 30/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3529 - mean_squared_error: 1.3529 - val_loss: 1.1782 - val_mean_squared_error: 1.1782\n",
      "Epoch 31/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3472 - mean_squared_error: 1.3472 - val_loss: 1.1692 - val_mean_squared_error: 1.1692\n",
      "Epoch 32/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3426 - mean_squared_error: 1.3426 - val_loss: 1.1811 - val_mean_squared_error: 1.1811\n",
      "Epoch 33/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3348 - mean_squared_error: 1.3348 - val_loss: 1.1788 - val_mean_squared_error: 1.1788\n",
      "Epoch 34/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3412 - mean_squared_error: 1.3412 - val_loss: 1.1829 - val_mean_squared_error: 1.1829\n",
      "Epoch 35/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3422 - mean_squared_error: 1.3422 - val_loss: 1.2162 - val_mean_squared_error: 1.2162\n",
      "Epoch 36/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3410 - mean_squared_error: 1.3410 - val_loss: 1.2210 - val_mean_squared_error: 1.2210\n",
      "Epoch 37/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3426 - mean_squared_error: 1.3426 - val_loss: 1.2291 - val_mean_squared_error: 1.2291\n",
      "Epoch 38/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3413 - mean_squared_error: 1.3413 - val_loss: 1.2193 - val_mean_squared_error: 1.2193\n",
      "Epoch 39/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3469 - mean_squared_error: 1.3469 - val_loss: 1.2300 - val_mean_squared_error: 1.2300\n",
      "Epoch 40/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3447 - mean_squared_error: 1.3447 - val_loss: 1.1821 - val_mean_squared_error: 1.1821\n",
      "Train on 9725 samples, validate on 1081 samples\n",
      "Epoch 1/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3491 - mean_squared_error: 1.3491 - val_loss: 1.1291 - val_mean_squared_error: 1.1291\n",
      "Epoch 2/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3425 - mean_squared_error: 1.3425 - val_loss: 1.1106 - val_mean_squared_error: 1.1106\n",
      "Epoch 3/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3424 - mean_squared_error: 1.3424 - val_loss: 1.1480 - val_mean_squared_error: 1.1480\n",
      "Epoch 4/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3446 - mean_squared_error: 1.3446 - val_loss: 1.1748 - val_mean_squared_error: 1.1748\n",
      "Epoch 5/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3419 - mean_squared_error: 1.3419 - val_loss: 1.1841 - val_mean_squared_error: 1.1841\n",
      "Epoch 6/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3354 - mean_squared_error: 1.3354 - val_loss: 1.1818 - val_mean_squared_error: 1.1818\n",
      "Epoch 7/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3435 - mean_squared_error: 1.3435 - val_loss: 1.2236 - val_mean_squared_error: 1.2236\n",
      "Epoch 8/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3491 - mean_squared_error: 1.3491 - val_loss: 1.2185 - val_mean_squared_error: 1.2185\n",
      "Epoch 9/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3342 - mean_squared_error: 1.3342 - val_loss: 1.1377 - val_mean_squared_error: 1.1377\n",
      "Epoch 10/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3401 - mean_squared_error: 1.3401 - val_loss: 1.2188 - val_mean_squared_error: 1.2188\n",
      "Epoch 11/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3411 - mean_squared_error: 1.3411 - val_loss: 1.2329 - val_mean_squared_error: 1.2329\n",
      "Epoch 12/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3492 - mean_squared_error: 1.3492 - val_loss: 1.2542 - val_mean_squared_error: 1.2542\n",
      "Epoch 13/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3427 - mean_squared_error: 1.3427 - val_loss: 1.2421 - val_mean_squared_error: 1.2421\n",
      "Epoch 14/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3393 - mean_squared_error: 1.3393 - val_loss: 1.2529 - val_mean_squared_error: 1.2529\n",
      "Epoch 15/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3378 - mean_squared_error: 1.3378 - val_loss: 1.2642 - val_mean_squared_error: 1.2642\n",
      "Epoch 16/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3470 - mean_squared_error: 1.3470 - val_loss: 1.2465 - val_mean_squared_error: 1.2465\n",
      "Epoch 17/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3383 - mean_squared_error: 1.3383 - val_loss: 1.2442 - val_mean_squared_error: 1.2442\n",
      "Epoch 18/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3379 - mean_squared_error: 1.3379 - val_loss: 1.2435 - val_mean_squared_error: 1.2435\n",
      "Epoch 19/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3295 - mean_squared_error: 1.3295 - val_loss: 1.2430 - val_mean_squared_error: 1.2430\n",
      "Epoch 20/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3279 - mean_squared_error: 1.3279 - val_loss: 1.2622 - val_mean_squared_error: 1.2622\n",
      "Epoch 21/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3290 - mean_squared_error: 1.3290 - val_loss: 1.2545 - val_mean_squared_error: 1.2545\n",
      "Epoch 22/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3315 - mean_squared_error: 1.3315 - val_loss: 1.2496 - val_mean_squared_error: 1.2496\n",
      "Epoch 23/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3349 - mean_squared_error: 1.3349 - val_loss: 1.2694 - val_mean_squared_error: 1.2694\n",
      "Epoch 24/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3395 - mean_squared_error: 1.3395 - val_loss: 1.2049 - val_mean_squared_error: 1.2049\n",
      "Epoch 25/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3359 - mean_squared_error: 1.3359 - val_loss: 1.2793 - val_mean_squared_error: 1.2793\n",
      "Epoch 26/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3446 - mean_squared_error: 1.3446 - val_loss: 1.2698 - val_mean_squared_error: 1.2698\n",
      "Epoch 27/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3437 - mean_squared_error: 1.3437 - val_loss: 1.3132 - val_mean_squared_error: 1.3132\n",
      "Epoch 28/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3295 - mean_squared_error: 1.3295 - val_loss: 1.2861 - val_mean_squared_error: 1.2861\n",
      "Epoch 29/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3242 - mean_squared_error: 1.3242 - val_loss: 1.2575 - val_mean_squared_error: 1.2575\n",
      "Epoch 30/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3247 - mean_squared_error: 1.3247 - val_loss: 1.2592 - val_mean_squared_error: 1.2592\n",
      "Epoch 31/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3474 - mean_squared_error: 1.3474 - val_loss: 1.0952 - val_mean_squared_error: 1.0952\n",
      "Epoch 32/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3366 - mean_squared_error: 1.3366 - val_loss: 1.1198 - val_mean_squared_error: 1.1198\n",
      "Epoch 33/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3264 - mean_squared_error: 1.3264 - val_loss: 1.2368 - val_mean_squared_error: 1.2368\n",
      "Epoch 34/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3252 - mean_squared_error: 1.3252 - val_loss: 1.3174 - val_mean_squared_error: 1.3174\n",
      "Epoch 35/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3306 - mean_squared_error: 1.3306 - val_loss: 1.2703 - val_mean_squared_error: 1.2703\n",
      "Epoch 36/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3261 - mean_squared_error: 1.3261 - val_loss: 1.2828 - val_mean_squared_error: 1.2828\n",
      "Epoch 37/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3296 - mean_squared_error: 1.3296 - val_loss: 1.2850 - val_mean_squared_error: 1.2850\n",
      "Epoch 38/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3310 - mean_squared_error: 1.3310 - val_loss: 1.2892 - val_mean_squared_error: 1.2892\n",
      "Epoch 39/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3215 - mean_squared_error: 1.3215 - val_loss: 1.2855 - val_mean_squared_error: 1.2855\n",
      "Epoch 40/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3395 - mean_squared_error: 1.3395 - val_loss: 1.2999 - val_mean_squared_error: 1.2999\n",
      "Train on 9725 samples, validate on 1081 samples\n",
      "Epoch 1/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.2424 - mean_squared_error: 1.2424 - val_loss: 2.1923 - val_mean_squared_error: 2.1923\n",
      "Epoch 2/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2344 - mean_squared_error: 1.2344 - val_loss: 2.2541 - val_mean_squared_error: 2.2541\n",
      "Epoch 3/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2025 - mean_squared_error: 1.2025 - val_loss: 1.6278 - val_mean_squared_error: 1.6278\n",
      "Epoch 4/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2700 - mean_squared_error: 1.2700 - val_loss: 2.2567 - val_mean_squared_error: 2.2567\n",
      "Epoch 5/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2129 - mean_squared_error: 1.2129 - val_loss: 2.4901 - val_mean_squared_error: 2.4901\n",
      "Epoch 6/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2065 - mean_squared_error: 1.2065 - val_loss: 2.4909 - val_mean_squared_error: 2.4909\n",
      "Epoch 7/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2049 - mean_squared_error: 1.2049 - val_loss: 2.5249 - val_mean_squared_error: 2.5249\n",
      "Epoch 8/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2133 - mean_squared_error: 1.2133 - val_loss: 2.5526 - val_mean_squared_error: 2.5526\n",
      "Epoch 9/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2127 - mean_squared_error: 1.2127 - val_loss: 2.5500 - val_mean_squared_error: 2.5500\n",
      "Epoch 10/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2080 - mean_squared_error: 1.2080 - val_loss: 2.5241 - val_mean_squared_error: 2.5241\n",
      "Epoch 11/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2081 - mean_squared_error: 1.2081 - val_loss: 2.3847 - val_mean_squared_error: 2.3847\n",
      "Epoch 12/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2121 - mean_squared_error: 1.2121 - val_loss: 2.2860 - val_mean_squared_error: 2.2860\n",
      "Epoch 13/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.1989 - mean_squared_error: 1.1989 - val_loss: 2.5530 - val_mean_squared_error: 2.5530\n",
      "Epoch 14/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2142 - mean_squared_error: 1.2142 - val_loss: 2.2631 - val_mean_squared_error: 2.2631\n",
      "Epoch 15/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2036 - mean_squared_error: 1.2036 - val_loss: 2.5915 - val_mean_squared_error: 2.5915\n",
      "Epoch 16/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2073 - mean_squared_error: 1.2073 - val_loss: 2.4569 - val_mean_squared_error: 2.4569\n",
      "Epoch 17/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2090 - mean_squared_error: 1.2090 - val_loss: 2.3788 - val_mean_squared_error: 2.3788\n",
      "Epoch 18/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2036 - mean_squared_error: 1.2036 - val_loss: 2.3745 - val_mean_squared_error: 2.3745\n",
      "Epoch 19/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.2018 - mean_squared_error: 1.2018 - val_loss: 2.5995 - val_mean_squared_error: 2.5995\n",
      "Epoch 20/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2064 - mean_squared_error: 1.2064 - val_loss: 2.6227 - val_mean_squared_error: 2.6227\n",
      "Epoch 21/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2057 - mean_squared_error: 1.2057 - val_loss: 2.5446 - val_mean_squared_error: 2.5446\n",
      "Epoch 22/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2083 - mean_squared_error: 1.2083 - val_loss: 2.6391 - val_mean_squared_error: 2.6391\n",
      "Epoch 23/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2108 - mean_squared_error: 1.2108 - val_loss: 2.5774 - val_mean_squared_error: 2.5774\n",
      "Epoch 24/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2084 - mean_squared_error: 1.2084 - val_loss: 2.4341 - val_mean_squared_error: 2.4341\n",
      "Epoch 25/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2106 - mean_squared_error: 1.2106 - val_loss: 2.5460 - val_mean_squared_error: 2.5460\n",
      "Epoch 26/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2049 - mean_squared_error: 1.2049 - val_loss: 2.5070 - val_mean_squared_error: 2.5070\n",
      "Epoch 27/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2039 - mean_squared_error: 1.2039 - val_loss: 2.5742 - val_mean_squared_error: 2.5742\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2007 - mean_squared_error: 1.2007 - val_loss: 2.5563 - val_mean_squared_error: 2.5563\n",
      "Epoch 29/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2068 - mean_squared_error: 1.2068 - val_loss: 2.5096 - val_mean_squared_error: 2.5096\n",
      "Epoch 30/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2051 - mean_squared_error: 1.2051 - val_loss: 2.6466 - val_mean_squared_error: 2.6466\n",
      "Epoch 31/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2065 - mean_squared_error: 1.2065 - val_loss: 2.5385 - val_mean_squared_error: 2.5385\n",
      "Epoch 32/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2098 - mean_squared_error: 1.2098 - val_loss: 2.5317 - val_mean_squared_error: 2.5317\n",
      "Epoch 33/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2038 - mean_squared_error: 1.2038 - val_loss: 2.6308 - val_mean_squared_error: 2.6308\n",
      "Epoch 34/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.1964 - mean_squared_error: 1.1964 - val_loss: 2.6415 - val_mean_squared_error: 2.6415\n",
      "Epoch 35/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.1983 - mean_squared_error: 1.1983 - val_loss: 2.5999 - val_mean_squared_error: 2.5999\n",
      "Epoch 36/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2083 - mean_squared_error: 1.2083 - val_loss: 2.6515 - val_mean_squared_error: 2.6515\n",
      "Epoch 37/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2109 - mean_squared_error: 1.2109 - val_loss: 2.7528 - val_mean_squared_error: 2.7528\n",
      "Epoch 38/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.1972 - mean_squared_error: 1.1972 - val_loss: 2.7147 - val_mean_squared_error: 2.7147\n",
      "Epoch 39/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.1998 - mean_squared_error: 1.1998 - val_loss: 2.6821 - val_mean_squared_error: 2.6821\n",
      "Epoch 40/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.1949 - mean_squared_error: 1.1949 - val_loss: 2.7381 - val_mean_squared_error: 2.7381\n",
      "Train on 9725 samples, validate on 1081 samples\n",
      "Epoch 1/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3419 - mean_squared_error: 1.3419 - val_loss: 1.0409 - val_mean_squared_error: 1.0409\n",
      "Epoch 2/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3426 - mean_squared_error: 1.3426 - val_loss: 1.0175 - val_mean_squared_error: 1.0175\n",
      "Epoch 3/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3329 - mean_squared_error: 1.3329 - val_loss: 1.0196 - val_mean_squared_error: 1.0196\n",
      "Epoch 4/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3159 - mean_squared_error: 1.3159 - val_loss: 1.0212 - val_mean_squared_error: 1.0212\n",
      "Epoch 5/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3048 - mean_squared_error: 1.3048 - val_loss: 1.0215 - val_mean_squared_error: 1.0215\n",
      "Epoch 6/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3018 - mean_squared_error: 1.3018 - val_loss: 1.0209 - val_mean_squared_error: 1.0209\n",
      "Epoch 7/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3037 - mean_squared_error: 1.3037 - val_loss: 1.0243 - val_mean_squared_error: 1.0243\n",
      "Epoch 8/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3013 - mean_squared_error: 1.3013 - val_loss: 1.0286 - val_mean_squared_error: 1.0286\n",
      "Epoch 9/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2944 - mean_squared_error: 1.2944 - val_loss: 1.0321 - val_mean_squared_error: 1.0321\n",
      "Epoch 10/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2998 - mean_squared_error: 1.2998 - val_loss: 1.0354 - val_mean_squared_error: 1.0354\n",
      "Epoch 11/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3021 - mean_squared_error: 1.3021 - val_loss: 1.0370 - val_mean_squared_error: 1.0370\n",
      "Epoch 12/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2954 - mean_squared_error: 1.2954 - val_loss: 1.0390 - val_mean_squared_error: 1.0390\n",
      "Epoch 13/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2984 - mean_squared_error: 1.2984 - val_loss: 1.0467 - val_mean_squared_error: 1.0467\n",
      "Epoch 14/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2943 - mean_squared_error: 1.2943 - val_loss: 1.0448 - val_mean_squared_error: 1.0448\n",
      "Epoch 15/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2900 - mean_squared_error: 1.2900 - val_loss: 1.0491 - val_mean_squared_error: 1.0491\n",
      "Epoch 16/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2957 - mean_squared_error: 1.2957 - val_loss: 1.0497 - val_mean_squared_error: 1.0497\n",
      "Epoch 17/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2989 - mean_squared_error: 1.2989 - val_loss: 1.0515 - val_mean_squared_error: 1.0515\n",
      "Epoch 18/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2940 - mean_squared_error: 1.2940 - val_loss: 1.0550 - val_mean_squared_error: 1.0550\n",
      "Epoch 19/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2919 - mean_squared_error: 1.2919 - val_loss: 1.0555 - val_mean_squared_error: 1.0555\n",
      "Epoch 20/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.3182 - mean_squared_error: 1.3182 - val_loss: 1.1248 - val_mean_squared_error: 1.1248\n",
      "Epoch 21/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3096 - mean_squared_error: 1.3096 - val_loss: 1.0516 - val_mean_squared_error: 1.0516\n",
      "Epoch 22/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3088 - mean_squared_error: 1.3088 - val_loss: 1.0523 - val_mean_squared_error: 1.0523\n",
      "Epoch 23/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3085 - mean_squared_error: 1.3085 - val_loss: 1.0790 - val_mean_squared_error: 1.0790\n",
      "Epoch 24/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3079 - mean_squared_error: 1.3079 - val_loss: 1.0567 - val_mean_squared_error: 1.0567\n",
      "Epoch 25/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.2983 - mean_squared_error: 1.2983 - val_loss: 1.0563 - val_mean_squared_error: 1.0563\n",
      "Epoch 26/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2942 - mean_squared_error: 1.2942 - val_loss: 1.0523 - val_mean_squared_error: 1.0523\n",
      "Epoch 27/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2850 - mean_squared_error: 1.2850 - val_loss: 1.0542 - val_mean_squared_error: 1.0542\n",
      "Epoch 28/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2849 - mean_squared_error: 1.2849 - val_loss: 1.0577 - val_mean_squared_error: 1.0577\n",
      "Epoch 29/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2765 - mean_squared_error: 1.2765 - val_loss: 1.0626 - val_mean_squared_error: 1.0626\n",
      "Epoch 30/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2763 - mean_squared_error: 1.2763 - val_loss: 1.0622 - val_mean_squared_error: 1.0622\n",
      "Epoch 31/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2773 - mean_squared_error: 1.2773 - val_loss: 1.0786 - val_mean_squared_error: 1.0786\n",
      "Epoch 32/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2906 - mean_squared_error: 1.2906 - val_loss: 1.0663 - val_mean_squared_error: 1.0663\n",
      "Epoch 33/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2885 - mean_squared_error: 1.2885 - val_loss: 1.0776 - val_mean_squared_error: 1.0776\n",
      "Epoch 34/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2853 - mean_squared_error: 1.2853 - val_loss: 1.0672 - val_mean_squared_error: 1.0672\n",
      "Epoch 35/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.2913 - mean_squared_error: 1.2913 - val_loss: 1.1088 - val_mean_squared_error: 1.1088\n",
      "Epoch 36/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2942 - mean_squared_error: 1.2942 - val_loss: 1.1180 - val_mean_squared_error: 1.1180\n",
      "Epoch 37/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2925 - mean_squared_error: 1.2925 - val_loss: 1.0746 - val_mean_squared_error: 1.0746\n",
      "Epoch 38/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2856 - mean_squared_error: 1.2856 - val_loss: 1.0922 - val_mean_squared_error: 1.0922\n",
      "Epoch 39/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2909 - mean_squared_error: 1.2909 - val_loss: 1.0668 - val_mean_squared_error: 1.0668\n",
      "Epoch 40/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2872 - mean_squared_error: 1.2872 - val_loss: 1.0920 - val_mean_squared_error: 1.0920\n",
      "Train on 9725 samples, validate on 1081 samples\n",
      "Epoch 1/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2871 - mean_squared_error: 1.2871 - val_loss: 1.2263 - val_mean_squared_error: 1.2263\n",
      "Epoch 2/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2825 - mean_squared_error: 1.2825 - val_loss: 1.2232 - val_mean_squared_error: 1.2232\n",
      "Epoch 3/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2689 - mean_squared_error: 1.2689 - val_loss: 1.2215 - val_mean_squared_error: 1.2215\n",
      "Epoch 4/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2790 - mean_squared_error: 1.2790 - val_loss: 1.2281 - val_mean_squared_error: 1.2281\n",
      "Epoch 5/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2657 - mean_squared_error: 1.2657 - val_loss: 1.2276 - val_mean_squared_error: 1.2276\n",
      "Epoch 6/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2696 - mean_squared_error: 1.2696 - val_loss: 1.2300 - val_mean_squared_error: 1.2300\n",
      "Epoch 7/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.2593 - mean_squared_error: 1.2593 - val_loss: 1.2326 - val_mean_squared_error: 1.2326\n",
      "Epoch 8/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2659 - mean_squared_error: 1.2659 - val_loss: 1.2333 - val_mean_squared_error: 1.2333\n",
      "Epoch 9/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2638 - mean_squared_error: 1.2638 - val_loss: 1.2345 - val_mean_squared_error: 1.2345\n",
      "Epoch 10/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.2616 - mean_squared_error: 1.2616 - val_loss: 1.2367 - val_mean_squared_error: 1.2367\n",
      "Epoch 11/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2612 - mean_squared_error: 1.2612 - val_loss: 2.0062 - val_mean_squared_error: 2.0062\n",
      "Epoch 12/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.3209 - mean_squared_error: 1.3209 - val_loss: 1.2462 - val_mean_squared_error: 1.2462\n",
      "Epoch 13/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2770 - mean_squared_error: 1.2770 - val_loss: 1.2385 - val_mean_squared_error: 1.2385\n",
      "Epoch 14/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2824 - mean_squared_error: 1.2824 - val_loss: 1.2370 - val_mean_squared_error: 1.2370\n",
      "Epoch 15/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.2667 - mean_squared_error: 1.2667 - val_loss: 1.2392 - val_mean_squared_error: 1.2392\n",
      "Epoch 16/40\n",
      "9725/9725 [==============================] - 70s 7ms/step - loss: 1.2618 - mean_squared_error: 1.2618 - val_loss: 1.2402 - val_mean_squared_error: 1.2402\n",
      "Epoch 17/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2636 - mean_squared_error: 1.2636 - val_loss: 1.2421 - val_mean_squared_error: 1.2421\n",
      "Epoch 18/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2637 - mean_squared_error: 1.2637 - val_loss: 1.2417 - val_mean_squared_error: 1.2417\n",
      "Epoch 19/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2642 - mean_squared_error: 1.2642 - val_loss: 1.2455 - val_mean_squared_error: 1.2455\n",
      "Epoch 20/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2666 - mean_squared_error: 1.2666 - val_loss: 1.2424 - val_mean_squared_error: 1.2424\n",
      "Epoch 21/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2673 - mean_squared_error: 1.2673 - val_loss: 1.2451 - val_mean_squared_error: 1.2451\n",
      "Epoch 22/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2830 - mean_squared_error: 1.2830 - val_loss: 1.2462 - val_mean_squared_error: 1.2462\n",
      "Epoch 23/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2816 - mean_squared_error: 1.2816 - val_loss: 1.2560 - val_mean_squared_error: 1.2560\n",
      "Epoch 24/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2814 - mean_squared_error: 1.2814 - val_loss: 1.2568 - val_mean_squared_error: 1.2568\n",
      "Epoch 25/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2770 - mean_squared_error: 1.2770 - val_loss: 1.2478 - val_mean_squared_error: 1.2478\n",
      "Epoch 26/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2753 - mean_squared_error: 1.2753 - val_loss: 1.2501 - val_mean_squared_error: 1.2501\n",
      "Epoch 27/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2767 - mean_squared_error: 1.2767 - val_loss: 1.2510 - val_mean_squared_error: 1.2510\n",
      "Epoch 28/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2776 - mean_squared_error: 1.2776 - val_loss: 1.2488 - val_mean_squared_error: 1.2488\n",
      "Epoch 29/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2846 - mean_squared_error: 1.2846 - val_loss: 1.2474 - val_mean_squared_error: 1.2474\n",
      "Epoch 30/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2732 - mean_squared_error: 1.2732 - val_loss: 1.2448 - val_mean_squared_error: 1.2448\n",
      "Epoch 31/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2703 - mean_squared_error: 1.2703 - val_loss: 1.2471 - val_mean_squared_error: 1.2471\n",
      "Epoch 32/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2698 - mean_squared_error: 1.2698 - val_loss: 1.2538 - val_mean_squared_error: 1.2538\n",
      "Epoch 33/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2723 - mean_squared_error: 1.2723 - val_loss: 1.2514 - val_mean_squared_error: 1.2514\n",
      "Epoch 34/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2726 - mean_squared_error: 1.2726 - val_loss: 1.2489 - val_mean_squared_error: 1.2489\n",
      "Epoch 35/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2749 - mean_squared_error: 1.2749 - val_loss: 1.2532 - val_mean_squared_error: 1.2532\n",
      "Epoch 36/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2823 - mean_squared_error: 1.2823 - val_loss: 1.2555 - val_mean_squared_error: 1.2555\n",
      "Epoch 37/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2774 - mean_squared_error: 1.2774 - val_loss: 1.2538 - val_mean_squared_error: 1.2538\n",
      "Epoch 38/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2839 - mean_squared_error: 1.2839 - val_loss: 1.2644 - val_mean_squared_error: 1.2644\n",
      "Epoch 39/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2796 - mean_squared_error: 1.2796 - val_loss: 1.2590 - val_mean_squared_error: 1.2590\n",
      "Epoch 40/40\n",
      "9725/9725 [==============================] - 71s 7ms/step - loss: 1.2857 - mean_squared_error: 1.2857 - val_loss: 1.2587 - val_mean_squared_error: 1.2587\n",
      "Train on 9726 samples, validate on 1080 samples\n",
      "Epoch 1/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3211 - mean_squared_error: 1.3211 - val_loss: 1.0208 - val_mean_squared_error: 1.0208\n",
      "Epoch 2/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3131 - mean_squared_error: 1.3131 - val_loss: 1.0281 - val_mean_squared_error: 1.0281\n",
      "Epoch 3/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3266 - mean_squared_error: 1.3266 - val_loss: 1.0348 - val_mean_squared_error: 1.0348\n",
      "Epoch 4/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3034 - mean_squared_error: 1.3034 - val_loss: 1.0389 - val_mean_squared_error: 1.0389\n",
      "Epoch 5/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2941 - mean_squared_error: 1.2941 - val_loss: 1.0418 - val_mean_squared_error: 1.0418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3044 - mean_squared_error: 1.3044 - val_loss: 1.0450 - val_mean_squared_error: 1.0450\n",
      "Epoch 7/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2995 - mean_squared_error: 1.2995 - val_loss: 1.0479 - val_mean_squared_error: 1.0479\n",
      "Epoch 8/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2960 - mean_squared_error: 1.2960 - val_loss: 1.0495 - val_mean_squared_error: 1.0495\n",
      "Epoch 9/40\n",
      "9726/9726 [==============================] - 72s 7ms/step - loss: 1.2913 - mean_squared_error: 1.2913 - val_loss: 1.0524 - val_mean_squared_error: 1.0524\n",
      "Epoch 10/40\n",
      "9726/9726 [==============================] - 72s 7ms/step - loss: 1.2959 - mean_squared_error: 1.2959 - val_loss: 1.0560 - val_mean_squared_error: 1.0560\n",
      "Epoch 11/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2989 - mean_squared_error: 1.2989 - val_loss: 1.0578 - val_mean_squared_error: 1.0578\n",
      "Epoch 12/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3190 - mean_squared_error: 1.3190 - val_loss: 1.0618 - val_mean_squared_error: 1.0618\n",
      "Epoch 13/40\n",
      "9726/9726 [==============================] - 72s 7ms/step - loss: 1.3024 - mean_squared_error: 1.3024 - val_loss: 1.1066 - val_mean_squared_error: 1.1066\n",
      "Epoch 14/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3142 - mean_squared_error: 1.3142 - val_loss: 1.0818 - val_mean_squared_error: 1.0818\n",
      "Epoch 15/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3045 - mean_squared_error: 1.3045 - val_loss: 1.0617 - val_mean_squared_error: 1.0617\n",
      "Epoch 16/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3012 - mean_squared_error: 1.3012 - val_loss: 1.0644 - val_mean_squared_error: 1.0644\n",
      "Epoch 17/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2807 - mean_squared_error: 1.2807 - val_loss: 1.0631 - val_mean_squared_error: 1.0631\n",
      "Epoch 18/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2902 - mean_squared_error: 1.2902 - val_loss: 1.0639 - val_mean_squared_error: 1.0639\n",
      "Epoch 19/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2922 - mean_squared_error: 1.2922 - val_loss: 1.0659 - val_mean_squared_error: 1.0659\n",
      "Epoch 20/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2881 - mean_squared_error: 1.2881 - val_loss: 1.0679 - val_mean_squared_error: 1.0679\n",
      "Epoch 21/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3017 - mean_squared_error: 1.3017 - val_loss: 1.0672 - val_mean_squared_error: 1.0672\n",
      "Epoch 22/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3109 - mean_squared_error: 1.3109 - val_loss: 1.0692 - val_mean_squared_error: 1.0692\n",
      "Epoch 23/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3027 - mean_squared_error: 1.3027 - val_loss: 1.0716 - val_mean_squared_error: 1.0716\n",
      "Epoch 24/40\n",
      "9726/9726 [==============================] - 72s 7ms/step - loss: 1.2980 - mean_squared_error: 1.2980 - val_loss: 1.0728 - val_mean_squared_error: 1.0728\n",
      "Epoch 25/40\n",
      "9726/9726 [==============================] - 72s 7ms/step - loss: 1.2917 - mean_squared_error: 1.2917 - val_loss: 1.0712 - val_mean_squared_error: 1.0712\n",
      "Epoch 26/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2981 - mean_squared_error: 1.2981 - val_loss: 1.0727 - val_mean_squared_error: 1.0727\n",
      "Epoch 27/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2922 - mean_squared_error: 1.2922 - val_loss: 1.0744 - val_mean_squared_error: 1.0744\n",
      "Epoch 28/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3074 - mean_squared_error: 1.3074 - val_loss: 1.0712 - val_mean_squared_error: 1.0712\n",
      "Epoch 29/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3179 - mean_squared_error: 1.3179 - val_loss: 1.0699 - val_mean_squared_error: 1.0699\n",
      "Epoch 30/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3116 - mean_squared_error: 1.3116 - val_loss: 1.0732 - val_mean_squared_error: 1.0732\n",
      "Epoch 31/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2946 - mean_squared_error: 1.2946 - val_loss: 1.0712 - val_mean_squared_error: 1.0712\n",
      "Epoch 32/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2929 - mean_squared_error: 1.2929 - val_loss: 1.0732 - val_mean_squared_error: 1.0732\n",
      "Epoch 33/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2904 - mean_squared_error: 1.2904 - val_loss: 1.0725 - val_mean_squared_error: 1.0725\n",
      "Epoch 34/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2981 - mean_squared_error: 1.2981 - val_loss: 1.0747 - val_mean_squared_error: 1.0747\n",
      "Epoch 35/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3072 - mean_squared_error: 1.3072 - val_loss: 1.0753 - val_mean_squared_error: 1.0753\n",
      "Epoch 36/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2979 - mean_squared_error: 1.2979 - val_loss: 1.0764 - val_mean_squared_error: 1.0764\n",
      "Epoch 37/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3038 - mean_squared_error: 1.3038 - val_loss: 1.0755 - val_mean_squared_error: 1.0755\n",
      "Epoch 38/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3041 - mean_squared_error: 1.3041 - val_loss: 1.0762 - val_mean_squared_error: 1.0762\n",
      "Epoch 39/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2998 - mean_squared_error: 1.2998 - val_loss: 1.0752 - val_mean_squared_error: 1.0752\n",
      "Epoch 40/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2994 - mean_squared_error: 1.2994 - val_loss: 1.0753 - val_mean_squared_error: 1.0753\n",
      "Train on 9726 samples, validate on 1080 samples\n",
      "Epoch 1/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3013 - mean_squared_error: 1.3013 - val_loss: 1.0486 - val_mean_squared_error: 1.0486\n",
      "Epoch 2/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3043 - mean_squared_error: 1.3043 - val_loss: 1.0656 - val_mean_squared_error: 1.0656\n",
      "Epoch 3/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2953 - mean_squared_error: 1.2953 - val_loss: 1.0645 - val_mean_squared_error: 1.0645\n",
      "Epoch 4/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3065 - mean_squared_error: 1.3065 - val_loss: 1.0609 - val_mean_squared_error: 1.0609\n",
      "Epoch 5/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2935 - mean_squared_error: 1.2935 - val_loss: 1.0590 - val_mean_squared_error: 1.0590\n",
      "Epoch 6/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2984 - mean_squared_error: 1.2984 - val_loss: 1.0653 - val_mean_squared_error: 1.0653\n",
      "Epoch 7/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2929 - mean_squared_error: 1.2929 - val_loss: 1.0746 - val_mean_squared_error: 1.0746\n",
      "Epoch 8/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3004 - mean_squared_error: 1.3004 - val_loss: 1.0810 - val_mean_squared_error: 1.0810\n",
      "Epoch 9/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2934 - mean_squared_error: 1.2934 - val_loss: 1.0892 - val_mean_squared_error: 1.0892\n",
      "Epoch 10/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3017 - mean_squared_error: 1.3017 - val_loss: 1.0804 - val_mean_squared_error: 1.0804\n",
      "Epoch 11/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2888 - mean_squared_error: 1.2888 - val_loss: 1.0863 - val_mean_squared_error: 1.0863\n",
      "Epoch 12/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3094 - mean_squared_error: 1.3094 - val_loss: 1.0723 - val_mean_squared_error: 1.0723\n",
      "Epoch 13/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2911 - mean_squared_error: 1.2911 - val_loss: 1.0876 - val_mean_squared_error: 1.0876\n",
      "Epoch 14/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3074 - mean_squared_error: 1.3074 - val_loss: 1.0977 - val_mean_squared_error: 1.0977\n",
      "Epoch 15/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2953 - mean_squared_error: 1.2953 - val_loss: 1.1009 - val_mean_squared_error: 1.1009\n",
      "Epoch 16/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2912 - mean_squared_error: 1.2912 - val_loss: 1.1076 - val_mean_squared_error: 1.1076\n",
      "Epoch 17/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2923 - mean_squared_error: 1.2923 - val_loss: 1.1082 - val_mean_squared_error: 1.1082\n",
      "Epoch 18/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2937 - mean_squared_error: 1.2937 - val_loss: 1.1021 - val_mean_squared_error: 1.1021\n",
      "Epoch 19/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3032 - mean_squared_error: 1.3032 - val_loss: 1.0991 - val_mean_squared_error: 1.0991\n",
      "Epoch 20/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2985 - mean_squared_error: 1.2985 - val_loss: 1.1084 - val_mean_squared_error: 1.1084\n",
      "Epoch 21/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2978 - mean_squared_error: 1.2978 - val_loss: 1.1054 - val_mean_squared_error: 1.1054\n",
      "Epoch 22/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2834 - mean_squared_error: 1.2834 - val_loss: 1.0949 - val_mean_squared_error: 1.0949\n",
      "Epoch 23/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2957 - mean_squared_error: 1.2957 - val_loss: 1.1126 - val_mean_squared_error: 1.1126\n",
      "Epoch 24/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2984 - mean_squared_error: 1.2984 - val_loss: 1.1026 - val_mean_squared_error: 1.1026\n",
      "Epoch 25/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2994 - mean_squared_error: 1.2994 - val_loss: 1.1316 - val_mean_squared_error: 1.1316\n",
      "Epoch 26/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2931 - mean_squared_error: 1.2931 - val_loss: 1.1356 - val_mean_squared_error: 1.1356\n",
      "Epoch 27/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2826 - mean_squared_error: 1.2826 - val_loss: 1.1263 - val_mean_squared_error: 1.1263\n",
      "Epoch 28/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2919 - mean_squared_error: 1.2919 - val_loss: 1.1438 - val_mean_squared_error: 1.1438\n",
      "Epoch 29/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2937 - mean_squared_error: 1.2937 - val_loss: 1.1388 - val_mean_squared_error: 1.1388\n",
      "Epoch 30/40\n",
      "9726/9726 [==============================] - 70s 7ms/step - loss: 1.2932 - mean_squared_error: 1.2932 - val_loss: 1.1282 - val_mean_squared_error: 1.1282\n",
      "Epoch 31/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2962 - mean_squared_error: 1.2962 - val_loss: 1.1284 - val_mean_squared_error: 1.1284\n",
      "Epoch 32/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3007 - mean_squared_error: 1.3007 - val_loss: 1.1456 - val_mean_squared_error: 1.1456\n",
      "Epoch 33/40\n",
      "9726/9726 [==============================] - 70s 7ms/step - loss: 1.3047 - mean_squared_error: 1.3047 - val_loss: 1.1513 - val_mean_squared_error: 1.1513\n",
      "Epoch 34/40\n",
      "9726/9726 [==============================] - 70s 7ms/step - loss: 1.2942 - mean_squared_error: 1.2942 - val_loss: 1.1402 - val_mean_squared_error: 1.1402\n",
      "Epoch 35/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2912 - mean_squared_error: 1.2912 - val_loss: 1.1532 - val_mean_squared_error: 1.1532\n",
      "Epoch 36/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2965 - mean_squared_error: 1.2965 - val_loss: 1.1319 - val_mean_squared_error: 1.1319\n",
      "Epoch 37/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2909 - mean_squared_error: 1.2909 - val_loss: 1.1820 - val_mean_squared_error: 1.1820\n",
      "Epoch 38/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2971 - mean_squared_error: 1.2971 - val_loss: 1.1465 - val_mean_squared_error: 1.1465\n",
      "Epoch 39/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2952 - mean_squared_error: 1.2952 - val_loss: 1.1702 - val_mean_squared_error: 1.1702\n",
      "Epoch 40/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2977 - mean_squared_error: 1.2977 - val_loss: 1.1533 - val_mean_squared_error: 1.1533\n",
      "Train on 9726 samples, validate on 1080 samples\n",
      "Epoch 1/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2859 - mean_squared_error: 1.2859 - val_loss: 1.1956 - val_mean_squared_error: 1.1956\n",
      "Epoch 2/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2866 - mean_squared_error: 1.2866 - val_loss: 1.2121 - val_mean_squared_error: 1.2121\n",
      "Epoch 3/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2889 - mean_squared_error: 1.2889 - val_loss: 1.2168 - val_mean_squared_error: 1.2168\n",
      "Epoch 4/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2860 - mean_squared_error: 1.2860 - val_loss: 1.2200 - val_mean_squared_error: 1.2200\n",
      "Epoch 5/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2852 - mean_squared_error: 1.2852 - val_loss: 1.2399 - val_mean_squared_error: 1.2399\n",
      "Epoch 6/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2842 - mean_squared_error: 1.2842 - val_loss: 1.2529 - val_mean_squared_error: 1.2529\n",
      "Epoch 7/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2802 - mean_squared_error: 1.2802 - val_loss: 1.2871 - val_mean_squared_error: 1.2871\n",
      "Epoch 8/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2895 - mean_squared_error: 1.2895 - val_loss: 1.2624 - val_mean_squared_error: 1.2624\n",
      "Epoch 9/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2816 - mean_squared_error: 1.2816 - val_loss: 1.2350 - val_mean_squared_error: 1.2350\n",
      "Epoch 10/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2812 - mean_squared_error: 1.2812 - val_loss: 1.3163 - val_mean_squared_error: 1.3163\n",
      "Epoch 11/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2972 - mean_squared_error: 1.2972 - val_loss: 1.2457 - val_mean_squared_error: 1.2457\n",
      "Epoch 12/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2891 - mean_squared_error: 1.2891 - val_loss: 1.3257 - val_mean_squared_error: 1.3257\n",
      "Epoch 13/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2932 - mean_squared_error: 1.2932 - val_loss: 1.2931 - val_mean_squared_error: 1.2931\n",
      "Epoch 14/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.3021 - mean_squared_error: 1.3021 - val_loss: 1.2986 - val_mean_squared_error: 1.2986\n",
      "Epoch 15/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2832 - mean_squared_error: 1.2832 - val_loss: 1.3095 - val_mean_squared_error: 1.3095\n",
      "Epoch 16/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2844 - mean_squared_error: 1.2844 - val_loss: 1.2816 - val_mean_squared_error: 1.2816\n",
      "Epoch 17/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2911 - mean_squared_error: 1.2911 - val_loss: 1.3326 - val_mean_squared_error: 1.3326\n",
      "Epoch 18/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2847 - mean_squared_error: 1.2847 - val_loss: 1.3320 - val_mean_squared_error: 1.3320\n",
      "Epoch 19/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2808 - mean_squared_error: 1.2808 - val_loss: 1.3392 - val_mean_squared_error: 1.3392\n",
      "Epoch 20/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2841 - mean_squared_error: 1.2841 - val_loss: 1.3481 - val_mean_squared_error: 1.3481\n",
      "Epoch 21/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2773 - mean_squared_error: 1.2773 - val_loss: 1.3530 - val_mean_squared_error: 1.3530\n",
      "Epoch 22/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2799 - mean_squared_error: 1.2799 - val_loss: 1.3677 - val_mean_squared_error: 1.3677\n",
      "Epoch 23/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2827 - mean_squared_error: 1.2827 - val_loss: 1.3692 - val_mean_squared_error: 1.3692\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2800 - mean_squared_error: 1.2800 - val_loss: 1.3561 - val_mean_squared_error: 1.3561\n",
      "Epoch 25/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2736 - mean_squared_error: 1.2736 - val_loss: 1.4088 - val_mean_squared_error: 1.4088\n",
      "Epoch 26/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2754 - mean_squared_error: 1.2754 - val_loss: 1.3826 - val_mean_squared_error: 1.3826\n",
      "Epoch 27/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2725 - mean_squared_error: 1.2725 - val_loss: 1.4083 - val_mean_squared_error: 1.4083\n",
      "Epoch 28/40\n",
      "9726/9726 [==============================] - 70s 7ms/step - loss: 1.2775 - mean_squared_error: 1.2775 - val_loss: 1.4074 - val_mean_squared_error: 1.4074\n",
      "Epoch 29/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2763 - mean_squared_error: 1.2763 - val_loss: 1.3878 - val_mean_squared_error: 1.3878\n",
      "Epoch 30/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2776 - mean_squared_error: 1.2776 - val_loss: 1.3928 - val_mean_squared_error: 1.3928\n",
      "Epoch 31/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2721 - mean_squared_error: 1.2721 - val_loss: 1.4050 - val_mean_squared_error: 1.4050\n",
      "Epoch 32/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2733 - mean_squared_error: 1.2733 - val_loss: 1.4407 - val_mean_squared_error: 1.4407\n",
      "Epoch 33/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2744 - mean_squared_error: 1.2744 - val_loss: 1.4408 - val_mean_squared_error: 1.4408\n",
      "Epoch 34/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2764 - mean_squared_error: 1.2764 - val_loss: 1.4324 - val_mean_squared_error: 1.4324\n",
      "Epoch 35/40\n",
      "9726/9726 [==============================] - 70s 7ms/step - loss: 1.2670 - mean_squared_error: 1.2670 - val_loss: 1.4542 - val_mean_squared_error: 1.4542\n",
      "Epoch 36/40\n",
      "9726/9726 [==============================] - 70s 7ms/step - loss: 1.2795 - mean_squared_error: 1.2795 - val_loss: 1.4386 - val_mean_squared_error: 1.4386\n",
      "Epoch 37/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2736 - mean_squared_error: 1.2736 - val_loss: 1.4554 - val_mean_squared_error: 1.4554\n",
      "Epoch 38/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2695 - mean_squared_error: 1.2695 - val_loss: 1.4566 - val_mean_squared_error: 1.4566\n",
      "Epoch 39/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2732 - mean_squared_error: 1.2732 - val_loss: 1.4544 - val_mean_squared_error: 1.4544\n",
      "Epoch 40/40\n",
      "9726/9726 [==============================] - 70s 7ms/step - loss: 1.2782 - mean_squared_error: 1.2782 - val_loss: 1.4402 - val_mean_squared_error: 1.4402\n",
      "Train on 9726 samples, validate on 1080 samples\n",
      "Epoch 1/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2251 - mean_squared_error: 1.2251 - val_loss: 1.8241 - val_mean_squared_error: 1.8241\n",
      "Epoch 2/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2609 - mean_squared_error: 1.2609 - val_loss: 1.7850 - val_mean_squared_error: 1.7850\n",
      "Epoch 3/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2348 - mean_squared_error: 1.2348 - val_loss: 1.8181 - val_mean_squared_error: 1.8181\n",
      "Epoch 4/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2129 - mean_squared_error: 1.2129 - val_loss: 1.8527 - val_mean_squared_error: 1.8527\n",
      "Epoch 5/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2089 - mean_squared_error: 1.2089 - val_loss: 1.8716 - val_mean_squared_error: 1.8716\n",
      "Epoch 6/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2080 - mean_squared_error: 1.2080 - val_loss: 1.8820 - val_mean_squared_error: 1.8820\n",
      "Epoch 7/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1957 - mean_squared_error: 1.1957 - val_loss: 1.8821 - val_mean_squared_error: 1.8821\n",
      "Epoch 8/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1923 - mean_squared_error: 1.1923 - val_loss: 1.8962 - val_mean_squared_error: 1.8962\n",
      "Epoch 9/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1998 - mean_squared_error: 1.1998 - val_loss: 1.8991 - val_mean_squared_error: 1.8991\n",
      "Epoch 10/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1900 - mean_squared_error: 1.1900 - val_loss: 1.9037 - val_mean_squared_error: 1.9037\n",
      "Epoch 11/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1860 - mean_squared_error: 1.1860 - val_loss: 1.9124 - val_mean_squared_error: 1.9124\n",
      "Epoch 12/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1981 - mean_squared_error: 1.1981 - val_loss: 1.9236 - val_mean_squared_error: 1.9236\n",
      "Epoch 13/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1977 - mean_squared_error: 1.1977 - val_loss: 1.9095 - val_mean_squared_error: 1.9095\n",
      "Epoch 14/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1917 - mean_squared_error: 1.1917 - val_loss: 1.9170 - val_mean_squared_error: 1.9170\n",
      "Epoch 15/40\n",
      "9726/9726 [==============================] - 70s 7ms/step - loss: 1.2097 - mean_squared_error: 1.2097 - val_loss: 1.9125 - val_mean_squared_error: 1.9125\n",
      "Epoch 16/40\n",
      "9726/9726 [==============================] - 70s 7ms/step - loss: 1.2119 - mean_squared_error: 1.2119 - val_loss: 1.9536 - val_mean_squared_error: 1.9536\n",
      "Epoch 17/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1983 - mean_squared_error: 1.1983 - val_loss: 1.9652 - val_mean_squared_error: 1.9652\n",
      "Epoch 18/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1948 - mean_squared_error: 1.1948 - val_loss: 1.9202 - val_mean_squared_error: 1.9202\n",
      "Epoch 19/40\n",
      "9726/9726 [==============================] - 70s 7ms/step - loss: 1.1880 - mean_squared_error: 1.1880 - val_loss: 1.9224 - val_mean_squared_error: 1.9224\n",
      "Epoch 20/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1972 - mean_squared_error: 1.1972 - val_loss: 1.9200 - val_mean_squared_error: 1.9200\n",
      "Epoch 21/40\n",
      "9726/9726 [==============================] - 70s 7ms/step - loss: 1.1883 - mean_squared_error: 1.1883 - val_loss: 1.9237 - val_mean_squared_error: 1.9237\n",
      "Epoch 22/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1873 - mean_squared_error: 1.1873 - val_loss: 1.9298 - val_mean_squared_error: 1.9298\n",
      "Epoch 23/40\n",
      "9726/9726 [==============================] - 70s 7ms/step - loss: 1.1868 - mean_squared_error: 1.1868 - val_loss: 1.9291 - val_mean_squared_error: 1.9291\n",
      "Epoch 24/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2038 - mean_squared_error: 1.2038 - val_loss: 1.9541 - val_mean_squared_error: 1.9541\n",
      "Epoch 25/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2035 - mean_squared_error: 1.2035 - val_loss: 2.0354 - val_mean_squared_error: 2.0354\n",
      "Epoch 26/40\n",
      "9726/9726 [==============================] - 70s 7ms/step - loss: 1.2051 - mean_squared_error: 1.2051 - val_loss: 1.9698 - val_mean_squared_error: 1.9698\n",
      "Epoch 27/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2054 - mean_squared_error: 1.2054 - val_loss: 1.9222 - val_mean_squared_error: 1.9222\n",
      "Epoch 28/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1887 - mean_squared_error: 1.1887 - val_loss: 1.9320 - val_mean_squared_error: 1.9320\n",
      "Epoch 29/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1828 - mean_squared_error: 1.1828 - val_loss: 1.9334 - val_mean_squared_error: 1.9334\n",
      "Epoch 30/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1860 - mean_squared_error: 1.1860 - val_loss: 1.9317 - val_mean_squared_error: 1.9317\n",
      "Epoch 31/40\n",
      "9726/9726 [==============================] - 70s 7ms/step - loss: 1.1843 - mean_squared_error: 1.1843 - val_loss: 1.9407 - val_mean_squared_error: 1.9407\n",
      "Epoch 32/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1867 - mean_squared_error: 1.1867 - val_loss: 1.9323 - val_mean_squared_error: 1.9323\n",
      "Epoch 33/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1852 - mean_squared_error: 1.1852 - val_loss: 1.9394 - val_mean_squared_error: 1.9394\n",
      "Epoch 34/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1870 - mean_squared_error: 1.1870 - val_loss: 1.9328 - val_mean_squared_error: 1.9328\n",
      "Epoch 35/40\n",
      "9726/9726 [==============================] - 70s 7ms/step - loss: 1.2037 - mean_squared_error: 1.2037 - val_loss: 1.9384 - val_mean_squared_error: 1.9384\n",
      "Epoch 36/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.2012 - mean_squared_error: 1.2012 - val_loss: 1.9653 - val_mean_squared_error: 1.9653\n",
      "Epoch 37/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1930 - mean_squared_error: 1.1930 - val_loss: 2.0092 - val_mean_squared_error: 2.0092\n",
      "Epoch 38/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1938 - mean_squared_error: 1.1938 - val_loss: 1.9752 - val_mean_squared_error: 1.9752\n",
      "Epoch 39/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1996 - mean_squared_error: 1.1996 - val_loss: 1.9827 - val_mean_squared_error: 1.9827\n",
      "Epoch 40/40\n",
      "9726/9726 [==============================] - 71s 7ms/step - loss: 1.1959 - mean_squared_error: 1.1959 - val_loss: 1.9508 - val_mean_squared_error: 1.9508\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 40\n",
    "\n",
    "cv_idx = 1\n",
    "for train_index, test_index in kf.split(X_mel):\n",
    "    model_name = \"../data/CV_ACC_mel_40_CV%d.h5\" % (cv_idx)\n",
    "#     model.load_weights(model_name)\n",
    "    X_train, X_test = X_mel[train_index], X_mel[test_index]\n",
    "    X_train_wav, X_test_wav = X_wav[train_index], X_wav[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    history = model_mel.fit(X_train, y_train, batch_size = batch_size, epochs = num_epochs, shuffle = False,\n",
    "                       class_weight = None, verbose = 1, validation_data = (X_test, y_test), \n",
    "                       callbacks = [tensorboard_callback])\n",
    "    CV_mel_histories.append(history)\n",
    "            \n",
    "    model_mel.save(model_name)\n",
    "    \n",
    "    scores = model_mel.evaluate(X_test, y_test, verbose=0)\n",
    "    CV_mel_mse.append(scores[1])\n",
    "    y_prediction = model_mel.predict(X_test)\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        result = \"%d\\t%s\\t%d\\t%f\\n\" % (cv_idx, wav_names[X_test_wav[i]], y_test[i], y_prediction[i][0])\n",
    "#         print(result)\n",
    "        CV_mel_prediction.append(result)\n",
    "    \n",
    "    cv_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.459484366081469\n",
      "2 1.119681463651807\n",
      "3 1.2086396092733336\n",
      "4 2.401153661496765\n",
      "5 1.3314205574614377\n",
      "6 1.447696704096975\n",
      "7 1.1030245114255834\n",
      "8 1.2911398031093455\n",
      "9 1.5589563369750976\n",
      "10 2.038569023874071\n"
     ]
    }
   ],
   "source": [
    "for i, mse in enumerate(CV_mse[-10:]):\n",
    "    print(i + 1, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results/accented_mel_10CV.txt\", \"w\") as output:\n",
    "    for prediction in CV_mel_prediction:\n",
    "        output.write(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "\n",
    "for history in CV_mel_histories[-10:]:\n",
    "    plt.plot(history.history['loss'])\n",
    "    \n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNgj1JHcGzGQnCrsiYuWjzf",
   "collapsed_sections": [],
   "name": "RNN_automatic_judgment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
